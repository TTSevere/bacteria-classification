{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaXSEE2f1D6c"
   },
   "source": [
    "###  <span style=\"color:red\">**This Notebook can be run from Google Colab:**</span>\n",
    "\n",
    "https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXXypVC31ETj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from google.colab import files\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization,\\\n",
    "                          Conv2D, MaxPooling2D, Flatten, AveragePooling2D,\\\n",
    "                          GlobalAveragePooling2D, ZeroPadding2D\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam, Adamax, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, \\\n",
    "                            classification_report\n",
    "\n",
    "# Import PyDrive and associated libraries (to connect with GoogleDrive)\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DItexGaqdfEA"
   },
   "source": [
    "### **Check if we are using GPU:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vn7AYx74dNq6",
    "outputId": "5b48763f-c7e3-42c3-f083-6f484f95a497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 1.15.0 , GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "if K.backend() == \"tensorflow\":\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name == '':\n",
    "        device_name = \"None\"\n",
    "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQXfhMrHlqrz"
   },
   "source": [
    "### **Download Patches from GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ACvUlEucnnY0",
    "outputId": "1beed7dd-220f-400a-e404-bb6b489c26b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded content: \"Patches_pos_vs_neg_128_s60_vs22_min1250_minval_1024_inclborder_noStreak_yes_cls_balance_yes_pos_neg_balance.zip\"\n",
      "Root dir content: ['.config', 'Patches', 'gdrive', 'adc.json', 'base_model.h5', 'Patches_pos_vs_neg_128_s60_vs22_min1250_minval_1024_inclborder_noStreak_yes_cls_balance_yes_pos_neg_balance.zip', 'model_pos_neg.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "file_id = '1AbZppC-Fe_fVI1mslm7BP8PBSoOu3u36' #Pos_vs_Neg_128_s60_VS_22 .... min1250_minval_1024_inclborder FULL BALANCE\n",
    "\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile(downloaded['title'])\n",
    "print('Downloaded content: \"{}\"'.format(downloaded['title']))\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSdGQav-qEJM"
   },
   "source": [
    "### **Unzip the Patches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jP1-2THkn47w",
    "outputId": "c486c53e-b036-41dc-bbd3-070fc3039d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir content: ['.config', 'Patches', 'gdrive', 'adc.json', 'base_model.h5', 'model_pos_neg.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Remove 'Patches' dir if it already exists\n",
    "if 'Patches' in os.listdir():\n",
    "  shutil.rmtree('./Patches')\n",
    "with zipfile.ZipFile(downloaded['title'],\"r\") as zip:\n",
    "    zip.extractall()\n",
    "os.remove(downloaded['title'])\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nd7htfD3rJ6V"
   },
   "source": [
    "### **Let's count patches by type and location and save class weights in inverse proportion to the number of patches for each class:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "DjJy7FFsvm5H",
    "outputId": "7ed899fd-72a3-40eb-ab97-d2d5d5a49a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_Serial: 45660 = 22830 positive + 22830 negative\n",
      "total_Control: 7420 = 3710 positive + 3710 negative\n",
      "total_Streak: 0 = 0 positive + 0 negative\n",
      "\n",
      "class_weights: {\n",
      "  \"Serial\": {\n",
      "    \"neg\": 2.0,\n",
      "    \"pos\": 2.0\n",
      "  },\n",
      "  \"Control\": {\n",
      "    \"neg\": 2.0,\n",
      "    \"pos\": 2.0\n",
      "  },\n",
      "  \"Streak\": {\n",
      "    \"neg\": 0,\n",
      "    \"pos\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class_weights = {} # empty dictionary to store class weights\n",
    "for type_ in ['Serial', 'Control', 'Streak']:\n",
    "    class_weights[type_] = {} # nested empty dictionary to store class weights\n",
    "    pos_folder = './Patches/{}/pos'.format(type_)\n",
    "    neg_folder = './Patches/{}/neg'.format(type_)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    class_weights[type_]['neg'] = total/n_neg if n_neg else 0\n",
    "    class_weights[type_]['pos'] = total/n_pos if n_pos else 0\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(type_,total,n_pos,n_neg))\n",
    "print('\\nclass_weights:', str(json.dumps(class_weights, indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNJ7lSKQpdOT"
   },
   "source": [
    "#### **Let's build image generators, using keras.preprocessing.image.ImageDataGenerator, rescaling image pixel values from [0,  255] to [0, 1]:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "UANfdA6IUFKt",
    "outputId": "51334524-dc59-4a4c-cd2c-2a38d6cb1470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Found 45660 images belonging to 2 classes.\n",
      "\n",
      "For validation:\n",
      "Found 7420 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "serial_pos_folder = './Patches/Serial/pos'\n",
    "img = plt.imread(serial_pos_folder + '/' + os.listdir(serial_pos_folder)[:5][0])\n",
    "img_size = img.shape\n",
    "train_batch_size = 32\n",
    "val_batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"For training:\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        './Patches/Serial',\n",
    "        target_size=(img_size[0],img_size[1]),\n",
    "        batch_size=train_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "print(\"\\nFor validation:\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        './Patches/Control',\n",
    "        target_size=(img_size[0],img_size[1]),\n",
    "        batch_size=val_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44ZzUGXvwqUn"
   },
   "source": [
    "#### **Let's check what is the train generators' index for each class, so we can correclty set up the class weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tSHQNC2awn84",
    "outputId": "f11f5196-e5ac-4d0d-ae1a-873a01d88451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_generator.class_indices: {\n",
      "  \"neg\": 0,\n",
      "  \"pos\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('train_generator.class_indices:', str(json.dumps(train_generator.class_indices, indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o30MT4e2O7gk"
   },
   "source": [
    "#### **Let's set up the class weights in correct order:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "U2gsR9n6w2vm",
    "outputId": "e38d3491-3ddf-4505-a0fe-777180475bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class weights dictionary:\n",
      "{\n",
      "  \"neg\": 2.0,\n",
      "  \"pos\": 2.0\n",
      "}\n",
      "class weights for generator, re-arranging indexes:\n",
      "[\n",
      "  2.0,\n",
      "  2.0\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "serial_pos_weights = []\n",
    "classes = ['neg','pos']\n",
    "for cls in classes:\n",
    "    serial_pos_weights.append(class_weights['Serial']['{}'.format(cls)])\n",
    "print('original class weights dictionary:')\n",
    "print(str(json.dumps(class_weights['Serial'], indent=2, default=str)))\n",
    "print('class weights for generator, re-arranging indexes:')\n",
    "print(str(json.dumps(serial_pos_weights, indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdXBPBsVxA39"
   },
   "source": [
    "## **Let's build our Base Model. We will use Resnet:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjNmNKdHw4tM"
   },
   "source": [
    "#### **First. let's create a function to build a residual block.**\n",
    "\n",
    "#### We will use the residual block proposed in  [ResNetV2](https://arxiv.org/pdf/1603.05027.pdf) and will implement it by ourselves:\n",
    "\n",
    "\n",
    ">![Google's logo](https://camo.githubusercontent.com/7ae470c333cd76078e1c669055ad98bcedaf523f/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3130303532332f61313536613563322d303236622d646535352d613666622d6534666131373732623432632e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-DqZH20w3ji"
   },
   "outputs": [],
   "source": [
    "def res_block(X, filters, kernel_size=(3,3), l2_reg=1e-6, residual=True,\n",
    "              first=False, subsampling=False):\n",
    "    \"\"\"\n",
    "    Function to build a residual block as proposed in ResNetV2:\n",
    "             https://arxiv.org/pdf/1603.05027.pdf:\n",
    "    :param X: The input to the residual block\n",
    "    :param filters: Integer. Number of filters / channels in the output\n",
    "    :param kernel_size: Tuple (Int, Int). kernel size for convolution operations\n",
    "    :param l2_reg: Float. L2 norm for L2 regularization\n",
    "    :param residual: Boolean. True if residual block. Otherwise 'plain' block.\n",
    "    :param first: Boolean. True if first residual block -> ZeroPad and Maxpool.\n",
    "    :param subsampling: Boolean. True if subsampling within the residual block.\n",
    "    :return: the addition output from the residual block proposed in ResNetV2:\n",
    "              https://arxiv.org/pdf/1603.05027.pdf\n",
    "    \"\"\"\n",
    "    bn = BatchNormalization()(X)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "    \n",
    "    if first: #The first layer is subsampled with Maxpool\n",
    "      pad = ZeroPadding2D(padding=(1, 1))(relu)\n",
    "      relu = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(pad)    \n",
    "    \n",
    "    if subsampling: #Resnet reduces size just by using stride=2 instead of pool\n",
    "      #Here we will reduce the size (subsample) by using stride 2 \n",
    "      conv_1 = Conv2D(filters, kernel_size, strides=(2,2), padding='same',\n",
    "                         kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                         kernel_initializer = glorot_uniform(0),\n",
    "                         bias_initializer = glorot_uniform(0))(relu)\n",
    "      if residual:\n",
    "        #To be able to add, we also need to reduce size of input\n",
    "        #For this, we will just use a 1x1 Conv2D with stride 2  \n",
    "        res = Conv2D(filters, kernel_size=[1,1], strides=(2,2),\n",
    "                     padding='same')(X)\n",
    "    else: #No subsampling, same size as input\n",
    "      conv_1 = Conv2D(filters, kernel_size, strides=(1,1), padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                   kernel_initializer = glorot_uniform(0),\n",
    "                   bias_initializer = glorot_uniform(0))(relu)\n",
    "      if residual:\n",
    "        if first: #The first layer is subsampled with Maxpool so, resize X\n",
    "          #For this, we will just use a 1x1 Conv2D with stride 2\n",
    "          res = Conv2D(filters, kernel_size=[1,1], strides=(2,2),\n",
    "                     padding='same')(X)\n",
    "        else:\n",
    "          res = X\n",
    "    bn = BatchNormalization()(conv_1)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "\n",
    "    conv_2 = Conv2D(filters, kernel_size, padding='same',\n",
    "                       kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                       kernel_initializer = glorot_uniform(0),\n",
    "                       bias_initializer = glorot_uniform(0))(relu)\n",
    "    if residual:\n",
    "      add = keras.layers.add([res, conv_2])\n",
    "      return add\n",
    "    else:\n",
    "      return conv_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0K3-02NNUXOV"
   },
   "source": [
    "#### **Second, let's create a function to build a Resnet network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32s7rai-609p"
   },
   "outputs": [],
   "source": [
    "#from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "\n",
    "def make_resnet(img_size, n_classes, layers_per_group, n_filters, \n",
    "                    kernel_sizes, l2_reg=1e-6, optimizer=keras.optimizers.SGD,\n",
    "                    lr=1e-1, decay=1e-4, momentum=0.9, residual=True):\n",
    "  \n",
    "    \"\"\"\n",
    "    Function to build ResNet network, but with some user defined parameters.\n",
    "        \n",
    "        ResNet network input size is (224,224,3) then it starts with one \n",
    "        convolution layer, (7x7x64, stride 2) followed by maxpool (3x3, stride2) \n",
    "        then it will build 4 layer groups and the user will define the number of\n",
    "        residual layers per group.\n",
    "        \n",
    "        As example, ResNet34, after the first convolution layer, it has 4 groups\n",
    "        of layers with the following number of residual 'layers_per_group':\n",
    "        [6,8,12,6]\n",
    "        Because the residual connections are made between pair of layers, the\n",
    "        number of layers for each group must be a pair number.\n",
    "        \n",
    "        The user will also be able to define the number of filters and size of\n",
    "        each filter, independently for each group of layers. All layers in the\n",
    "        same group group will have the same number of filters and each filter\n",
    "        within the group will have the same size.\n",
    "        \n",
    "        Same as ResNet, an average pooling layer follows after the 4 groups\n",
    "        of layers.\n",
    "    \n",
    "    :param img_size: Size of input image, in the form: (size, size, #channels)\n",
    "    :param n_classes: Integer. Number of classes for classification.\n",
    "    :param layers_per_group: List with # of layers per group (e.g.[6,8,12,6])\n",
    "    :param n_filters: List of length 4, with number of filters for each group of\n",
    "                      layers.\n",
    "    :param kernel_sizes: List of length 4, with kernel sizes tuples for each \n",
    "                          group of layers\n",
    "    :param l2_reg: Float. L2 norm for L2 regularization\n",
    "    :param optimizer: A keras optimizer from keras.optimizers\n",
    "    :param lr: Float. learning rate for the optimizer.\n",
    "    :param decay: Float. learning rate decay for the optimizer.\n",
    "    :param momentum: Float. Momentum for SGD if optimizer=keras.optimizers.SGD\n",
    "    :param residual: Boolean. True if residual net. Otherwise 'plain' net.\n",
    "    :return: CNN with residual connections, similar to ResNet32\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(layers_per_block) != len(n_filters) or len(layers_per_block) !=\\\n",
    "        len(kernel_sizes) or len(n_filters) != len(n_filters):\n",
    "        e = \"Length of 'layers_per_block', 'n_filters' and 'kernel_sizes'\" +\\\n",
    "        \" must be the same\"\n",
    "        raise Exception(e)  \n",
    "\n",
    "    for layers in layers_per_block:\n",
    "      if layers % 2 == 1:\n",
    "        e = \"Number of 'layers_per_block' must be even/pair numbers\"\n",
    "        raise Exception(e)\n",
    "      \n",
    "    inputs = Input(shape=img_size)\n",
    "    \n",
    "    n_filters_conv1 = 64\n",
    "    kernel_sizes_conv1 = (3,3)\n",
    "    #kernel_sizes_conv1 = (5,5)\n",
    "    #kernel_sizes_conv1 = (7,7)\n",
    "    strides_conv1 = (2,2)\n",
    "    \n",
    "    conv1 = Conv2D(n_filters_conv1, kernel_sizes_conv1, strides=strides_conv1,\n",
    "                   padding='same', kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                   kernel_initializer = glorot_uniform(0),\n",
    "                   bias_initializer = glorot_uniform(0))(inputs)\n",
    "    \n",
    "    layer_count = 1 # counter for the number of layers\n",
    "    \n",
    "   \n",
    "    for i in range(len(layers_per_block)):\n",
    "      for j in range(int(layers_per_block[i]/2)):\n",
    "        if j == 0:\n",
    "          if i == 0:\n",
    "            add = res_block(conv1, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                            residual, first=True)\n",
    "            #add = res_block(conv0_1, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "            #                residual, subsampling=True)\n",
    "          else:\n",
    "            add = res_block(add, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                            residual, subsampling=True)\n",
    "        else:\n",
    "          add = res_block(add, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                          residual)\n",
    "          \n",
    "    bn = BatchNormalization()(add)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "\n",
    "    #pool = AveragePooling2D(pool_size=(2 ,2), padding='same')(relu)\n",
    "    #flat = Flatten()(pool)\n",
    "    flat = GlobalAveragePooling2D()(relu)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                      kernel_initializer=glorot_uniform(0),\n",
    "                      bias_initializer=glorot_uniform(0))(flat)\n",
    "\n",
    "    res_cnn = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "    if optimizer == keras.optimizers.Nadam:\n",
    "        res_cnn.compile(optimizer(lr=lr, schedule_decay=decay),\n",
    "                    \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    elif optimizer == keras.optimizers.SGD:\n",
    "        res_cnn.compile(optimizer(lr=lr, momentum=momentum, decay=decay),\n",
    "                        \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    else:\n",
    "        res_cnn.compile(optimizer(lr=lr, decay=decay),\n",
    "                        \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return res_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nR0XHpb2gtN"
   },
   "source": [
    "### **Let's build a ResNet18:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8FawwuFI2rLe",
    "outputId": "0b21a8e3-9af5-44cb-f5ff-a24a59b202a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           add_9[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  73856       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 128)  512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  8320        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 128)  147584      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  147584      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 256)    295168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 256)    33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 256)    590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 512)    1180160     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 512)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 512)    131584      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 512)    2359808     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 512)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 512)    2359808     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 512)    2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 512)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 512)    2359808     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 512)    0           add_15[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 512)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            1026        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,184,834\n",
      "Trainable params: 11,177,026\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = list(iter(train_generator.class_indices))\n",
    "n_classes = len(classes)\n",
    "layers_per_block = [4, 4, 4, 4] #18 layers total with first conv and last FC\n",
    "n_filters = [64, 128, 256, 512]\n",
    "kernel_sizes = [(3,3), (3,3), (3,3), (3,3)]\n",
    "l2_reg = 0.1\n",
    "optimizer = RMSprop # Adamax, RMSprop, Adam (No: Nadam, SGD)\n",
    "lr = 1e-3\n",
    "decay = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "res_cnn = make_resnet(img_size, n_classes, layers_per_block, n_filters,\n",
    "                       kernel_sizes, l2_reg, optimizer, lr, decay, momentum)\n",
    "res_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBJOgDlhm60I"
   },
   "source": [
    "#### **Let's mount our GoogleDrive so we can later download the best model:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1q3nGK-zmxSQ",
    "outputId": "03ff29ee-8ee9-4a5f-b186-cc655ee58a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUL3HGj4dyft"
   },
   "source": [
    "### **Let's train and validate our Base Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fOLUaLTymmjv",
    "outputId": "579e4e03-d529-4319-afa9-3acf4f97a04d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1426/1426 [==============================] - 64s 45ms/step - loss: 2.6357 - acc: 0.9579 - val_loss: 0.2189 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99470, saving model to base_model.h5\n",
      "Epoch 2/50\n",
      "1426/1426 [==============================] - 59s 42ms/step - loss: 0.1929 - acc: 0.9863 - val_loss: 0.1700 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99470\n",
      "Epoch 3/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.1457 - acc: 0.9909 - val_loss: 0.2336 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99470\n",
      "Epoch 4/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.1207 - acc: 0.9937 - val_loss: 0.1352 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99470\n",
      "Epoch 5/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.1104 - acc: 0.9947 - val_loss: 0.1096 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99470\n",
      "Epoch 6/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0982 - acc: 0.9961 - val_loss: 0.1194 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99470\n",
      "Epoch 7/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0900 - acc: 0.9967 - val_loss: 0.1048 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99470\n",
      "Epoch 8/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0817 - acc: 0.9978 - val_loss: 0.0880 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99470 to 0.99606, saving model to base_model.h5\n",
      "Epoch 9/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0796 - acc: 0.9974 - val_loss: 0.0814 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99606\n",
      "Epoch 10/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0746 - acc: 0.9979 - val_loss: 0.0966 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99606\n",
      "Epoch 11/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0716 - acc: 0.9983 - val_loss: 0.0957 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99606\n",
      "Epoch 12/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0690 - acc: 0.9984 - val_loss: 0.0783 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99606\n",
      "Epoch 13/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0650 - acc: 0.9989 - val_loss: 0.0746 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.99606 to 0.99660, saving model to base_model.h5\n",
      "Epoch 14/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0639 - acc: 0.9987 - val_loss: 0.0733 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99660 to 0.99687, saving model to base_model.h5\n",
      "Epoch 15/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0612 - acc: 0.9987 - val_loss: 0.0686 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99687\n",
      "Epoch 16/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0594 - acc: 0.9988 - val_loss: 0.0669 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99687\n",
      "Epoch 17/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0587 - acc: 0.9988 - val_loss: 0.0658 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99687 to 0.99728, saving model to base_model.h5\n",
      "Epoch 18/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0569 - acc: 0.9989 - val_loss: 0.0669 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99728\n",
      "Epoch 19/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0561 - acc: 0.9989 - val_loss: 0.0632 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99728\n",
      "Epoch 20/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0549 - acc: 0.9990 - val_loss: 0.1416 - val_acc: 0.9970\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99728\n",
      "Epoch 21/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0544 - acc: 0.9987 - val_loss: 0.0593 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99728\n",
      "Epoch 22/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0540 - acc: 0.9989 - val_loss: 0.0635 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99728\n",
      "Epoch 23/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0523 - acc: 0.9989 - val_loss: 0.0577 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99728\n",
      "Epoch 24/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0510 - acc: 0.9991 - val_loss: 0.0597 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99728\n",
      "Epoch 25/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0502 - acc: 0.9991 - val_loss: 0.0611 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99728\n",
      "Epoch 26/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0497 - acc: 0.9989 - val_loss: 0.0623 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99728\n",
      "Epoch 27/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0493 - acc: 0.9989 - val_loss: 0.0698 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99728\n",
      "Epoch 28/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0483 - acc: 0.9991 - val_loss: 0.0599 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99728\n",
      "Epoch 29/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0479 - acc: 0.9991 - val_loss: 0.0564 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99728\n",
      "Epoch 30/50\n",
      "1426/1426 [==============================] - 59s 41ms/step - loss: 0.0470 - acc: 0.9993 - val_loss: 0.0681 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99728\n",
      "Epoch 31/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0469 - acc: 0.9993 - val_loss: 0.0541 - val_acc: 0.9970\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99728\n",
      "Epoch 32/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0464 - acc: 0.9993 - val_loss: 0.0559 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99728\n",
      "Epoch 33/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0466 - acc: 0.9991 - val_loss: 0.0599 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99728\n",
      "Epoch 34/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0463 - acc: 0.9992 - val_loss: 0.0715 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007225000590551645.\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99728\n",
      "Epoch 35/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0442 - acc: 0.9995 - val_loss: 0.0530 - val_acc: 0.9970\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99728\n",
      "Epoch 36/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0438 - acc: 0.9995 - val_loss: 0.0583 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99728\n",
      "Epoch 37/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0433 - acc: 0.9994 - val_loss: 0.0592 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99728\n",
      "Epoch 38/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0430 - acc: 0.9994 - val_loss: 0.0534 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0006141250254586339.\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99728\n",
      "Epoch 39/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0429 - acc: 0.9995 - val_loss: 0.0583 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99728\n",
      "Epoch 40/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0426 - acc: 0.9994 - val_loss: 0.0536 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99728\n",
      "Epoch 41/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0426 - acc: 0.9993 - val_loss: 0.0591 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005220062914304435.\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99728\n",
      "Epoch 42/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0421 - acc: 0.9993 - val_loss: 0.0543 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99728\n",
      "Epoch 43/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0415 - acc: 0.9995 - val_loss: 0.0531 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99728\n",
      "Epoch 44/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0414 - acc: 0.9995 - val_loss: 0.0535 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00044370535761117935.\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99728\n",
      "Epoch 45/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0410 - acc: 0.9996 - val_loss: 0.0593 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99728\n",
      "Epoch 46/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0407 - acc: 0.9995 - val_loss: 0.0553 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99728\n",
      "Epoch 47/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0415 - acc: 0.9993 - val_loss: 0.0548 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00037714955396950245.\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99728\n",
      "Epoch 48/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0409 - acc: 0.9994 - val_loss: 0.0543 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99728\n",
      "Epoch 49/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0407 - acc: 0.9994 - val_loss: 0.0544 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99728\n",
      "Epoch 50/50\n",
      "1426/1426 [==============================] - 58s 41ms/step - loss: 0.0401 - acc: 0.9995 - val_loss: 0.0551 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003205771208740771.\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99728\n"
     ]
    }
   ],
   "source": [
    "#Pos_vs_Neg_128_s60_VS_22 .... min1250_minval_1024_inclborder FULL BALANCE\n",
    "\n",
    "## No Rotations\n",
    "## train_batch_size = 32\n",
    "\n",
    "## 128x128 stride_60\n",
    "## min_pos_pix_1250, mivalpos_1024\n",
    "## INCLUDING dish_border on training images\n",
    "## l2_reg = 0.1\n",
    "## lr = 1e-3  \n",
    "## opt_RMSprop, first_Kernel:3x3 (original ResNet is 7x7)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "val_steps = val_generator.n//val_generator.batch_size\n",
    "\n",
    "# Callbacks:\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=3, \n",
    "                                   verbose=1, mode='min', min_lr=1e-9)\n",
    "EarlyStop = EarlyStopping(monitor='val_acc', patience=70, verbose=1,\n",
    "                          min_delta=0, mode='max')\n",
    "checkpoint = ModelCheckpoint('base_model.h5', monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [reduce_lr, checkpoint, EarlyStop] #order matters!\n",
    "\n",
    "#res_cnn.load_weights('base_model.h5')\n",
    "\n",
    "history = res_cnn.fit_generator(train_generator, steps_per_epoch=train_steps,\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=val_steps, epochs=epochs,\n",
    "                            verbose=1, callbacks=callbacks_list, shuffle=False,\n",
    "                            class_weight=serial_pos_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oM6Pg4p8ZFcp"
   },
   "source": [
    "#### **Let's download the best model to our 'Capstone' folder in GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uzutbAnER5y8",
    "outputId": "b3998bf9-1030-4fea-8936-ddfe66ebf3d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gdrive/My Drive/Capstone/model_pos_neg_2.h5'"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = './base_model.h5'\n",
    "dest = 'gdrive/My Drive/Capstone/model_pos_neg_2.h5'\n",
    "shutil.copyfile(source, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRz_1oJzJRFH"
   },
   "source": [
    "#### **Let's download the training history to a local file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5Y5GUUhcyAt"
   },
   "outputs": [],
   "source": [
    "for k,v in history.history.items():\n",
    "  history.history[k] = str(v)\n",
    "\n",
    "with open('history_dict.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "try:\n",
    "    time.sleep(3) # To avoid warning when downloading various files at once\n",
    "    files.download('history_dict.json')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxEpvYPVcyUb"
   },
   "outputs": [],
   "source": [
    "#uploaded = files.upload()\n",
    "with open('history_dict.json') as f:\n",
    "    history_dict = json.load(f)\n",
    "    \n",
    "for k,v in history_dict.items():\n",
    "  history_dict[k] = json.loads(v)\n",
    "\n",
    "history_df = pd.DataFrame(history_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eAC27OxKOLY"
   },
   "source": [
    "#### **Let's plot training and validation loss vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "h3brS64myvSD",
    "outputId": "454c46f2-7572-4677-fc9a-e5e5857e7df7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6fecaa0e48>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF1CAYAAADMXG9eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debxddX3v/9dn77P32edkIgmBQEAG\nZRQUSlQQrVp7/SGi+FABcYTrvVSqFXvVltrW6Wp/9nH7s71eEa5WHLiIIjhQxWsdsFitSkAEmRHB\nJCCEzMmZ9vD9/bHWGZKc5JzkHNhrxdfz8diPNe61vmvvQ3jv7/e7vitSSkiSJGnPVLpdAEmSpDIz\nTEmSJM2AYUqSJGkGDFOSJEkzYJiSJEmaAcOUJEnSDBimJGkWRcQLI2JVt8sh6cljmJK0SxHxYET8\ncbfLIUlFZZiSJEmaAcOUpD0WEf81Iu6PiHURcV1EHJivj4j4x4h4LCI2RcTtEXFcvu30iLgzIjZH\nxOqIePckx+2NiA2j78nXLYmIwYjYLyL2jYhv5vusi4gfRcSk/55FxNER8d18v3si4uwJ2z4XEZfl\n2zdHxL9FxCETtj83Im6KiI359LkTti2KiM9GxMMRsT4ivr7ded+VX/8jEXH+hPVTXr+kcjFMSdoj\nEfFHwP8LnA0cADwEfCnf/BLgD4EjgQX5PmvzbZ8B/iSlNA84DvjB9sdOKQ0DXwXOnbD6bODfUkqP\nAe8CVgFLgP2B9wI7PBsrIuYA3wW+COwHvBb4ZEQcO2G31wP/HdgXuBW4Mn/vIuBbwMeBxcDHgG9F\nxOL8fVcA/cDT82P/44RjLs2vexnwFuCSiFg43euXVC6GKUl76vXA5SmlW/Lw81fAKRFxKNAE5gFH\nA5FSuiul9Ej+viZwbETMTymtTyndspPjf5Es/Ix6Xb5u9BgHAIeklJoppR+lyR80egbwYErpsyml\nVkrpF8C1wFkT9vlWSunG/Br+Or+Gg4GXAfellK7I33sVcDfw8og4AHgp8Nb8GpoppX+bcMwm8KF8\n/fXAFuCo3bx+SSVhmJK0pw4kq40CIKW0haz2aVlK6QfAJ4BLgMci4lMRMT/f9dXA6cBDebPaKTs5\n/g1Af0Q8Jw9oJwBfy7f9D+B+4F8j4oGIuHgnxzgEeE7eHLghIjaQhcClE/ZZud01rMuvbZvryz1E\nVtt0MLAupbR+J+ddm1JqTVgeAObm89O9fkklYZiStKceJgsrwFiT2mJgNUBK6eMppZOAY8ma+96T\nr78ppXQmWdPY14GrJzt4Sqmdbzs3f30zpbQ537Y5pfSulNLhwCuA/xYRL57kMCvJmgb3mfCam1K6\ncMI+B0+4hrnAovzatrm+3FPy61sJLIqIfab6kCa5rmldv6TyMExJmo5aRDQmvHqAq4DzI+KEiOgF\n/g74WUrpwYh4Vl6jVAO2AkNAJyLqEfH6iFiQUmoCm4DOLs77ReAcstqk0SY+IuKMiHhaRASwEWjv\n5DjfBI6MiDdGRC1/PSsijpmwz+kR8byIqJP1nfppSmklcH3+3tdFRE9EnEMWDL+ZN1l+m6z/1cL8\nuH841Ye4B9cvqQQMU5Km43pgcMLrAyml7wF/S9YH6RHgqYz3cZoPfBpYT9Y0tpasaQ7gjcCDEbEJ\neCtZUJpUSulnZGHsQLLwMuoI4HtkfZH+A/hkSumGSd6/mawz/GvJapp+B/w90Dthty8C7ydr3jsJ\neEP+3rVkfa7elZf/L4AzUkqPT7iOJlk/qseAd+7sOrYz7euXVA4xeZ9NSdr7RcTngFUppb/pdlkk\nlZc1U5IkSTNgmJIkSZoBm/kkSZJmwJopSZKkGTBMSZIkzUBPt0687777pkMPPbRbp5ckSZq2m2++\n+fGU0pLJtnUtTB166KGsWLGiW6eXJEmatojY/vFSY2zmkyRJmgHDlCRJ0gwYpiRJkmaga32mJEnS\n7Gg2m6xatYqhoaFuF6X0Go0GBx10ELVabdrvMUxJklRyq1atYt68eRx66KFERLeLU1opJdauXcuq\nVas47LDDpv0+m/kkSSq5oaEhFi9ebJCaoYhg8eLFu13DZ5iSJGkvYJCaHXvyORqmJEmSZsAwJUmS\nZmzDhg188pOf3O33nX766WzYsGG333feeedxzTXX7Pb7ngiGKUmSNGM7C1OtVmuX77v++uvZZ599\nnqhiPSm8m0+SpL3IB//lDu58eNOsHvPYA+fz/pc/fZf7XHzxxfz617/mhBNOoFar0Wg0WLhwIXff\nfTf33nsvr3zlK1m5ciVDQ0NcdNFFXHDBBcD44+W2bNnCS1/6Up73vOfxk5/8hGXLlvGNb3yDvr6+\nKcv3/e9/n3e/+920Wi2e9axncemll9Lb28vFF1/MddddR09PDy95yUv4h3/4B77yla/wwQ9+kGq1\nyoIFC7jxxhtn/Pl0LUxtHtp1UpUkSeXx0Y9+lF/96lfceuut/PCHP+RlL3sZv/rVr8aGGLj88stZ\ntGgRg4ODPOtZz+LVr341ixcv3uYY9913H1dddRWf/vSnOfvss7n22mt5wxvesMvzDg0Ncd555/H9\n73+fI488kje96U1ceumlvPGNb+RrX/sad999NxEx1pT4oQ99iO985zssW7Zsj5oXJ9O1MPXbdQPd\nOrUkSXutqWqQnizPfvaztxmr6eMf/zhf+9rXAFi5ciX33XffDmHqsMMO44QTTgDgpJNO4sEHH5zy\nPPfccw+HHXYYRx55JABvfvObueSSS3j7299Oo9HgLW95C2eccQZnnHEGAKeeeirnnXceZ599Nq96\n1atm41K712eqkxIppW6dXpIkPYHmzJkzNv/DH/6Q733ve/zHf/wHv/zlLznxxBMnHcupt7d3bL5a\nrU7Z32pXenp6+PnPf85rXvMavvnNb3LaaacBcNlll/HhD3+YlStXctJJJ7F27do9PsfYuWZ8hBkY\nbnVo1KrdLIIkSZoF8+bNY/PmzZNu27hxIwsXLqS/v5+7776bn/70p7N23qOOOooHH3yQ+++/n6c9\n7WlcccUVvOAFL2DLli0MDAxw+umnc+qpp3L44YcD8Otf/5rnPOc5POc5z+Hb3/42K1eu3KGGbHd1\nNUwNjrQNU5Ik7QUWL17MqaeeynHHHUdfXx/777//2LbTTjuNyy67jGOOOYajjjqKk08+edbO22g0\n+OxnP8tZZ5011gH9rW99K+vWrePMM89kaGiIlBIf+9jHAHjPe97DfffdR0qJF7/4xTzzmc+ccRmi\nW01tvQcckX5z120cuM/UvfQlSdLO3XXXXRxzzDHdLsZeY7LPMyJuTiktn2z/ro4zNTDS7ubpJUmS\nZqyrzXxDTcOUJEnaube97W38+Mc/3mbdRRddxPnnn9+lEu2ou32mDFOSJGkXLrnkkm4XYUo280mS\nJM1AV8PUoGFKkiSVXHfDVNNHykiSpHLrcs1Up5unlyRJmrEu95myZkqSpN9Hc+fO3em2Bx98kOOO\nO+5JLM3MTBmmIuLgiLghIu6MiDsi4qJJ9nlhRGyMiFvz1/umc3KHRpAkSWU3naERWsC7Ukq3RMQ8\n4OaI+G5K6c7t9vtRSumM6Z448G4+SZJm3bcvht/dPrvHXHo8vPSju9zl4osv5uCDD+Ztb3sbAB/4\nwAfo6enhhhtuYP369TSbTT784Q9z5pln7taph4aGuPDCC1mxYgU9PT187GMf40UvehF33HEH559/\nPiMjI3Q6Ha699loOPPBAzj77bFatWkW73eZv//ZvOeecc/b4sqdryjCVUnoEeCSf3xwRdwHLgO3D\n1G6JCMeZkiRpL3HOOefwzne+cyxMXX311XznO9/hHe94B/Pnz+fxxx/n5JNP5hWveAURMe3jXnLJ\nJUQEt99+O3fffTcveclLuPfee7nsssu46KKLeP3rX8/IyAjtdpvrr7+eAw88kG9961tA9oDlJ8Nu\nDdoZEYcCJwI/m2TzKRHxS+Bh4N0ppTsmef8FwAUAjaVPtZlPkqTZNkUN0hPlxBNP5LHHHuPhhx9m\nzZo1LFy4kKVLl/Lnf/7n3HjjjVQqFVavXs2jjz7K0qVLp33cf//3f+fP/uzPADj66KM55JBDuPfe\neznllFP4yEc+wqpVq3jVq17FEUccwfHHH8+73vUu/vIv/5IzzjiD5z//+U/U5W5j2h3QI2IucC3w\nzpTSpu023wIcklJ6JvC/gK9PdoyU0qdSSstTSst7qlWb+SRJ2oucddZZXHPNNXz5y1/mnHPO4cor\nr2TNmjXcfPPN3Hrrrey///4MDQ3Nyrle97rXcd1119HX18fpp5/OD37wA4488khuueUWjj/+eP7m\nb/6GD33oQ7NyrqlMK0xFRI0sSF2ZUvrq9ttTSptSSlvy+euBWkTsu8sTRzhopyRJe5FzzjmHL33p\nS1xzzTWcddZZbNy4kf32249arcYNN9zAQw89tNvHfP7zn8+VV14JwL333stvf/tbjjrqKB544AEO\nP/xw3vGOd3DmmWdy22238fDDD9Pf388b3vAG3vOe93DLLbfM9iVOaspmvsgaNj8D3JVS+thO9lkK\nPJpSShHxbLKQtnZXx61UfDafJEl7k6c//els3ryZZcuWccABB/D617+el7/85Rx//PEsX76co48+\nereP+ad/+qdceOGFHH/88fT09PC5z32O3t5err76aq644gpqtRpLly7lve99LzfddBPvec97qFQq\n1Go1Lr300ifgKncUKaVd7xDxPOBHwO3A6Cib7wWeApBSuiwi3g5cSHbn3yDw31JKP9nVcRcfekx6\n0V9+hmsufO7MrkCSpN9zd911F8ccc0y3i7HXmOzzjIibU0rLJ9t/Onfz/TvZSAa72ucTwCd2o5xU\nwqERJElS+e3W3XyzKSK8m0+SpN9jt99+O2984xu3Wdfb28vPfjbZoAHF1bUwVYmwZkqSpFmSUtqt\n8ZuK4Pjjj+fWW2/tdjG2MVX3p8l07dl8lbADuiRJs6HRaLB27do9CgIal1Ji7dq1NBqN3XpfV2um\nDFOSJM3cQQcdxKpVq1izZk23i1J6jUaDgw46aLfe09UwNdLq0O4kqpVyVUtKklQktVqNww47rNvF\n+L3VvWa+/MzWTkmSpDLrWpga7SQ3MNLqVhEkSZJmrKsd0AGGRjq73lGSJKnAuhim8pqppjVTkiSp\nvLoepnzYsSRJKrOuN/MZpiRJUpl1v2bKu/kkSVKJdT1M+UgZSZJUZl0cGiGbWjMlSZLKrIuDdmZp\nasgwJUmSSqzrHdBt5pMkSWXW9T5T3s0nSZLKrGthCqBRq9hnSpIklVpXw1R/vceaKUmSVGpdDVN9\ntap9piRJUql1N0zVq97NJ0mSSq0ANVM+6FiSJJVX18OUHdAlSVKZdb2Zb7DZ6WYRJEmSZqT7NVM2\n80mSpBLr8tAINvNJkqRy6+6gnfWq40xJkqRS627NVM0wJUmSyq3rHdAHmm1SSt0shiRJ0h7rephK\nCYZb3tEnSZLKqet38wE29UmSpNIqRpjyjj5JklRSXW/mA3zYsSRJKq1C1Ez5sGNJklRWXR60swew\nmU+SJJVXl5v5stPbzCdJksqqy818ec2UYUqSJJVUITqgDzZ92LEkSSqnrj/oGGBwxEE7JUlSOXX3\nQce10aERrJmSJEnl5NAIkiRJM9DVMFXvqdBTCe/mkyRJpdXVMAVZ7ZTjTEmSpLLqfpiqV23mkyRJ\npVWIMGUznyRJKqvuh6la1UE7JUlSaXU/TNXtMyVJksqr62Gqv27NlCRJKq8pw1REHBwRN0TEnRFx\nR0RcNMk+EREfj4j7I+K2iPiD6Ragr2afKUmSVF4909inBbwrpXRLRMwDbo6I76aU7pywz0uBI/LX\nc4BL8+mU+uo93s0nSZJKa8qaqZTSIymlW/L5zcBdwLLtdjsT+ELK/BTYJyIOmE4B+moVa6YkSVJp\n7VafqYg4FDgR+Nl2m5YBKycsr2LHwEVEXBARKyJixZo1awAH7ZQkSeU27TAVEXOBa4F3ppQ27cnJ\nUkqfSiktTyktX7JkCZA18xmmJElSWU0rTEVEjSxIXZlS+uoku6wGDp6wfFC+bkp9tSojrQ7tTprO\n7pIkSYUynbv5AvgMcFdK6WM72e064E35XX0nAxtTSo9MpwD99SqAtVOSJKmUpnM336nAG4HbI+LW\nfN17gacApJQuA64HTgfuBwaA86dbgEYepgZGWsztnU5xJEmSimPK9JJS+ncgptgnAW/bkwL017Iw\nNTTS2ZO3S5IkdVXXR0DvG62Zara6XBJJkqTdV5gw5SNlJElSGXU/TNUMU5IkqbyKE6a8m0+SJJVQ\n18NU/9jdfIYpSZJUPl0PUw1rpiRJUol1PUyN1kwNGaYkSVIJdT1M9dnMJ0mSSqzrYarR4918kiSp\nvLoepiqVoFGr2GdKkiSVUtfDFEB/vceaKUmSVEqFCFN9tap9piRJUikVIkw1ahXv5pMkSaVUiDDV\nX+9hYMQHHUuSpPIpRJjqq1XtgC5JkkqpGGGqXmWw2el2MSRJknZbMcJUrcqgzXySJKmEChGm+us2\n80mSpHIqRJhq1KuOMyVJkkqpEGGqv2aYkiRJ5VSIMNVXrzLQbJNS6nZRJEmSdkthwlRKMNzyjj5J\nklQuxQhTtSqATX2SJKl0ihWmvKNPkiSVTDHCVD0LUz7sWJIklU0xwlReM+XDjiVJUtkUIkz113sA\nm/kkSVL5FCJM9dWzYtjMJ0mSyqYYYaqW10wZpiRJUskUI0zVR+/m82HHkiSpXAoRpvpHw9SIg3ZK\nkqRyKUSYatRGh0awZkqSJJVLIcKUQyNIkqSyKkSYqvdU6KmEd/NJkqTSKUSYgqx2ynGmJElS2RQn\nTNWrNvNJkqTSKVSYsplPkiSVTXHCVK3qoJ2SJKl0ihOm6vaZkiRJ5VOYMNVft2ZKkiSVT2HCVF/N\nPlOSJKl8ChOmGjXv5pMkSeVTmDDV7918kiSphAoTphy0U5IklVFxwlS9xw7okiSpdIoTpmpVRtod\nWu1Ot4siSZI0bYUJU/31KgBDLcOUJEkqj8KEqUYepgZGWl0uiSRJ0vRNGaYi4vKIeCwifrWT7S+M\niI0RcWv+et+eFKS/ltdMjVgzJUmSyqNnGvt8DvgE8IVd7POjlNIZMylI32jNVNOaKUmSVB5T1kyl\nlG4E1j3RBRkNU97RJ0mSymS2+kydEhG/jIhvR8TTd7ZTRFwQESsiYsWaNWu22dZXM0xJkqTymY0w\ndQtwSErpmcD/Ar6+sx1TSp9KKS1PKS1fsmTJNtvGwpQDd0qSpBKZcZhKKW1KKW3J568HahGx7+4e\np3/sbj7DlCRJKo8Zh6mIWBoRkc8/Oz/m2t09TsOaKUmSVEJT3s0XEVcBLwT2jYhVwPuBGkBK6TLg\nNcCFEdECBoHXppTS7hZkbNBOw5QkSSqRKcNUSuncKbZ/gmzohBnps5lPkiSVUHFGQO/xbj5JklQ+\nhQlTlUrQqFXsMyVJkkqlMGEKoL/eY82UJEkqlUKFqb5a1T5TkiSpVAoVphq1infzSZKkUilUmOqv\n9zAw4oOOJUlSeRQqTPXVqnZAlyRJpVKsMFWvMtjsdLsYkiRJ01asMFWrMmgznyRJKpFChan+us18\nkiSpXAoVphr1quNMSZKkUilUmOqvGaYkSVK5FCpM9dWrDDTbpJS6XRRJkqRpKVSYatSqpATDLe/o\nkyRJ5VCoMNVfrwLY1CdJkkqjUGGqr5aHKe/okyRJJVGsMJXXTPmwY0mSVBbFClN5zZQPO5YkSWVR\nqDDVX+8BbOaTJEnlUagw1VfPimMznyRJKotihalaXjNlmJIkSSVRrDA1OjRC04cdS5KkcihUmBof\nZ8pBOyVJUjkUKkw1aqNDI1gzJUmSyqFQYcqhESRJUtkUKkzVeyr0VMK7+SRJUmkUKkxBVjvlOFOS\nJKksihem6lWb+SRJUmkUMkzZzCdJksqieGGqVnXQTkmSVBrFC1N1+0xJkqTyKFyY6q9bMyVJksqj\ncGGqr2afKUmSVB6FC1ONmnfzSZKk8ihcmOr3bj5JklQihQtTDtopSZLKpHhhqt5jB3RJklQaxQtT\ntSoj7Q6tdqfbRZEkSZpS4cJUf70KwFDLMCVJkoqvcGGqkYepgZFWl0siSZI0tcKFqf5aXjM1Ys2U\nJEkqvsKFqb7RmqmmNVOSJKn4ihem8pop7+iTJEllULwwVTdMSZKk8ihemBqtmXLgTkmSVAKFC1P9\nY3fzGaYkSVLxFS5MNayZkiRJJVK4MDU2aKdhSpIklcCUYSoiLo+IxyLiVzvZHhHx8Yi4PyJui4g/\nmEmB+mzmkyRJJTKdmqnPAaftYvtLgSPy1wXApTMpUKPHu/kkSVJ5TBmmUko3Aut2scuZwBdS5qfA\nPhFxwB4XqBI0ahX7TEmSpFKYjT5Ty4CVE5ZX5et2EBEXRMSKiFixZs2anR6wv95jzZQkSSqFJ7UD\nekrpUyml5Sml5UuWLNnpfn21qn2mJElSKcxGmFoNHDxh+aB83R5r1CrezSdJkkphNsLUdcCb8rv6\nTgY2ppQemckB++s9DIz4oGNJklR8PVPtEBFXAS8E9o2IVcD7gRpASuky4HrgdOB+YAA4f6aF6qtV\n7YAuSZJKYcowlVI6d4rtCXjbrJWIbKypDQMjs3lISZKkJ0ThRkAHa6YkSVJ5FDJM9dcNU5IkqRwK\nGaYa9arjTEmSpFIoZJjqrxmmJElSORQyTPXVqww022R92yVJkoqrkGGqUauSEgy3Ot0uiiRJ0i4V\nMkz116sANvVJkqTCK2SY6qvlYco7+iRJUsEVM0zlNVM+7FiSJBVdMcNUXjPlw44lSVLRFTJM9dez\np9zYzCdJkoqukGGqr54Vy2Y+SZJUdMUMU7W8ZsowJUmSCq6YYWp0aIRmq8slkSRJ2rVihqnRoRFG\nHLRTkiQVWzHD1NjQCNZMSZKkYitmmHJoBEmSVBKFDFP1ngo9lfBuPkmSVHiFDFOQ1U45zpQkSSq6\n4oapetVmPkmSVHiFDlM280mSpKIrbpiqVR20U5IkFV5xw1TdPlOSJKn4Chum+uvWTEmSpOIrbJjq\nq9lnSpIkFV9hw1Sj5t18kiSp+Aobpvq9m0+SJJVAYcOUg3ZKkqQyKG6YqvfYAV2SJBVeccNUrcpI\nu0Or3el2USRJknaqsGGqv14FYKhlmJIkScVV2DDVyMPUwEiryyWRJEnaucKGqf5aXjM1Ys2UJEkq\nrsKGqb7RmqmmNVOSJKm4ihum8pop7+iTJElFVtwwVTdMSZKk4itumBqtmXLgTkmSVGCFDVP9Y3fz\nGaYkSVJxFTZMNayZkiRJJVDYMDU2aKdhSpIkFVhhw1SfzXySJKkEChumGj3ezSdJkoqvsGGqUgka\ntYp9piRJUqEVNkxBNjyCNVOSJKnICh2m+us99pmSJEmFVugw1ahVvJtPkiQVWqHDVFYz5YOOJUlS\ncRU6TPXVqnZAlyRJhTatMBURp0XEPRFxf0RcPMn28yJiTUTcmr/+y2wUrq9uB3RJklRsPVPtEBFV\n4BLgPwGrgJsi4rqU0p3b7frllNLbZ7NwfbUqj1gzJUmSCmw6NVPPBu5PKT2QUhoBvgSc+cQWK9Nf\nt5lPkiQV23TC1DJg5YTlVfm67b06Im6LiGsi4uDJDhQRF0TEiohYsWbNmilP3LCZT5IkFdxsdUD/\nF+DQlNIzgO8Cn59sp5TSp1JKy1NKy5csWTLlQfsdtFOSJBXcdMLUamBiTdNB+boxKaW1KaXhfPGf\ngZNmo3B99SoDzTYppdk4nCRJ0qybTpi6CTgiIg6LiDrwWuC6iTtExAETFl8B3DUbhWvUqqQEw63O\nbBxOkiRp1k15N19KqRURbwe+A1SBy1NKd0TEh4AVKaXrgHdExCuAFrAOOG82CtdfrwIwONKmUavO\nxiElSZJm1ZRhCiCldD1w/Xbr3jdh/q+Av5rdomVDIwAMNtssnO2DS5IkzYJij4Ce10z5sGNJklRU\nxQ5Tec2UDzuWJElFVegw1V/PWiEduFOSJBVVocNUXz0rns18kiSpqIodpmp5zZRhSpIkFVSxw9To\n0AjNVpdLIkmSNLlih6nRoRFGHLRTkiQVU7HD1NjQCNZMSZKkYip2mHJoBEmSVHCFDlP1ngo9lfBu\nPkmSVFiFDlOQ1U45zpQkSSqq4oepetVmPkmSVFilCFM280mSpKIqfpiqVR20U5IkFVbxw1TdPlOS\nJKm4ih+mrJmSJEkFVvgw1W+fKUmSVGCFD1ONmnfzSZKk4ip8mLJmSpIkFVnhw5SDdkqSpCIrfpiq\n99gBXZIkFVbxw1Styki7Q6vd6XZRJEmSdlD4MNVfrwIw1DJMSZKk4il8mGrkYWpgpNXlkkiSJO2o\n8GGqv5bXTI1Mo2Zq/UPwpdfDde+AtuFLkiQ98Xq6dubW0LR26xutmWruIhy1W/Czy+CGj0DqZMce\n2giv/meo1majtJIkSZPqXs3UY3fDV86HR+/c5W59ec3UTu/o+93t8Jk/hn/9azjsD+HPboaXfATu\n/Dpc85+h3ZztkkuSJI3pXpiaux/c969w6Snw5TfCI7dNuttozdQOYao5CN99P/zvF8DGVfCay+Hc\nL8GCg+C5b4fTPgp3XQdfOQ9aI0/wxUiSpN9X3QtT8w+Ed94Of/gX8MAP4X8/H646F1bfss1uYzVT\nEwfufODf4JOnwI//CU44F972czju1RAxvs/JF8JL/wfc/U24+k3QGn4SLkqSJP2+6W4H9P5F8Ed/\nnYWqF74XHvoxfPpFcOVZsPImAPbpz/o8feBf7uDLN95G66sXwhdekb3/TdfBmZdkx5nMcy6Al/1/\ncO+3s9qv5vT6aUmSJE1XpJS6cuLly5enFStWbLtyaBPc9Gn4ySdgcB0c/iJ4wV/yvS2H8Yv/eznn\nbbqUhbGF257yZo4460PMmzd/eidb8Vn45jvhaX8M51wJtcbsX5AkSdprRcTNKaXlk24rVJgaNbwF\nVnwGfvxxGHgcFh4K6x9ky6Lj+bueP+WLv13A/EYPbzrlUM4/9VAWz+2d+oQ3fx7+5SI4/IVw7lVQ\n65vFq5EkSXuz8oWpUSMDcPNn4VdfheNeBc/+E6j28MuVG/jkD+/nO3c8SqNW4bXPegoX/OHhHLjP\nFAHpF/8HvvH27K6/c78E9a51oDYAABNTSURBVP7ZuyBJkrTXKm+YmsL9j23m0h8+wDduXQ3AK09c\nxltf8FSett/cnb/p1qvg6xfCoc+D130Z6nNmVAZJkrT322vD1KhV6wf49I0P8KWbVjLS7nDK4Yt5\n7lMXc/Lhi3nGQftQ79mun/1tV8PX/gSecgq87mro3UX4ksqm04Zf/yD7wWBztiTNir0+TI16fMsw\nn//Jg3z3zke5+3ebAWjUKiw/ZBEnH76IU566mOOX5eHq9mvgq/8VDjwRnvVf4NDnwz4Hz2p5pCfd\n1rVw7X/Ohhs58ER47RezYUgkSTPyexOmJlq/dYSf/WYdP31gLT99YO1YuOqrVVl+6EJOPnwxp1V+\nyuE/ez8x8Hj2poWHZf2pDvvDLFzN2/8JK58061bfko2ptuWxbFiQFZ+F+twsUB10UrdLJ0ml9nsZ\npra3busIP//NWn76wLptwlW9mjh5zmO8sPduTurczlFDt9FobwFgYMERNJ9yKr1HvJDG016w7XhW\nnTZsfRy2/A42P7rdNH+lDiw6HBY/FRY/DRY9FRYfDn0Ln7Tr1u+JW66Ab70re7LA2V+AZX8Aj94B\nV702+7s88xJ4xlndLqUklZZhahKj4eqXqzby6MYhfrdpiEc3DbFm0yCHjNzPcyt3cErlTp5VuZs5\nMUwnBQ9UD6VS7WFxWs+81noqTPK8wL6FMHdpXqsVsO4B2PBbYMLn3L84D1ZPy8LV6Py+R9jHRbun\nNQzf/gu4+XPZsB+vvhzmLB7fvvXxrLbqoR/D8/4c/uh9UOnuWL2SVEaGqd20ZbjFo5uGeHTjEI9u\n2Exa/Qv2+d1P2H/DLxhswarWfFY25/NoWsiatA+PpX1YV1lIz/wD2G/hfJYt7OOghX0csKDBojm9\nLG4k9m/9joVDD9G3+SFi7f1ZyFp7P2x+ZPzEUcmaGvc7BpYcnU33OwYWHwE99Sf+wgc3ZOVqN6FS\nzR7PExWIaj6t5Osr46++faxp65aNq+HqN8Lqm/Og9LfZ97O91gh8+z1Z4DrqdHjVp6B33pNeXEkq\nM8PUE2BgpMXDGwZZtT57rd4wyOr1g6xaP8DqDYM8tnmYyT7aWjVYNKfOwv46i+fWWdrX5ojqYxzC\nwyxrPcR+g79hweb7aWx+iEh5zVdUs5qr/Y6GJXnAWnAwNBZkYaaxAKq16RW83YT1D8Ha++Dx+/Lp\n/dl065o9+zDmHQD7HZuVa/+nZ/NLjrKW7Yn0mxvhK+dDawheeSkc+4pd758S/PzT8H8vzr6bc6/K\nBsOVJE2LYaoLhltt1mweZt3WEdZuHWHdlpHx+a0T1ufbNg+3tnl/nSaHxyMcXV3FM2oPc3R1NYen\nlezXfoQKO35nI9V+mrX5jNTm06zNp12fT6u+gHbvAqrVKnO3PkT/pt9Q3/wQ0Zlwrv7FsO+R482M\ni56ahaDUGX912hOW29n/mEeXtzwKj94Jj90Ja+6Bdv5A6ahk/cX2OzYPWHltW++87Pg9fdDTu+3D\nqTW1lOA/PgHffX/WF++c/5OFo+n69Q3wlTdnAf2cK7LhEyRJUzJMlcBwq836rU3WjgatLePBa3x+\nhM2bN7Fg4EEWNB9nbtrKgtjKAvJpbGU+204XsJUe2jyU9ueBdCAPpAOyV+cAHoxlNOsLmNvbw5zR\nV71KX61KvadCb0+F3p4qvbVsvj66PLqtVqVezdbXqhUalQ7zB1cyb9N9zNt0L/3r76Gx/h5qGx8k\nJgmAEFmwGg1XtcaE+b6stq3Sk/2Pv1KZMF/N5yvj85VaNgBrfU52B9vofO/cbZfrc6HWD9V6dvwy\nhbnhLXDd2+GOr8ExL89qpPakuW7tr+GL58D638Dp/wDLz5/9spbVyED2XNDWMMxZkn2+Zfob6ZaU\nYGAdbFwJG1dlP5SWHg9z9/fz017DMLWXSinRbCea7Q6tdqLZ6YzNj4yua3cYbrYZaLbZOtxiy3A2\n3TrSyqbDbbYMtxgYGd823Goz3Oww3Oow3Goz0srmh5ptOnvw59JgmCNiNYfFI8yJIRqMMK/aZG61\nxdxKkzmVEforTfqjSV8M02CEPkao0qKSOlRpU6FDJXWo0M6nHSqpTeTL1dSk1h6kQmf3PsOoQKVG\nqlSzQFatQaVKVGpQzUJaVKrjgW60/9jYukn6k3XaWQ1eZ0Jt3ti60Zq9fL5a3zFE1vqgp5GFvonb\nfnEFPH4vvPh9cOo7Z/Y/qcENcO1b4P7vwbMvgP/n76A9As1BGNmaTZtbs3CxzfwAdFpZKO2dB435\n0Ltgwvz8rLx7UraUsmN3WtlnM3Ga2hO2dcbnxz7Tznaf8STrh7dkQWlgbfY//rH59fn8OmgNblum\n2pzsZpK5S2Fe/pq7f9a0PbZ+f6jPy/5edtfw5qzv28ZV40Fk7LUyK9P8A7Na3kWHw6LD8tfhsOAp\ne3bO3ZVS9jew+ZHtyjhxfvWOnx1A/75ZqFp6HCx9Rja/+Ignp9zSLDNMada02lmwGg1Yw612Ftjy\ndSOtDs12YqSdhbCRdhpbP9JqM9jsMNhsM9RsMzjSZmAknx9dbrYZGmkz0GzRaic6KdHukE+z5U4n\n0U6JTmJsPvszTvTSZA5D9McQcxjK54ezKUPMiWxao00PbXqiTY021dHlia8YnXao0qFKokKHaqR8\nuUNl4jyJCokUQYoKiSqdPGilqGbBbWyazffQop6Gt3nVOvk0DVPvDI8FxC3VBVx9yAd4cMGzqURQ\nrWSvSgQ9laBSCaoRVCtQqQRBZPcQAJWIsXwTEdk62iy/95847rdXzOrfSCd66NTn0qnPo1OfRwDR\naWWvlE3pNPN1zSwUtZvjfQSfcJHdNNG/KGvm7luUzy8an6/2wtbHdhzuZPPvsmA5mUrPeA3r2LQx\nIRzn09bQeBgZ2rhd0aowfxksWAYLDsrKs2k1rPtNdnPIxMBS6YF9npLdtDIatGr9E0Jn9rlmgbS5\n4/JoeG6OBuYJ86PBeXTdZDXLc5dmZRx7HZxPl2Xv/93t8Ojt2fSxu8e7AFR7s2b/0YC1+KlZTeDw\n5vy1KQu+Y8v5upF8Xbs5/oNkYneEseA8oRtCpZoF/NGgv810Xj6/IJv2zh3/MTGyJSvDyOhra768\neXw+KpPXhu+wPDcLjyNbYWjThGvauO01jm4b2ZL9qBs7ztxJatnz+d65eXeJ0Rr67X74jdXiT1hH\nyj4jUv61TlwenXbGQ/Twpuw1tJPp6HxrOP8x2J9N6/3j87Xt5/vGf3wS4zc7kf+DxejNTzHJ/PbT\n0W2Mr5vUJH/Do/ln+7+jHV7ZZxIv+ivDlPZunU5WGzcW6tqjga89Icx1GM7Xt9qJViebtjtZrV67\nk9X0tTudfJpodbLllKCTstrATh7eOol8PpFgLPi1O6M1hYlWuzN2zFZnYi1itm3iMcePR76c6LQT\n1dSknkYYSDWGUw/t0WA5Gio7jK3bEy+p3MTTKw8xmOoM0MsgvQym3h3mB+hlKPXSpMpcBpkXg8xl\ngHkxyLxtpgNj2+eR/c+/SZUW1WyaemhTydf1jG1rUaWVqrSzOknaeUTtRBZX23kQ7VDN1uXzKbJ9\nsqhboU0WVrP3VbJgG1UGabCxMp+tMYcUlW3C5mjAZEL4rEQeUCtQjSDyADsnDbIorWNRWs/izjoW\ndtbTSINZGGaEemeEOlkQrjNMrTOSh+Ns2ooa62tLWV/bjw21/dlQ25+Nvfuzqb4/W2r7EtUeKjFe\nhjEpMa/5OItGVrFoeDWLhlexMJ8uGlpFo7OTkJdrR5VO9GQhv9JDO3poVRo0q41sWumjWWnQqvbS\nrDSy+dH11QZb6vuyuXcpm3uXsrW+hHa1N//ssuNvE94rQa0a1KoVeqoV6rRYNPhbFm25h4Wb7mHB\npnuYt+Eu6sPrJi1rih7a9Xm0a3No17Jg3q7NpVObmzfPj9YGV4AqVCKvNY68JjnbHp0WlZHNE16b\nqAyPT6MzssvPLFUbdOpzSPU5pNpcUn0uqZYtBxDNrdlrZLtpc2DXx63NIfXOJ/XOI9XnkXqzcJfq\n80j1udmPjZEtRHMrlZEt0NxKDGfLo2Ev2rsu+6yL6nZhdMG2y9V6FqiaE4L4WC334LbrmwNZ8J20\n+0dxxQc37TRMWdeqvUKlEjQqVRq1SYYG+D2R8kA2WoOXEiRGp+NBjR3W//H4D7T812qCHd6fRo+Z\noLVN+JwYRrNpFlazwDga9EYDYOpkAbTSyV49nUQljc+nxFjN46RBs5MmDbJpQrkhC5mj5e/k13Jg\nGv/ne/S921xf9taxMDtaKzqxZnSk08/DqZ9VnWW0K/k1bf95TTgmY2XKto+VvQXtkbRNgG531m5z\n3dsH5GxpSf46YcL/ixIL2EwtNWlSpZkqNFN1bL6VKvlnMF6WnRkPR6PLMfZ5ZWcaJKXfTvn3OLmD\n89cfA4klbOCQeJRBGmymjy2pj600GKYGg098X6teRpjHIPNigH6GGKLOQGqwlezVpgq7zqiTCjr0\nMTJWS16nxZbUxxay6+sMVWDzzMpeo0U/Q2Q/bzp5TXqHnkhZbXpea16LDj2Rra/SyWrOgcR4LU4i\n8hd5/Xq2bTjqbKWfrTGHYepEM6AZxFbGgvT2P0pg24qiidsBohZEbfzfpE6nQ+pkNT/ZvzHZj9dI\n7Xw5AR0qQCVS9iODNDYfJKqRsh8gZNM0es6JQX9CwcaX888hKkTeopC1JIwvR2RtDtm1vWCn34dh\nStpLRATVgGrFDr/atdFgPLHpd0+Pk023DaSjtbqtdmes/+ZYX87Otv06W+3ODmEUdgy4kwXVTr5x\nYmAeDaZMOObY/CRhmgnHH91v9PzbLm97rRM37rDvTtZP+3MdLV8aD+DbhvXxdZ2xzyiNfQZj+4/+\n2OiM/+jY5jy7KNe2PzZ2/LGSti/ThH1HL2Kb73DCZ5dSHopitAvC+HylwrbLE8L86Dk6E8u2k89p\nQjF2WoaJf1vb//iCiT/oJnznOzGtMBURpwH/E6gC/5xS+uh223uBLwAnAWuBc1JKD07n2JKkJ1dM\n6EM30+Nk07E1APweVxBrL3bFW3a+bcrnSkREFbgEeClwLHBuRBy73W5vAdanlJ4G/CPw93taWEmS\npDKZzkO6ng3cn1J6IKU0AnwJOHO7fc4EPp/PXwO8OPa03liSJKlEphOmlgErJyyvytdNuk9KqQVs\nBBYjSZK0l3tSHx8fERdExIqIWLFmzR4+B06SJKlAphOmVpPdyzrqoHzdpPtERA+wgKwj+jZSSp9K\nKS1PKS1fsmTJnpVYkiSpQKYTpm4CjoiIwyKiDrwWuG67fa4D3pzPvwb4QerWaKCSJElPoimHRkgp\ntSLi7cB3yIZGuDyldEdEfAhYkVK6DvgMcEVE3A+sIwtckiRJe71pjTOVUroeuH67de+bMD8EnDW7\nRZMkSSq+J7UDuiRJ0t7GMCVJkjQDhilJkqQZMExJkiTNgGFKkiRpBqJbw0FFxGbgnq6cXLNpX+Dx\nbhdCM+b3uHfwe9w7+D0W0yEppUlHHJ/W0AhPkHtSSsu7eH7NgohY4fdYfn6Pewe/x72D32P52Mwn\nSZI0A4YpSZKkGehmmPpUF8+t2eP3uHfwe9w7+D3uHfweS6ZrHdAlSZL2BjbzSZIkzUBXwlREnBYR\n90TE/RFxcTfKoN0XEZdHxGMR8asJ6xZFxHcj4r58urCbZdSuRcTBEXFDRNwZEXdExEX5er/HEomI\nRkT8PCJ+mX+PH8zXHxYRP8v/bf1yRNS7XVZNLSKqEfGLiPhmvuz3WDJPepiKiCpwCfBS4Fjg3Ig4\n9skuh/bI54DTtlt3MfD9lNIRwPfzZRVXC3hXSulY4GTgbfl/f36P5TIM/FFK6ZnACcBpEXEy8PfA\nP6aUngasB97SxTJq+i4C7pqw7PdYMt2omXo2cH9K6YGU0gjwJeDMLpRDuymldCOwbrvVZwKfz+c/\nD7zySS2UdktK6ZGU0i35/Gayf8CX4fdYKimzJV+s5a8E/BFwTb7e77EEIuIg4GXAP+fLgd9j6XQj\nTC0DVk5YXpWvUzntn1J6JJ//HbB/Nwuj6YuIQ4ETgZ/h91g6edPQrcBjwHeBXwMbUkqtfBf/bS2H\nfwL+Aujky4vxeywdO6Br1qTs1lBvDy2BiJgLXAu8M6W0aeI2v8dySCm1U0onAAeR1fgf3eUiaTdF\nxBnAYymlm7tdFs1MNx4nsxo4eMLyQfk6ldOjEXFASumRiDiA7FeyCiwiamRB6sqU0lfz1X6PJZVS\n2hARNwCnAPtERE9eq+G/rcV3KvCKiDgdaADzgf+J32PpdKNm6ibgiPxuhTrwWuC6LpRDs+M64M35\n/JuBb3SxLJpC3h/jM8BdKaWPTdjk91giEbEkIvbJ5/uA/0TW/+0G4DX5bn6PBZdS+quU0kEppUPJ\n/l/4g5TS6/F7LJ2uDNqZp/B/AqrA5SmljzzphdBui4irgBeSPdH8UeD9wNeBq4GnAA8BZ6eUtu+k\nroKIiOcBPwJuZ7yPxnvJ+k35PZZERDyDrGNylexH8dUppQ9FxOFkN/UsAn4BvCGlNNy9kmq6IuKF\nwLtTSmf4PZaPI6BLkiTNgB3QJUmSZsAwJUmSNAOGKUmSpBkwTEmSJM2AYUqSJGkGDFOSJEkzYJiS\nJEmaAcOUJEnSDPz/32w/Xp6/LXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_df[['loss','val_loss']]\n",
    "loss.columns = ['train_loss', 'val_loss']\n",
    "loss.plot(figsize=(10, 6), title='Loss vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSFAqg-gKlR0"
   },
   "source": [
    "#### **Let's plot training and validation accuracy vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "MxBp7usry3eo",
    "outputId": "e1dc7f54-a04e-4554-dcf1-442d7c69fa84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6fec9a7ba8>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAF1CAYAAADbfv+XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_df[['val_acc','acc']]\n",
    "acc.columns = ['val_acc', 'train_acc']\n",
    "acc.plot(figsize=(10, 6), title='Val acc & Train acc vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8RiTO3yLDXy"
   },
   "source": [
    "#### **Let's plot learning rate vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "mxKKNDsm0UCy",
    "outputId": "7326b068-98ed-44bc-bc49-39969567a7df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f704ea18be0>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAF1CAYAAABChiYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = history_df[['lr']]\n",
    "lr.plot(figsize=(10, 6), title='Learning rate vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEjAnQK9Mhfy"
   },
   "source": [
    "#### **Let's evaluate the best model on the validation set and compute relevant metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cH-tFKnoMjpw"
   },
   "outputs": [],
   "source": [
    "res_cnn.load_weights('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "_GWSA3vCzAqe",
    "outputId": "dcee2e18-efa6-4a15-a9f1-a4282ed42322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc:\n",
      " 0.9973045822102425\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3690   20]\n",
      " [   0 3710]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.99      1.00      3710\n",
      "         pos       0.99      1.00      1.00      3710\n",
      "\n",
      "    accuracy                           1.00      7420\n",
      "   macro avg       1.00      1.00      1.00      7420\n",
      "weighted avg       1.00      1.00      1.00      7420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pos_vs_Neg_128_s60_VS_22 .... min1250_minval_1024_inclborder FULL BALANCE\n",
    "\n",
    "## No Rotations\n",
    "## train_batch_size = 32\n",
    "\n",
    "## 128x128 stride_60\n",
    "## min_pos_pix_1250, mivalpos_1024\n",
    "## INCLUDING dish_border on training images\n",
    "## l2_reg = 0.1\n",
    "## lr = 1e-3  \n",
    "## opt_RMSprop, first_Kernel:3x3 (original ResNet is 7x7)\n",
    "\n",
    "X, y_true = next(val_generator)\n",
    "y_pred = res_cnn.predict(X)\n",
    "for i in range(1, len(val_generator)):\n",
    "  X, y = next(val_generator)\n",
    "  y_true = np.vstack((y_true, y))\n",
    "  y_pred = np.vstack((y_pred, res_cnn.predict(X)))\n",
    "\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "#roc_auc = roc_auc_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = [k for k in val_generator.class_indices]\n",
    "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "print('\\nval_acc:\\n', val_acc)\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', c_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yh7d39ioBHt"
   },
   "source": [
    "## **Let's evaluate the best model, when loaded from GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cVZz7DkUzVlL",
    "outputId": "3570dbe4-43e8-4d96-bc22-4ad2d1634a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded content: \"model_pos_neg_2.h5\"\n",
      "Root dir content: ['.config', 'Patches', 'gdrive', 'model_pos_neg_2.h5', 'adc.json', 'base_model.h5', 'model_pos_neg.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "file_id = '1-BxPnguFXE7PHmzKadW0AnwWO9VqTywR' # model pos vs neg\n",
    "\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile(downloaded['title'])\n",
    "print('Downloaded content: \"{}\"'.format(downloaded['title']))\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "up9Dz57kzV4F"
   },
   "outputs": [],
   "source": [
    "final_model = load_model(downloaded['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ydyLjGW6zWL8",
    "outputId": "9bafb220-db7a-4cd9-bb91-970b7ff23ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc:\n",
      " 0.9973045822102425\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3690   20]\n",
      " [   0 3710]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.99      1.00      3710\n",
      "         pos       0.99      1.00      1.00      3710\n",
      "\n",
      "    accuracy                           1.00      7420\n",
      "   macro avg       1.00      1.00      1.00      7420\n",
      "weighted avg       1.00      1.00      1.00      7420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## entire model loaded from GoogleDrive (not just weights)\n",
    "\n",
    "X, y_true = next(val_generator)\n",
    "y_pred = final_model.predict(X)\n",
    "for i in range(1, len(val_generator)):\n",
    "  X, y = next(val_generator)\n",
    "  y_true = np.vstack((y_true, y))\n",
    "  y_pred = np.vstack((y_pred, final_model.predict(X)))\n",
    "\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "#roc_auc = roc_auc_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = [k for k in val_generator.class_indices]\n",
    "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "print('\\nval_acc:\\n', val_acc)\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', c_report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pos_vs_neg_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
