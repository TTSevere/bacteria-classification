{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:red\">**This Notebook can be run from Google Colab:**</span>\n",
    "\n",
    "https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from google.colab import files\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization,\\\n",
    "                          Conv2D, MaxPooling2D, Flatten, AveragePooling2D,\\\n",
    "                          GlobalAveragePooling2D, ZeroPadding2D\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam, Adamax, Nadam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, \\\n",
    "                            classification_report\n",
    "\n",
    "# Import PyDrive and associated libraries (to connect with GoogleDrive)\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DItexGaqdfEA"
   },
   "source": [
    "### **Check if we are using GPU:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vn7AYx74dNq6",
    "outputId": "7a172a70-061a-4c1d-b341-4acaf8bf51c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 1.15.0 , GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "if K.backend() == \"tensorflow\":\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name == '':\n",
    "        device_name = \"None\"\n",
    "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQXfhMrHlqrz"
   },
   "source": [
    "### **Download Patches from GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "ACvUlEucnnY0",
    "outputId": "a8e974a9-b913-4037-f408-8c1fb971ef70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded content: \"Patches_new_128_s60_vs22_min1250_minval_1024_pos_only_no_border_nonNeg_rot_45_135_225_315.zip\"\n",
      "Root dir content: ['.config', 'Patches', 'gdrive', 'base_model_C4-7_C5_08223.h5', 'adc.json', 'Patches_new_128_s60_vs22_min1250_minval_1024_pos_only_no_border_nonNeg_rot_45_135_225_315.zip', 'base_model.h5', 'base_model_C4-7_C5_082875.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "file_id = '14JL8bMdA66NdcKxl9bnBsiKfyD_n6xfX' #NEW 128x128_s60_no border_minpospix_1250 minposval_1024 ROTATIONS_45,135,225,315\n",
    "\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile(downloaded['title'])\n",
    "print('Downloaded content: \"{}\"'.format(downloaded['title']))\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSdGQav-qEJM"
   },
   "source": [
    "### **Unzip the Patches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jP1-2THkn47w",
    "outputId": "a852a79f-be07-4038-e749-3a0995694354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir content: ['.config', 'Patches', 'gdrive', 'base_model_C4-7_C5_08223.h5', 'adc.json', 'base_model.h5', 'base_model_C4-7_C5_082875.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Remove 'Patches' dir if it already exists\n",
    "if 'Patches' in os.listdir():\n",
    "  shutil.rmtree('./Patches')\n",
    "with zipfile.ZipFile(downloaded['title'],\"r\") as zip:\n",
    "    zip.extractall()\n",
    "os.remove(downloaded['title'])\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nd7htfD3rJ6V"
   },
   "source": [
    "### **Let's count patches by type and class:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "colab_type": "code",
    "id": "DjJy7FFsvm5H",
    "outputId": "44581e7a-1b91-45b1-b344-aeb51c28801a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 'Serial' Patches per location:\n",
      "total_C1: 2969 = 2969 positive + 0 negative\n",
      "total_C2-3: 5649 = 5649 positive + 0 negative\n",
      "total_C4-7: 12233 = 12233 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_C6: 3373 = 3373 positive + 0 negative\n",
      "total_C8: 4438 = 4438 positive + 0 negative\n",
      "total_C9: 2066 = 2066 positive + 0 negative\n",
      "total_C10: 7816 = 7816 positive + 0 negative\n",
      "Total Serial: 44606 = 44606 positive + 0 negative\n",
      "\n",
      "Total 'Control' Patches per location:\n",
      "total_C1: 364 = 364 positive + 0 negative\n",
      "total_C2-3: 364 = 364 positive + 0 negative\n",
      "total_C4-7: 364 = 364 positive + 0 negative\n",
      "total_C5: 364 = 364 positive + 0 negative\n",
      "total_C6: 364 = 364 positive + 0 negative\n",
      "total_C8: 364 = 364 positive + 0 negative\n",
      "total_C9: 364 = 364 positive + 0 negative\n",
      "total_C10: 364 = 364 positive + 0 negative\n",
      "Total Control: 2912 = 2912 positive + 0 negative\n",
      "\n",
      "Total 'Streak' Patches per location:\n",
      "total_C1: 0 = 0 positive + 0 negative\n",
      "total_C2-3: 0 = 0 positive + 0 negative\n",
      "total_C4-7: 0 = 0 positive + 0 negative\n",
      "total_C5: 0 = 0 positive + 0 negative\n",
      "total_C6: 0 = 0 positive + 0 negative\n",
      "total_C8: 0 = 0 positive + 0 negative\n",
      "total_C9: 0 = 0 positive + 0 negative\n",
      "total_C10: 0 = 0 positive + 0 negative\n",
      "Total Streak: 0 = 0 positive + 0 negative\n",
      "\n",
      "GRAND TOTAL: 47518 = 47518 positive + 0 negative\n"
     ]
    }
   ],
   "source": [
    "class_weights = {} # empty dictionary to store class weights\n",
    "classes = ['C1','C2-3','C4-7','C5','C6','C8','C9','C10']\n",
    "\n",
    "grand_total, pos_total, neg_total = 0, 0, 0\n",
    "for type in ['Serial', 'Control', 'Streak']:\n",
    "    print(\"\\nTotal '{}' Patches per location:\".format(type))\n",
    "    n_type, type_pos, type_neg = 0, 0, 0\n",
    "    class_weights[type] = {} # nested empty dictionary to store class weights\n",
    "    class_weights[type]['pos'] = {} # nested dictionary to store class weights\n",
    "    class_weights[type]['neg'] = {} # nested dictionary to store class weights\n",
    "    for cls in classes:\n",
    "        pos_folder = './Patches/Positive/{}/{}_pos'.format(type,cls)\n",
    "        neg_folder = './Patches/Negative/{}/{}_neg'.format(type,cls)\n",
    "        n_pos = len(os.listdir(pos_folder))\n",
    "        n_neg = len(os.listdir(neg_folder))\n",
    "        total = n_pos + n_neg\n",
    "        n_type += total\n",
    "        type_pos += n_pos\n",
    "        type_neg += n_neg\n",
    "        print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "        class_weights[type]['pos']['{}'.format(cls)] = 1/n_pos if n_pos else 0\n",
    "        class_weights[type]['neg']['{}'.format(cls)] = 1/n_neg if n_neg else 0\n",
    "    print('Total {}: {} = {} positive + {} negative'.format(type,n_type,type_pos,type_neg))\n",
    "    for loc in class_weights[type]['pos'].keys():\n",
    "        class_weights[type]['pos'][loc] *= type_pos\n",
    "    for loc in class_weights[type]['neg'].keys():\n",
    "        class_weights[type]['neg'][loc] *= type_neg\n",
    "    grand_total += n_type\n",
    "    pos_total += type_pos\n",
    "    neg_total += type_neg\n",
    "print('\\nGRAND TOTAL: {} = {} positive + {} negative'.format(grand_total,pos_total,neg_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TLfSmpKFPLFu"
   },
   "source": [
    "### **Let's downsample training ('Serial') classes to no more than the minimum between 'C4-7' and 'C5':**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "IPt4zNrWPJed",
    "outputId": "34cd4b68-797e-4aeb-92e0-05cc37528290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downsampling training patches:\n",
      "total_C1: 2969 = 2969 positive + 0 negative\n",
      "total_C2-3: 5649 = 5649 positive + 0 negative\n",
      "total_C4-7: 12233 = 12233 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_C6: 3373 = 3373 positive + 0 negative\n",
      "total_C8: 4438 = 4438 positive + 0 negative\n",
      "total_C9: 2066 = 2066 positive + 0 negative\n",
      "total_C10: 7816 = 7816 positive + 0 negative\n",
      "Total Serial: 44606 = 44606 positive + 0 negative\n",
      "\n",
      "After downsampling validation patches:\n",
      "total_C1: 2969 = 2969 positive + 0 negative\n",
      "total_C2-3: 5649 = 5649 positive + 0 negative\n",
      "total_C4-7: 6062 = 6062 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_C6: 3373 = 3373 positive + 0 negative\n",
      "total_C8: 4438 = 4438 positive + 0 negative\n",
      "total_C9: 2066 = 2066 positive + 0 negative\n",
      "total_C10: 6062 = 6062 positive + 0 negative\n",
      "Total Serial: 36681 = 36681 positive + 0 negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_type = 'Serial'\n",
    "print('Before downsampling training patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(train_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(train_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(train_type,n_type,type_pos,type_neg))\n",
    "\n",
    "if totals['C4-7'] < totals['C5']:\n",
    "    minority = 'C4-7'\n",
    "else:\n",
    "    minority = 'C5'\n",
    "n_min = totals[minority]\n",
    "for key, value in totals.items():\n",
    "    #if key != minority and key not in ['C4-7','C5']:\n",
    "    if key != minority:\n",
    "        n_to_delete = max(value-n_min, 0)\n",
    "        root = './Patches/Positive/{}/{}_pos/'.format(train_type,key)\n",
    "        patches = os.listdir(root)\n",
    "        patches_to_delete = np.random.choice(patches, n_to_delete, replace=False)\n",
    "        for patch in patches_to_delete:\n",
    "            pass\n",
    "            os.remove(root + patch)\n",
    "\n",
    "print('After downsampling validation patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(train_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(train_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(train_type,n_type,type_pos,type_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8a8ZcfKKvw5"
   },
   "source": [
    "### **Let's move all patches for classes other than 'C4-7' or 'C5', to a single folder called 'all_other':**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz9V2uuxLM50"
   },
   "outputs": [],
   "source": [
    "for patch_type in ['Positive','Negative']:\n",
    "    if patch_type == 'Positive': sufix = '_pos'\n",
    "    if patch_type == 'Negative': sufix = '_neg'\n",
    "    for type_ in ['Serial', 'Control', 'Streak']:\n",
    "        folder = './Patches/{}/{}/'.format(patch_type,type_)\n",
    "        if 'all_other' + sufix not in os.listdir(folder):\n",
    "            dest = folder + 'all_other' + sufix\n",
    "            os.mkdir(dest)\n",
    "\n",
    "        for cls in classes:\n",
    "            if cls in ['C4-7','C5']: continue\n",
    "            cls_folder = folder + cls + sufix\n",
    "            for patch in os.listdir(cls_folder):\n",
    "                source = cls_folder + '/' + patch\n",
    "                shutil.move(source, dest)\n",
    "            shutil.rmtree(cls_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sPAFxK7REM7"
   },
   "source": [
    "### **Let's count patches by type and class again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "WmKlpYPZRE-_",
    "outputId": "772fbdcf-75c7-4e59-9622-ba58b2e6e1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 'Serial' Patches per location:\n",
      "total_C4-7: 6062 = 6062 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_all_other: 24557 = 24557 positive + 0 negative\n",
      "Total Serial: 36681 = 36681 positive + 0 negative\n",
      "\n",
      "Total 'Control' Patches per location:\n",
      "total_C4-7: 364 = 364 positive + 0 negative\n",
      "total_C5: 364 = 364 positive + 0 negative\n",
      "total_all_other: 2184 = 2184 positive + 0 negative\n",
      "Total Control: 2912 = 2912 positive + 0 negative\n",
      "\n",
      "Total 'Streak' Patches per location:\n",
      "total_C4-7: 0 = 0 positive + 0 negative\n",
      "total_C5: 0 = 0 positive + 0 negative\n",
      "total_all_other: 0 = 0 positive + 0 negative\n",
      "Total Streak: 0 = 0 positive + 0 negative\n",
      "\n",
      "GRAND TOTAL: 39593 = 39593 positive + 0 negative\n"
     ]
    }
   ],
   "source": [
    "class_weights = {} # empty dictionary to store class weights\n",
    "classes = ['C4-7','C5','all_other']\n",
    "grand_total, pos_total, neg_total = 0, 0, 0\n",
    "\n",
    "for type in ['Serial', 'Control', 'Streak']:\n",
    "    print(\"\\nTotal '{}' Patches per location:\".format(type))\n",
    "    n_type, type_pos, type_neg = 0, 0, 0\n",
    "    class_weights[type] = {} # nested empty dictionary to store class weights\n",
    "    class_weights[type]['pos'] = {} # nested dictionary to store class weights\n",
    "    class_weights[type]['neg'] = {} # nested dictionary to store class weights\n",
    "    for cls in classes:\n",
    "        pos_folder = './Patches/Positive/{}/{}_pos'.format(type,cls)\n",
    "        neg_folder = './Patches/Negative/{}/{}_neg'.format(type,cls)\n",
    "        n_pos = len(os.listdir(pos_folder))\n",
    "        n_neg = len(os.listdir(neg_folder))\n",
    "        total = n_pos + n_neg\n",
    "        n_type += total\n",
    "        type_pos += n_pos\n",
    "        type_neg += n_neg\n",
    "        print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "        class_weights[type]['pos']['{}'.format(cls)] = 1/n_pos if n_pos else 0\n",
    "        class_weights[type]['neg']['{}'.format(cls)] = 1/n_neg if n_neg else 0\n",
    "    print('Total {}: {} = {} positive + {} negative'.format(type,n_type,type_pos,type_neg))\n",
    "    for loc in class_weights[type]['pos'].keys():\n",
    "        class_weights[type]['pos'][loc] *= type_pos\n",
    "    for loc in class_weights[type]['neg'].keys():\n",
    "        class_weights[type]['neg'][loc] *= type_neg\n",
    "    grand_total += n_type\n",
    "    pos_total += type_pos\n",
    "    neg_total += type_neg\n",
    "print('\\nGRAND TOTAL: {} = {} positive + {} negative'.format(grand_total,pos_total,neg_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb9BMr39R9LH"
   },
   "source": [
    "### **Since we want to focus on 'C4-7' and 'C5', let's downsample again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "31ZsitULR-Ap",
    "outputId": "c050dcce-fca0-404b-f892-385b4a820cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downsampling training patches:\n",
      "total_C4-7: 6062 = 6062 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_all_other: 24557 = 24557 positive + 0 negative\n",
      "Total Serial: 36681 = 36681 positive + 0 negative\n",
      "\n",
      "After downsampling validation patches:\n",
      "total_C4-7: 6062 = 6062 positive + 0 negative\n",
      "total_C5: 6062 = 6062 positive + 0 negative\n",
      "total_all_other: 6062 = 6062 positive + 0 negative\n",
      "Total Serial: 18186 = 18186 positive + 0 negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_type = 'Serial'\n",
    "print('Before downsampling training patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(train_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(train_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(train_type,n_type,type_pos,type_neg))\n",
    "\n",
    "minority = min(totals, key=totals.get)\n",
    "n_min = totals[minority]\n",
    "for key, value in totals.items():\n",
    "    if key != minority and key not in ['C4-7','C5']:\n",
    "        n_to_delete = value - n_min\n",
    "        root = './Patches/Positive/{}/{}_pos/'.format(train_type,key)\n",
    "        patches = os.listdir(root)\n",
    "        patches_to_delete = np.random.choice(patches, n_to_delete, replace=False)\n",
    "        for patch in patches_to_delete:\n",
    "            pass\n",
    "            os.remove(root + patch)\n",
    "\n",
    "print('After downsampling validation patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(train_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(train_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    class_weights[train_type]['pos']['{}'.format(cls)] = 1/n_pos if n_pos else 0\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(train_type,n_type,type_pos,type_neg))\n",
    "for loc in class_weights[train_type]['pos'].keys():\n",
    "    class_weights[train_type]['pos'][loc] *= type_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_pnI1G0ywLOp"
   },
   "source": [
    "#### **Since we still have slightly imbalanced training data, we have set different class weights to give more importance to the minority classes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "zCcbwQX7mKQq",
    "outputId": "baeefd01-4208-46bf-d728-ca0214eea6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {\n",
      "  \"pos\": {\n",
      "    \"C4-7\": 3.0,\n",
      "    \"C5\": 3.0,\n",
      "    \"all_other\": 3.0\n",
      "  },\n",
      "  \"neg\": {\n",
      "    \"C4-7\": 0,\n",
      "    \"C5\": 0,\n",
      "    \"all_other\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('Class Weights:', str(json.dumps(class_weights['Serial'], indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2gctgbsF-fF"
   },
   "source": [
    "### **Let's downsample positive majority classes in validation ('Control')patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "tJETu-bSF_R8",
    "outputId": "e3bb2fd7-a101-4864-cc6e-13735996587f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downsampling validation patches:\n",
      "total_C4-7: 364 = 364 positive + 0 negative\n",
      "total_C5: 364 = 364 positive + 0 negative\n",
      "total_all_other: 2184 = 2184 positive + 0 negative\n",
      "Total Control: 2912 = 2912 positive + 0 negative\n",
      "\n",
      "After downsampling validation patches:\n",
      "total_C4-7: 364 = 364 positive + 0 negative\n",
      "total_C5: 364 = 364 positive + 0 negative\n",
      "total_all_other: 364 = 364 positive + 0 negative\n",
      "Total Control: 1092 = 1092 positive + 0 negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_type = 'Control'\n",
    "print('Before downsampling validation patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(val_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(val_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(val_type,n_type,type_pos,type_neg))\n",
    "\n",
    "minority = min(totals, key=totals.get)\n",
    "n_min = totals[minority]\n",
    "for key, value in totals.items():\n",
    "    if key != minority:\n",
    "        n_to_delete = value - n_min\n",
    "        root = './Patches/Positive/{}/{}_pos/'.format(val_type,key)\n",
    "        patches = os.listdir(root)\n",
    "        patches_to_delete = np.random.choice(patches, n_to_delete, replace=False)\n",
    "        for patch in patches_to_delete:\n",
    "            os.remove(root + patch)\n",
    "\n",
    "print('After downsampling validation patches:')\n",
    "totals = {}\n",
    "n_type, type_pos, type_neg = 0, 0, 0\n",
    "for cls in classes:\n",
    "    pos_folder = './Patches/Positive/{}/{}_pos'.format(val_type,cls)\n",
    "    neg_folder = './Patches/Negative/{}/{}_neg'.format(val_type,cls)\n",
    "    n_pos = len(os.listdir(pos_folder))\n",
    "    n_neg = len(os.listdir(neg_folder))\n",
    "    total = n_pos + n_neg\n",
    "    n_type += total\n",
    "    type_pos += n_pos\n",
    "    type_neg += n_neg\n",
    "    print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
    "    totals['{}'.format(cls)] = n_pos if n_pos else 0\n",
    "print('Total {}: {} = {} positive + {} negative\\n'.format(val_type,n_type,type_pos,type_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNJ7lSKQpdOT"
   },
   "source": [
    "#### **Let's build image generators, using keras.preprocessing.image.ImageDataGenerator, rescaling image pixel values from [0,  255] to [0, 1]:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "UANfdA6IUFKt",
    "outputId": "0d68afe4-2d71-40cd-b151-830f9548ef5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Found 18186 images belonging to 3 classes.\n",
      "\n",
      "For validation:\n",
      "Found 1092 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "c1_pos_folder = './Patches/Positive/Serial/C5_pos'\n",
    "img = plt.imread(c1_pos_folder + '/' + os.listdir(c1_pos_folder)[:5][0])\n",
    "img_size = img.shape\n",
    "train_batch_size = 32\n",
    "val_batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"For training:\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        './Patches/Positive/Serial',\n",
    "        target_size=(img_size[0],img_size[1]),\n",
    "        batch_size=train_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "print(\"\\nFor validation:\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        './Patches/Positive/Control',\n",
    "        target_size=(img_size[0],img_size[1]),\n",
    "        batch_size=val_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44ZzUGXvwqUn"
   },
   "source": [
    "#### **Let's check what is the training generator's index for each class, so we can correclty set up the class weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "tSHQNC2awn84",
    "outputId": "323511d0-a6f4-43ab-d6e2-95b2c8c08bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_generator.class_indices: {\n",
      "  \"C4-7_pos\": 0,\n",
      "  \"C5_pos\": 1,\n",
      "  \"all_other_pos\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('train_generator.class_indices:', str(json.dumps(train_generator.class_indices, indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o30MT4e2O7gk"
   },
   "source": [
    "#### **Let's set up the class weights in correct order:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "U2gsR9n6w2vm",
    "outputId": "280c97ff-8b0e-4e9a-af01-4fd76df3bce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class weights dictionary:\n",
      "{\n",
      "  \"C4-7\": 3.0,\n",
      "  \"C5\": 3.0,\n",
      "  \"all_other\": 3.0\n",
      "}\n",
      "class weights for generator, re-arranging indexes:\n",
      "[\n",
      "  3.0,\n",
      "  3.0,\n",
      "  3.0\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "serial_pos_weights = []\n",
    "for cls in classes:\n",
    "    serial_pos_weights.append(class_weights['Serial']['pos']['{}'.format(cls)])\n",
    "print('original class weights dictionary:')\n",
    "print(str(json.dumps(class_weights['Serial']['pos'], indent=2, default=str)))\n",
    "print('class weights for generator, re-arranging indexes:')\n",
    "print(str(json.dumps(serial_pos_weights, indent=2, default=str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdXBPBsVxA39"
   },
   "source": [
    "## **Let's build our Base Model. We will use Resnet:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjNmNKdHw4tM"
   },
   "source": [
    "#### **First. let's create a function to build a residual block.**\n",
    "\n",
    "#### We will use the residual block proposed in  [ResNetV2](https://arxiv.org/pdf/1603.05027.pdf) and will implement it by ourselves:\n",
    "\n",
    "\n",
    ">![Google's logo](https://camo.githubusercontent.com/7ae470c333cd76078e1c669055ad98bcedaf523f/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3130303532332f61313536613563322d303236622d646535352d613666622d6534666131373732623432632e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-DqZH20w3ji"
   },
   "outputs": [],
   "source": [
    "def res_block(X, filters, kernel_size=(3,3), l2_reg=1e-6, residual=True,\n",
    "              first=False, subsampling=False):\n",
    "    \"\"\"\n",
    "    Function to build a residual block as proposed in ResNetV2:\n",
    "             https://arxiv.org/pdf/1603.05027.pdf:\n",
    "    :param X: The input to the residual block\n",
    "    :param filters: Integer. Number of filters / channels in the output\n",
    "    :param kernel_size: Tuple (Int, Int). kernel size for convolution operations\n",
    "    :param l2_reg: Float. L2 norm for L2 regularization\n",
    "    :param residual: Boolean. True if residual block. Otherwise 'plain' block.\n",
    "    :param first: Boolean. True if first residual block -> ZeroPad and Maxpool.\n",
    "    :param subsampling: Boolean. True if subsampling within the residual block.\n",
    "    :return: the addition output from the residual block proposed in ResNetV2:\n",
    "              https://arxiv.org/pdf/1603.05027.pdf\n",
    "    \"\"\"\n",
    "    bn = BatchNormalization()(X)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "    \n",
    "    if first: #The first layer is subsampled with Maxpool\n",
    "      pad = ZeroPadding2D(padding=(1, 1))(relu)\n",
    "      relu = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(pad)    \n",
    "    \n",
    "    if subsampling: #Resnet reduces size just by using stride=2 instead of pool\n",
    "      #Here we will reduce the size (subsample) by using stride 2 \n",
    "      conv_1 = Conv2D(filters, kernel_size, strides=(2,2), padding='same',\n",
    "                         kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                         kernel_initializer = glorot_uniform(0),\n",
    "                         bias_initializer = glorot_uniform(0))(relu)\n",
    "      if residual:\n",
    "        #To be able to add, we also need to reduce size of input\n",
    "        #For this, we will just use a 1x1 Conv2D with stride 2  \n",
    "        res = Conv2D(filters, kernel_size=[1,1], strides=(2,2),\n",
    "                     padding='same')(X)\n",
    "    else: #No subsampling, same size as input\n",
    "      conv_1 = Conv2D(filters, kernel_size, strides=(1,1), padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                   kernel_initializer = glorot_uniform(0),\n",
    "                   bias_initializer = glorot_uniform(0))(relu)\n",
    "      if residual:\n",
    "        if first: #The first layer is subsampled with Maxpool so, resize X\n",
    "          #For this, we will just use a 1x1 Conv2D with stride 2\n",
    "          res = Conv2D(filters, kernel_size=[1,1], strides=(2,2),\n",
    "                     padding='same')(X)\n",
    "        else:\n",
    "          res = X\n",
    "    bn = BatchNormalization()(conv_1)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "\n",
    "    conv_2 = Conv2D(filters, kernel_size, padding='same',\n",
    "                       kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                       kernel_initializer = glorot_uniform(0),\n",
    "                       bias_initializer = glorot_uniform(0))(relu)\n",
    "    if residual:\n",
    "      add = keras.layers.add([res, conv_2])\n",
    "      return add\n",
    "    else:\n",
    "      return conv_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0K3-02NNUXOV"
   },
   "source": [
    "#### **Second, let's create a function to build a Resnet network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32s7rai-609p"
   },
   "outputs": [],
   "source": [
    "#from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "\n",
    "def make_resnet(img_size, n_classes, layers_per_group, n_filters, \n",
    "                    kernel_sizes, l2_reg=1e-6, optimizer=keras.optimizers.SGD,\n",
    "                    lr=1e-1, decay=1e-4, momentum=0.9, residual=True):\n",
    "  \n",
    "    \"\"\"\n",
    "    Function to build ResNet network, but with some user defined parameters.\n",
    "        \n",
    "        ResNet network input size is (224,224,3) then it starts with one \n",
    "        convolution layer, (7x7x64, stride 2) followed by maxpool (3x3, stride2) \n",
    "        then it will build 4 layer groups and the user will define the number of\n",
    "        residual layers per group.\n",
    "        \n",
    "        As example, ResNet34, after the first convolution layer, it has 4 groups\n",
    "        of layers with the following number of residual 'layers_per_group':\n",
    "        [6,8,12,6]\n",
    "        Because the residual connections are made between pair of layers, the\n",
    "        number of layers for each group must be a pair number.\n",
    "        \n",
    "        The user will also be able to define the number of filters and size of\n",
    "        each filter, independently for each group of layers. All layers in the\n",
    "        same group group will have the same number of filters and each filter\n",
    "        within the group will have the same size.\n",
    "        \n",
    "        Same as ResNet, an average pooling layer follows after the 4 groups\n",
    "        of layers.\n",
    "    \n",
    "    :param img_size: Size of input image, in the form: (size, size, #channels)\n",
    "    :param n_classes: Integer. Number of classes for classification.\n",
    "    :param layers_per_group: List with # of layers per group (e.g.[6,8,12,6])\n",
    "    :param n_filters: List of length 4, with number of filters for each group of\n",
    "                      layers.\n",
    "    :param kernel_sizes: List of length 4, with kernel sizes tuples for each \n",
    "                          group of layers\n",
    "    :param l2_reg: Float. L2 norm for L2 regularization\n",
    "    :param optimizer: A keras optimizer from keras.optimizers\n",
    "    :param lr: Float. learning rate for the optimizer.\n",
    "    :param decay: Float. learning rate decay for the optimizer.\n",
    "    :param momentum: Float. Momentum for SGD if optimizer=keras.optimizers.SGD\n",
    "    :param residual: Boolean. True if residual net. Otherwise 'plain' net.\n",
    "    :return: CNN with residual connections, similar to ResNet32\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(layers_per_block) != len(n_filters) or len(layers_per_block) !=\\\n",
    "        len(kernel_sizes) or len(n_filters) != len(n_filters):\n",
    "        e = \"Length of 'layers_per_block', 'n_filters' and 'kernel_sizes'\" +\\\n",
    "        \" must be the same\"\n",
    "        raise Exception(e)  \n",
    "\n",
    "    for layers in layers_per_block:\n",
    "      if layers % 2 == 1:\n",
    "        e = \"Number of 'layers_per_block' must be even/pair numbers\"\n",
    "        raise Exception(e)\n",
    "      \n",
    "    inputs = Input(shape=img_size)\n",
    "    \n",
    "    n_filters_conv1 = 64\n",
    "    kernel_sizes_conv1 = (3,3) # kernel size for very first conv layer\n",
    "    strides_conv1 = (2,2)\n",
    "    \n",
    "    conv1 = Conv2D(n_filters_conv1, kernel_sizes_conv1, strides=strides_conv1,\n",
    "                   padding='same', kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                   kernel_initializer = glorot_uniform(0),\n",
    "                   bias_initializer = glorot_uniform(0))(inputs)\n",
    "    \n",
    "    layer_count = 1 # counter for the number of layers\n",
    "    for i in range(len(layers_per_block)):\n",
    "      for j in range(int(layers_per_block[i]/2)):\n",
    "        if j == 0:\n",
    "          if i == 0:\n",
    "            add = res_block(conv1, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                            residual, first=True)\n",
    "            #add = res_block(conv0_1, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "            #                residual, subsampling=True)\n",
    "          else:\n",
    "            add = res_block(add, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                            residual, subsampling=True)\n",
    "        else:\n",
    "          add = res_block(add, n_filters[i], kernel_sizes[i], l2_reg,\n",
    "                          residual)\n",
    "          \n",
    "    bn = BatchNormalization()(add)\n",
    "    relu = Activation(\"relu\")(bn)\n",
    "\n",
    "    flat = GlobalAveragePooling2D()(relu)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                      kernel_initializer=glorot_uniform(0),\n",
    "                      bias_initializer=glorot_uniform(0))(flat)\n",
    "\n",
    "    res_cnn = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "    if optimizer == keras.optimizers.Nadam:\n",
    "        res_cnn.compile(optimizer(lr=lr, schedule_decay=decay),\n",
    "                    \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    elif optimizer == keras.optimizers.SGD:\n",
    "        res_cnn.compile(optimizer(lr=lr, momentum=momentum, decay=decay),\n",
    "                        \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    else:\n",
    "        res_cnn.compile(optimizer(lr=lr, decay=decay),\n",
    "                        \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return res_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m21vIzndbOIZ"
   },
   "source": [
    "### **Let's build a ResNet18:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rLvSCOTsAuKF",
    "outputId": "8c3c3a91-6634-4234-8099-46432a13cbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 64, 64, 64)   256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 64, 64, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 32, 32, 64)   256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 32, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 32, 32, 64)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 32, 32, 64)   256         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 32, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 32, 64)   256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 32, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 32, 32, 64)   0           add_25[0][0]                     \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 32, 32, 64)   256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 32, 32, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 128)  73856       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 128)  512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 128)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 128)  8320        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 128)  147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 128)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 128)  512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 128)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 128)  147584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 16, 16, 128)  0           add_27[0][0]                     \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 256)    295168      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 256)    33024       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 256)    0           conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 256)    1024        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 256)    590080      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 256)    1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 256)    590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 256)    0           add_29[0][0]                     \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 512)    1180160     activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 512)    2048        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 512)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 512)    131584      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 512)    2359808     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 4, 4, 512)    0           conv2d_81[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 512)    2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 512)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 512)    2359808     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 512)    2048        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 512)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 512)    2359808     activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 4, 4, 512)    0           add_31[0][0]                     \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 4, 512)    2048        add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 4, 512)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 512)          0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            1539        global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,185,347\n",
      "Trainable params: 11,177,539\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = list(iter(train_generator.class_indices))\n",
    "n_classes = len(classes)\n",
    "layers_per_block = [4, 4, 4, 4] #18 layers total with first conv and last FC\n",
    "n_filters = [64, 128, 256, 512]\n",
    "kernel_sizes = [(3,3), (3,3), (3,3), (3,3)]\n",
    "l2_reg = 0.1\n",
    "optimizer = RMSprop # Adamax, RMSprop, Adam (No: Nadam, SGD)\n",
    "lr = 1e-3\n",
    "decay = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "res_cnn = make_resnet(img_size, n_classes, layers_per_block, n_filters,\n",
    "                       kernel_sizes, l2_reg, optimizer, lr, decay, momentum)\n",
    "res_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GZSdBwZul7U"
   },
   "source": [
    "#### **Let's mount our GoogleDrive to download the best model (need to authenticate again):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YjYcj5zrumc5",
    "outputId": "a478c2bc-b8f1-4b45-f976-61387966c79f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUL3HGj4dyft"
   },
   "source": [
    "### **Let's train and validate our Base Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N1-xGeCJ9jRe",
    "outputId": "a0962138-9bec-4a93-966f-87d8361d81f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "568/568 [==============================] - 32s 56ms/step - loss: 6.4826 - acc: 0.5964 - val_loss: 1.0617 - val_acc: 0.6222\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62224, saving model to base_model.h5\n",
      "Epoch 2/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.8314 - acc: 0.6528 - val_loss: 1.3205 - val_acc: 0.5379\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.62224\n",
      "Epoch 3/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.7399 - acc: 0.7049 - val_loss: 1.1446 - val_acc: 0.6031\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.62224\n",
      "Epoch 4/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.6888 - acc: 0.7288 - val_loss: 0.7440 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.62224 to 0.73930, saving model to base_model.h5\n",
      "Epoch 5/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.6587 - acc: 0.7379 - val_loss: 0.7969 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73930\n",
      "Epoch 6/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.6372 - acc: 0.7407 - val_loss: 0.7173 - val_acc: 0.6537\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73930\n",
      "Epoch 7/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.6150 - acc: 0.7512 - val_loss: 0.7160 - val_acc: 0.6839\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73930\n",
      "Epoch 8/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5992 - acc: 0.7607 - val_loss: 1.1895 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73930\n",
      "Epoch 9/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5871 - acc: 0.7684 - val_loss: 0.5892 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.73930 to 0.81518, saving model to base_model.h5\n",
      "Epoch 10/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5753 - acc: 0.7741 - val_loss: 0.6196 - val_acc: 0.7354\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81518\n",
      "Epoch 11/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5663 - acc: 0.7816 - val_loss: 0.5991 - val_acc: 0.7111\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81518\n",
      "Epoch 12/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5506 - acc: 0.7891 - val_loss: 0.7117 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.81518\n",
      "Epoch 13/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5321 - acc: 0.8028 - val_loss: 0.6464 - val_acc: 0.7938\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81518\n",
      "Epoch 14/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5232 - acc: 0.8092 - val_loss: 1.1395 - val_acc: 0.6323\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.81518\n",
      "Epoch 15/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.5070 - acc: 0.8218 - val_loss: 0.6744 - val_acc: 0.7529\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0007225000590551645.\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81518\n",
      "Epoch 16/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4935 - acc: 0.8322 - val_loss: 0.7158 - val_acc: 0.7004\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81518\n",
      "Epoch 17/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4864 - acc: 0.8361 - val_loss: 0.6319 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.81518\n",
      "Epoch 18/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4743 - acc: 0.8436 - val_loss: 0.5229 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.81518 to 0.83755, saving model to base_model.h5\n",
      "Epoch 19/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4697 - acc: 0.8475 - val_loss: 0.6259 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.83755\n",
      "Epoch 20/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4629 - acc: 0.8511 - val_loss: 0.5781 - val_acc: 0.7461\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.83755\n",
      "Epoch 21/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4549 - acc: 0.8551 - val_loss: 0.6558 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006141250254586339.\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.83755\n",
      "Epoch 22/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4434 - acc: 0.8646 - val_loss: 0.7052 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.83755\n",
      "Epoch 23/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.4357 - acc: 0.8707 - val_loss: 0.7539 - val_acc: 0.6683\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.83755\n",
      "Epoch 24/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.4293 - acc: 0.8727 - val_loss: 0.5980 - val_acc: 0.7286\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005220062914304435.\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.83755\n",
      "Epoch 25/70\n",
      "568/568 [==============================] - 27s 48ms/step - loss: 0.4156 - acc: 0.8807 - val_loss: 0.5949 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83755\n",
      "Epoch 26/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.4086 - acc: 0.8867 - val_loss: 0.5701 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83755\n",
      "Epoch 27/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.3998 - acc: 0.8903 - val_loss: 0.7663 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00044370535761117935.\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83755\n",
      "Epoch 28/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.3868 - acc: 0.8985 - val_loss: 0.6902 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83755\n",
      "Epoch 29/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3796 - acc: 0.8999 - val_loss: 0.6468 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83755\n",
      "Epoch 30/70\n",
      "568/568 [==============================] - 27s 47ms/step - loss: 0.3725 - acc: 0.9049 - val_loss: 0.5713 - val_acc: 0.7811\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00037714955396950245.\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.83755\n",
      "Epoch 31/70\n",
      "568/568 [==============================] - 26s 47ms/step - loss: 0.3646 - acc: 0.9110 - val_loss: 0.8395 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83755\n",
      "Epoch 32/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3487 - acc: 0.9182 - val_loss: 1.0423 - val_acc: 0.7072\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83755\n",
      "Epoch 33/70\n",
      "568/568 [==============================] - 26s 45ms/step - loss: 0.3521 - acc: 0.9169 - val_loss: 0.7616 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003205771208740771.\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.83755\n",
      "Epoch 34/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3401 - acc: 0.9235 - val_loss: 0.7620 - val_acc: 0.7169\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.83755\n",
      "Epoch 35/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3298 - acc: 0.9277 - val_loss: 0.8343 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83755\n",
      "Epoch 36/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3263 - acc: 0.9319 - val_loss: 0.8757 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002724905527429655.\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83755\n",
      "Epoch 37/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3143 - acc: 0.9377 - val_loss: 0.8449 - val_acc: 0.6976\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83755\n",
      "Epoch 38/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3161 - acc: 0.9341 - val_loss: 0.9387 - val_acc: 0.7072\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83755\n",
      "Epoch 39/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.3153 - acc: 0.9358 - val_loss: 0.8137 - val_acc: 0.7189\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00023161696735769509.\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83755\n",
      "Epoch 40/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2977 - acc: 0.9442 - val_loss: 0.8376 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83755\n",
      "Epoch 41/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2965 - acc: 0.9469 - val_loss: 0.8368 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83755\n",
      "Epoch 42/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2901 - acc: 0.9483 - val_loss: 0.8646 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00019687442472786642.\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.83755\n",
      "Epoch 43/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2826 - acc: 0.9515 - val_loss: 0.9975 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.83755\n",
      "Epoch 44/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2749 - acc: 0.9561 - val_loss: 0.7735 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.83755\n",
      "Epoch 45/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2754 - acc: 0.9564 - val_loss: 0.8901 - val_acc: 0.7461\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00016734325545257888.\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.83755\n",
      "Epoch 46/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2758 - acc: 0.9564 - val_loss: 0.9269 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83755\n",
      "Epoch 47/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2659 - acc: 0.9594 - val_loss: 0.9432 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83755\n",
      "Epoch 48/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2627 - acc: 0.9630 - val_loss: 0.8137 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00014224176775314845.\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.83755\n",
      "Epoch 49/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2581 - acc: 0.9635 - val_loss: 0.9721 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83755\n",
      "Epoch 50/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2555 - acc: 0.9635 - val_loss: 0.9863 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.83755\n",
      "Epoch 51/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2539 - acc: 0.9662 - val_loss: 1.1114 - val_acc: 0.7053\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00012090550444554538.\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83755\n",
      "Epoch 52/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2476 - acc: 0.9674 - val_loss: 1.0347 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.83755\n",
      "Epoch 53/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2448 - acc: 0.9708 - val_loss: 1.0781 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.83755\n",
      "Epoch 54/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2494 - acc: 0.9679 - val_loss: 0.9376 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010276967877871357.\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.83755\n",
      "Epoch 55/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2402 - acc: 0.9717 - val_loss: 1.0527 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.83755\n",
      "Epoch 56/70\n",
      "568/568 [==============================] - 26s 47ms/step - loss: 0.2383 - acc: 0.9727 - val_loss: 1.0453 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.83755\n",
      "Epoch 57/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2400 - acc: 0.9722 - val_loss: 1.1316 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 8.735422634345013e-05.\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.83755\n",
      "Epoch 58/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2380 - acc: 0.9730 - val_loss: 1.0711 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.83755\n",
      "Epoch 59/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2374 - acc: 0.9731 - val_loss: 1.1120 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.83755\n",
      "Epoch 60/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2334 - acc: 0.9753 - val_loss: 1.1338 - val_acc: 0.7091\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 7.425108960887882e-05.\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.83755\n",
      "Epoch 61/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2297 - acc: 0.9753 - val_loss: 1.0654 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.83755\n",
      "Epoch 62/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2362 - acc: 0.9733 - val_loss: 1.0816 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.83755\n",
      "Epoch 63/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2304 - acc: 0.9750 - val_loss: 0.9936 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.31134258583188e-05.\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.83755\n",
      "Epoch 64/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2243 - acc: 0.9794 - val_loss: 1.0083 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.83755\n",
      "Epoch 65/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2299 - acc: 0.9777 - val_loss: 1.1012 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.83755\n",
      "Epoch 66/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2309 - acc: 0.9759 - val_loss: 0.9771 - val_acc: 0.7539\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 5.364641074265819e-05.\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.83755\n",
      "Epoch 67/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2238 - acc: 0.9799 - val_loss: 1.1570 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.83755\n",
      "Epoch 68/70\n",
      "568/568 [==============================] - 26s 45ms/step - loss: 0.2239 - acc: 0.9783 - val_loss: 1.1125 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.83755\n",
      "Epoch 69/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2246 - acc: 0.9789 - val_loss: 1.1661 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 4.559944882203126e-05.\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.83755\n",
      "Epoch 70/70\n",
      "568/568 [==============================] - 26s 46ms/step - loss: 0.2238 - acc: 0.9792 - val_loss: 1.2195 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.83755\n"
     ]
    }
   ],
   "source": [
    "## fully balanced training\n",
    "## Rot 45,135,225,315\n",
    "## 'C4-7' vs 'C5' vs 'all_other' - Downsampling training\n",
    "\n",
    "## 128x128, stride_60,\n",
    "##min_pos_pix_1250, mivalpos_1024\n",
    "## ReduceLROnPlateau(monitor='val_loss'... )\n",
    "## train_batch_32, opt_RMSprop, Kernel_3x3:\n",
    "\n",
    "epochs = 70\n",
    "\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "val_steps = val_generator.n//val_generator.batch_size\n",
    "\n",
    "# Callbacks:\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=3, \n",
    "                                   verbose=1, mode='min', min_lr=1e-9)\n",
    "EarlyStop = EarlyStopping(monitor='val_acc', patience=70, verbose=1,\n",
    "                          min_delta=0, mode='max')\n",
    "checkpoint = ModelCheckpoint('base_model.h5', monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [reduce_lr, checkpoint, EarlyStop] #order matters!\n",
    "\n",
    "#res_cnn.load_weights('base_model.h5')\n",
    "\n",
    "history = res_cnn.fit_generator(train_generator, steps_per_epoch=train_steps,\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=val_steps, epochs=epochs,\n",
    "                            verbose=1, callbacks=callbacks_list, shuffle=False,\n",
    "                            class_weight=serial_pos_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5mhZnDUvLsL"
   },
   "source": [
    "#### **Let's download the best model to our 'Capstone' folder in GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a4nSrCq4vQCi",
    "outputId": "0bb742b3-0b2f-4c21-eadd-1ef15dbf69b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gdrive/My Drive/Capstone/base_model_C4-7_C5_08375.h5'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = './base_model.h5'\n",
    "dest = 'gdrive/My Drive/Capstone/base_model_C4-7_C5_08375.h5'\n",
    "shutil.copyfile(source, dest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRz_1oJzJRFH"
   },
   "source": [
    "#### **Let's download the training history to a local file (just in case colab's session is interrupted):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5Y5GUUhcyAt"
   },
   "outputs": [],
   "source": [
    "for k,v in history.history.items():\n",
    "  history.history[k] = str(v)\n",
    "\n",
    "with open('history_dict.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "try:\n",
    "    time.sleep(3) # To avoid warning when downloading various files at once\n",
    "    files.download('history_dict.json')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxEpvYPVcyUb"
   },
   "outputs": [],
   "source": [
    "#uploaded = files.upload()\n",
    "with open('history_dict.json') as f:\n",
    "    history_dict = json.load(f)\n",
    "    \n",
    "for k,v in history_dict.items():\n",
    "  history_dict[k] = json.loads(v)\n",
    "\n",
    "history_df = pd.DataFrame(history_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eAC27OxKOLY"
   },
   "source": [
    "#### **Let's plot training and validation loss vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "DCtryy1abrRA",
    "outputId": "67c4caea-7af4-43ba-9eff-14152a6150a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5b6e89c1d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAF1CAYAAAD80H5/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_df[['loss','val_loss']]\n",
    "loss.columns = ['train_loss', 'val_loss']\n",
    "loss.plot(figsize=(10, 6), title='Loss vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSFAqg-gKlR0"
   },
   "source": [
    "#### **Let's plot training and validation accuracy vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "bAbt9je3b1x1",
    "outputId": "03ea0e89-2a7a-4d84-ec89-afc354364083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5afd4c1b00>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF1CAYAAADMXG9eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3zV1f348de5N3vvEAiQsPcWFAcq\nblQcddVRbSturVatrdZaa7/tr2pbJ9ZVxYqKe+AWEBUBw15hBUISssie5Obe8/vj3JsEyLhJbu69\nCe/n4/F5JPczz72MvHPO+7yP0lojhBBCCCG6xuLrBgghhBBC9GYSTAkhhBBCdIMEU0IIIYQQ3SDB\nlBBCCCFEN0gwJYQQQgjRDRJMCSGEEEJ0gwRTQvQSSqk0pZRWSgX4ui2+opT6hVLqM1+3oy9RSgU4\n/16l+botQvRWEkwJ4SVKqc+VUg+3sn+uUqqgNwRJSqmpSqk1SqlqpdQOpdSZ7Zx7pfO8aqVUnVLK\n0eJ1dVeer7V+VWt9dtffgRBCeJ4EU0J4z6vAVUopddj+q4HXtdaNPmhTZz0NfAZEAmcCuW2dqLV+\nXWsdobWOAM4G9rteO/cdojcEk0II0RoJpoTwng+AeOBE1w6lVCxwLrDA+XqOUmqdUqpSKZWjlHrI\n3Zsrpe5TSu1WSlUppbYqpS487Pj1SqltLY5Pce4fqJR6TylVrJQqUUo93c5jbEC2NvZorbe4/e5b\nb3OuUuoepdQmoMa57wGlVJaznVuUUue3OP/XSqllzu9dw1M3KKV2KaXKlFJPtvOs45RSK5VS5Uqp\nfKXUk0qpwBbHxyulvlZKlTp7Cu9t8Zw/Oj/bSqVUhlKqfyv3/0opdeNh+zYrpc5XSlmczytSSlUo\npTYqpca00c4YpdR/nW3MVUo9rJSytHj/y5VSzzrvs00pdUqLa1OVUp8438NOpdQvWxzr6H2c2drn\nqJQa4XxmhVLqgFJqYVufsRBHKwmmhPASrXUdsAi4psXuS4FMrfUG5+sa5/EYYA5wk1LqAjcfsRsT\nqEUDfwb+p5RKAVBKXQI85Lx3FHA+UKKUsgKfANlAGjAAeLOdZ/wE/MMViHnI5Zieqxjn6x3A8c73\n8VdgoVIquZ3rzwGmApMxPX+ntXFeI3AHkOC8/1nADQBKqWjga+BjIAUYASxzXncP8DPn+THAr4H6\nVu7/BnCF64VSaqLzXp8739+xwHAg1vmeS9to52tAHTDU+b7mANe1OD4TyHS+j78A7ymlXJ/dW8Ae\noD9wGebPapab76Otz/GvwGJnu1OBZ9potxBHL621bLLJ5qUNOAEoB0Kcr38A7mzn/H8D/3J+nwZo\nIMDNZ60H5jq//wK4o5VzjgOK3bknJgBYiwkM8oApzv2nAWs6uPZkILeV/bnANR1cuxmY4/z+18Ay\n5/cBzs/j2Bbnvgfc7ebnczfwtvP7q4Gf2jhvt+v5HdwvGqgFUp2v/x/wvPP7MzAB0AzA0s49BmAC\nqeAW+64Gvmrx/nMA1eL4WkwQl47pOQxvcexR4MX23kdHnyOwEJgPDPDFvxnZZOsNm/RMCeFFWuvv\ngQPABUqpocB0zA8rAJRSM5RSS51DbhXAjZgeiA4ppa5RSq13DmOVA+NaXDsQ88P0cAMxw3bu5Gvd\nATyqtf4M06PzmbOH6nhgiTttbENOyxdKqWuVUhtavI9RtP8ZFLT4vhY4Ih/Led9RSqnFziG8SuBh\nOv58OjrWRGtdgemFusyZF3c58Lrz2JfAc5igpFAp9ZxSKrKV2wwGgp3nuN7/M0DLnrlcrXXLFeqz\nMT1R/YEDWuuaw44NcPN9tPU5/hYIBDKUUpuUUr9o5x5CHJUkmBLC+xZghtuuAr7QWhe2OLYQ+AgY\nqLWOxvwAPjxh/QhKqcHAC8CtQLzWOgbTo+O6NgczbHS4HGCQci/5OwDzQxWt9SfAXcCXwC8xield\n1RQYKKWGYAKOm2h+H5m48Rm44T+Yz2SY1joKeJCOP5+Ojh3ONdR3Aub/1+WuA1rrf2utp2CC3DGY\nz6+1Z9UCcVrrGOcWpbWe0OKc1MOuGQTsd24JSqnww47ldeF9NNFa52utf621TgFuAZ5XSqV39j5C\n9GUSTAnhfQswQ2PXY2b4tRQJlGqt65VS04Gfu3nPcExQUgyglLoO80Pb5UXgbmVKGyil1DBnALYa\nyAf+rpQKV0qFKKWOb+MZbwMPKqUmOhOid2B+8Ie62UZ3RLR4H0opdT2mZ8oTIoEKoEYpNRpnvpTT\nR5ig8lalVLBSKsr5+YP57B5RSg11fnaTlFJxbTzjY0xe1IPAm64eJKXUdOcWgMmLawAch1+stc4B\nvgUec7bB4vyzOqnFaSnOdgYopS7HBEifa633ABnA/znfwyRMrtX/uvA+miilLlVKuXq3yjF/PvaO\nrhPiaCLBlBBeprXeC6zABEAfHXb4ZuBhpVQV5gfyIjfvuRV4HPgRKATGY/KxXMffxpnMDVRhZhbG\naa3twHnAMGAfJofpsjYe8xjwMvC+8x7PY4aAXgUWO5O4u0VrvRF4iuYgbySwqrv3dfot8AtM2/+D\nSdZ2PbcCOB24GPP57QBciduPYj6vb4BKzPsOaaP99c5zT6PF8C0m4fslTDCyF/Pe/tlGO6/C/N3Y\nCpRhgth+LY6vAMZiEtgfAi7WWpc5j12GCeYKgHeAP2itl3X2fRxmBvCTUqoGk0t1i9Z6nxvXCXHU\nUIcOvQshhPBXSqlfA1dprU/2dVuEEM2kZ0oIIYQQohskmBJCCCGE6AYZ5hNCCCGE6IYOe6aUUi8r\nswTC5jaOK2WWSdilzBIJnqyMLIQQQgjh19wZ5nsFs/xAW87GzB4ZDszD1IgRQgghhDgqdFioT2u9\nXCmV1s4pc4EFznoqK5VZpDNFa53f3n0TEhJ0Wlp7txVCCCGE8A9r1qw5oLVObO2YO1WPOzKAQ5eD\nyHXuOyKYUkrNw/ReMWjQIDIyMjzweCGEEEKInqWUym7rmFdn82mtn9daT9NaT0tMbDW4E0IIIYTo\nVTwRTOVhFtB0SaV5LSghhBBCiD7NE8HUR8A1zll9xwIVHeVLCSGEEEL0FR3mTCml3gBOxqxGngv8\nieaV458DPgXOAXZhFj29rquNsdls5ObmUl9f39VbHPVCQkJITU0lMDDQ100RQgghjgruzOa7ooPj\nGrjFE43Jzc0lMjKStLQ0lFKeuOVRRWtNSUkJubm5pKen+7o5QgghxFHBr5aTqa+vJz4+XgKpLlJK\nER8fLz17QgghhBf5VTAFSCDVTfL5CSGEEN7ld8GUEEIIIURvIsFUN0RERPi6CUIIIYTwMQmmhBBC\nCCG6wRPLyfSIP3+8ha37Kz16zzH9o/jTeWPbPH7fffcxcOBAbrnFTE586KGHCAgIYOnSpZSVlWGz\n2XjkkUeYO3duh8+qrq5m7ty5rV63YMECHnvsMZRSTJgwgddee43CwkJuvPFGsrKyAJg/fz4zZ870\nwLsWQgghRE/y22DKFy677DJ+85vfNAVTixYt4osvvuD2228nKiqKAwcOcOyxx3L++ed3mOgdEhLC\n+++/f8R1W7du5ZFHHmHFihUkJCRQWloKwO23386sWbN4//33sdvtVFdX9/j7FUIIIXo9hwPy14NS\nEJsOoTFeb4LfBlPt9SD1lMmTJ1NUVMT+/fspLi4mNjaWfv36ceedd7J8+XIsFgt5eXkUFhbSr1+/\ndu+lteYPf/jDEdctWbKESy65hISEBADi4uIAWLJkCQsWLADAarUSHR3ds29WCCGE6EkOB+xbAevf\ngF1fQXgiJAyHhBFmix9mXgeFd+3eOSth64ew9SOo2t98LDTWBFVx6Yd+tQbBwQqor4SDleZrfUXz\n9w3V0FgPtjqzNdaDrRZs9dBY125z/DaY8pVLLrmEd955h4KCAi677DJef/11iouLWbNmDYGBgaSl\npblVx6mr1wkhhBC9Wslu2PAmbHwTyvdBUAQMPwMaamD/ehMAaUfz+VGpkDAM4oZAbNqhW0iLjgWH\nHbJXmOu3fQzVBWANhuGnw+iHICgMSvdA2R7zNW8NbPkAtL3ttioLBEdCcLQJ6gJDzRYWBwEhEBgG\ngSEQEAo82uZtJJg6zGWXXcb111/PgQMH+Pbbb1m0aBFJSUkEBgaydOlSsrOz3bpPRUVFq9edeuqp\nXHjhhdx1113Ex8dTWlpKXFwcs2fPZv78+fzmN79pGuaT3ikhhBDdVlUIFTkmcLBYwRJgNmV1vraa\ngCc01gyVdUVdOWz9wPRC5awEFAw5GU79I4yac2jvU+NBKM2CAzuc206zbfkA6koPvW9IjAmqovpD\n7k9QU2wCm+Gnw5i5MOJMEwy1xW4z7710jwnGQqIgOKr5a1AEWNydiyfBlNvGjh1LVVUVAwYMICUl\nhSuvvJLzzjuP8ePHM23aNEaNGuXWfdq6buzYsdx///3MmjULq9XK5MmTeeWVV3jiiSeYN28eL730\nElarlfnz53Pcccf15FsVQgjRl2gNlXmQv8H0AOVvMFt1gXvXh8ZCwkgz9JY40nyfOAKiB5mAw2GH\nilwTCJXuNgFKaZbZSnaDw2auOe0hGH8pRA9o/TkBwZA02myHq6+Asmwo29u8lWeb+6edYAKo4We4\nPzRoDTQ9XnFD3Du/i5RZWs/7pk2bpjMyMg7Zt23bNkaPbuXDFZ0in6MQQvjIwWqoLjRbVQFUF5nv\ntcMMGQWFOYeSwp3fOzd7A9SXQ12Z6eWpKzNbfbl53XjQBAaWgOavTd8HQm2JCZxqD5h2KAskjoKU\niWaLG2KCLUejGfZyNJq8I9fr+srmnqLi7c33AdMTFJEElftNwNS0P8TkIsUPNflPY86H/lO63rvl\n55RSa7TW01o7Jj1TQgghjm51ZWY4qbNBQHURZH4CmYtN70xVIdhqjjzPNaRmP+j+va3BpqfItQWF\ngb3RBFUN1Wb4ytFoNrvNDHWNPNsZPE2C5LHmmq6qLTVB1YHtULwDqvJh7AXOXp6h5mtkSieGyPo2\nCaa6adOmTVx99dWH7AsODmbVqlU+apEQQoh22erNLLOdX8Our03AEJYAg2eaoaS0EyBxdOuBQlWB\nSX7e+iFk/2B6nOKGmgBmRD+ISDZbZDJEOF+Hxpp72Ruds8PqTNBlq4OGWvO9JdAZOMWYr4Gh3v9c\nWgqLg8HHmU10SIKpbho/fjzr16/3dTOEEEK0pzSrOXja+50JaqzBkHY8jL/E5ADt/R62fWTOD42F\nwcebLXUa5K01AdS+HwFtpvafeLfprUka416vljUArM7kZ9GnSDAlhBCid2s8aHqMqgrMcFR1ofnq\n2leaZZKYweT4TL4Khp1uAqnDE5nLsk2P094fIPt7M4znkjQWTv69SYJOcm8ykjg6SDAlhBCi97A3\nQtEWyM0wdYRyM0zSNIdNprIEQqRzmC1lIhx3Cww7zSRLtyd2sNkm/dy8rsg1z0kaY2a5CdEKCaaE\nEEJ4T2ODSaBuqDFDbQ3VJocJbWabaUfz966v9RUmoMlbY6b8u6pRh8XDgGlmqC16oEmIjuxnttA4\nzyRHR6eaTYh2SDAlhBDCs7Q2dYF2fW2WESna5gygag+dWt8Z1mBImQBTrzU5TAOmmmKOfXQavuhd\nJJhqoby8nIULF3LzzTd36rpzzjmHhQsXEhPj/cUVhRDCLzTUwJ7vTPC062tTbBFM/aH0k5zVpsNM\njlJQhPNruKm3FBBs6iIpizM4Uod+DQwzNZMCgnz4BoVomwRTLZSXl/Pss88eEUw1NjYSEND2R/Xp\np5/2dNOEEMK/2Opg/zrYtxL2fGvWTLM3mMAnfRYcd6vJUYpL93VLhehx/htMfXYfFGzy7D37jYez\n/97m4fvuu4/du3czadIkAgMDCQkJITY2lszMTHbs2MEFF1xATk4O9fX13HHHHcybNw+AtLQ0MjIy\nqK6u5uyzz+aEE05gxYoVDBgwgA8//JDQ0Nbrhbzwwgs8//zzNDQ0MGzYMF577TXCwsIoLCzkxhtv\nJCsrC4D58+czc+ZMFixYwGOPPYZSigkTJvDaa6959vMRQoi2VBVAzirYt8p8zd/QPGSXOAqmzzPr\npQ06zvQ0CXEU8d9gygf+/ve/s3nzZtavX8+yZcuYM2cOmzdvJj3d/Gb18ssvExcXR11dHccccwwX\nX3wx8fHxh9xj586dvPHGG7zwwgtceumlvPvuu1x11VWtPu+iiy7i+uuvB+CBBx7gpZde4rbbbuP2\n229n1qxZvP/++02LHm/ZsoVHHnmEFStWkJCQQGlpaav3FEKIJlpD/nozI81WbxK3bc6tsd5ZQLLe\nVOZ2NJqZcg5bi++dr0t2N5cWCAgxS4bMvBUGzoDU6RAe3347hOjj/DeYaqcHyVumT5/eFEgBPPnk\nk7z//vsA5OTksHPnziOCqfT0dCZNmgTA1KlT2bt3b5v337x5Mw888ADl5eVUV1dz5plnArBkyRIW\nLFgAgNVqJTo6mgULFnDJJZeQkJAAQFxcnMfepxCij6nMhw1vwPqFULKz7fOswRAYYr5aA8FiNSUF\nDl/7LWUizLjBBE/9JkjukhCH8d9gyg+EhzcXc1u2bBlff/01P/74I2FhYZx88snU19cfcU1wcHP3\nttVqpa6urs37X3vttXzwwQdMnDiRV155hWXLlnm0/UKIo0jjQdj+Gax/3SSAa4cZcjv+DhMMBYaa\nLSDUBFABobKumhAeIv+SWoiMjKSqqqrVYxUVFcTGxhIWFkZmZiYrV67s9vOqqqpISUnBZrPx+uuv\nN+2fPXs28+fPB8But1NRUcGpp57K22+/TUlJCYAM8wkhwOEwy5x8ei88PhLe/gUUbIYT7oTb1sIv\nP4cpV5uSAgnDTb2k8Hgzi04CKSE8RnqmWoiPj+f4449n3LhxhIaGkpyc3HTsrLPO4rnnnmP06NGM\nHDmSY489ttvP+8tf/sKMGTNITExkxowZTYHcE088wbx583jppZewWq3Mnz+f4447jvvvv59Zs2Zh\ntVqZPHkyr7zySrfbIIToRVz1m/Ysg6xvzRpzdWVmmG7UHJh8JQw5xQzXCSG8RmmtOz6rB0ybNk1n\nZGQcsm/btm2MHj3aJ+3pS+RzFKKPsDdCZS5k/2jKD+xZDpV55lhUKgyZZWo4DT8DwiSPUoiepJRa\no7We1tox6ZkSQghfqa9snm1Xud8szluZD1X7zdeaIufyKpjlUdJPgvTfwpCTIW6IVP8Wwk9IMOUF\nt9xyCz/88MMh++644w6uu+46H7VICOETFXmw70dT6DJnJRRuaQ6WAEJiIKq/WWMuaSxEpZjXA6ZB\n8jjJcxLCT/ldMKW1RvWx37aeeeYZrz3LV8O2QohWNNTCxjdNdfB9q6Bin9kfGG7WlzvpXhh4DMSm\nmwAqKMy37RVCdIlfBVMhISGUlJQQHx/f5wIqb9BaU1JSQkhIiK+bIoTIWwPv3WDqPEX0g0HHwnG3\nwKAZkDwerH71368Qohv86l9zamoqubm5FBcX+7opvVZISAipqam+boYQRy+7DZY/Bssfhch+cPX7\nZoad/IIoRJ/lV8FUYGDgIRXHhRCiVyneAe/PMwsAT7gczv5/EBrj61YJIXqYXwVTQgjRKzkcsPp5\n+PpPEBgGly6AMXN93SohhJdIMCWEOPpoDXu/NwFQyS5TamDEmTBoZufXnavIhQ9uNnWghp8J5z8F\nkckdXyeE6DMkmBJCHD0aamDjW7D6BSjaCqGxZuHen16Clc9CUCQMOxVGnAXDToeIxMOur4UDO8xW\nvB0ObDeVyB12OO8JmPILyY0S4igkwZQQou8rzYLVL8K6/8HBChNAzX0Gxl1sFv9tqDFB0Y7PYccX\nsPVDQJnyBSmToGyvCZzK9zXfU1lMSYNhp8HsP5oimkKIo5JfLScjhBAe47DDrm/gpxdh55dmvbox\nc2H6DTBwets9SFpD/gYTVO343PRCxaVDwkhIHAkJI8wWPxQCgr37noQQPiPLyQghjh6V+aYHau2r\nUJED4Ukw616Yep2pKN4RpaD/JLOd/Lueb68QoteTYEoI0fs5HJC1BDL+C9s/A22H9Flwxl9g5JzO\nJ5ULIUQnSDAlhOi9qgpg/euw5lUoz4aweFNlfOq1ZhhOCCG8QIIpIUTvUlcGWz+Cze+Y8gbaAWkn\nwuwHYfR5ksckhPA6CaaEEP6vocYM3216B3Z9DQ4bxA2Fk+6B8ZdCwjBft1AIcRSTYEoI4b+ylsHa\nBSaQstVCZH+YcQOM/5kpWSA1nYQQfkCCKSGE/ynYBF/+EbKWQmgcTLwcxv0MBh0HFouvWyeEEIeQ\nYEoI4T8q8mDpX2H9QrNA8Jl/g2N+JXlQQgi/JsGUEML36ivhhyfgx2dMWYOZt8KJvzXLvQghhJ+T\nYEoI0TOKd8C3/8+Z69QPIlMgItl8db0OiYZ1C2Dp36D2gBnKm/1HiE3zdeuFEMJtEkwJITyrvhKW\n/wNWzofAMIgeCPtWQl1p29cMPh7OWAQDpnqvnUII4SESTAkhPMPhgE2L4KsHoboQJl8Fsx+CiERz\nvPGg2V9VAFX55mt1IaQeAyPOkpl5QoheS4IpIUT37V8Pn94Duauh/xS4/A1IPayXKSAYYgaZTQgh\n+hAJpoQQXVdTAkseNsu5hMXD+U/DpCulfIEQ4qgiwZQQovNqS2HVc7DyOWiohmNvglm/M+UMhBDi\nKCPBlBDCfdVF8OPT8NNLJogadS6c+gAkjfZ1y4QQwmckmBJCdKwiD1Y8CWteAXsDjL3I1IFKHuPr\nlgkhhM9JMCWEaFvpHvjh37DudUDDhMvhhDtlYWEhhGhBgikhxKG0hr3fwar/wPZPwRIAU66B4++A\n2MG+bp0QQvgdt4IppdRZwBOAFXhRa/33w44PBl4GEoFS4Cqtda6H2yqE6EkNNbDxLVj9AhRtNUu5\nzLwdZtwIUSm+bp0QQvitDoMppZQVeAY4HcgFflJKfaS13tritMeABVrrV5VSpwJ/A67uiQYLITys\nNAtWvwjr/gcHK6DfBJj7DIy7GAJDfd06IYTwe+70TE0HdmmtswCUUm8Cc4GWwdQY4C7n90uBDzzZ\nSCFEN2kNdWVQkWOSySvzoCIXCjbB7iVgscLo82HGDTBwhlQjF0KITnAnmBoA5LR4nQvMOOycDcBF\nmKHAC4FIpVS81rqk5UlKqXnAPIBBg6QKshA9as938P2/oDzbBFCNdYcetwRCzECYdS9MvU6G8oQQ\noos8lYB+N/C0UupaYDmQB9gPP0lr/TzwPMC0adO0h54thGjJVg/fPAwrn4GoVLOsy/AzIXoARA0w\nCw9HD4DwJKlULoQQHuBOMJUHDGzxOtW5r4nWej+mZwqlVARwsda63FONFEK4af96eP8GKM6Eab+C\nM/4CQeG+bpUQQvRp7gRTPwHDlVLpmCDqcuDnLU9QSiUApVprB/B7zMw+IYS32BvNkN63f4fwRLjq\nXRh2mq9bJYQQR4UOgymtdaNS6lbgC0xphJe11luUUg8DGVrrj4CTgb8ppTRmmO+WHmyzEKKlA7tM\nb1RehpmBd85jEBbn61YJIcRRQ2ntm9SladOm6YyMDJ88W4g+wWGHjJfhyz9CQDDMeRzG/8zXrRJC\niD5JKbVGaz2ttWNSAV2I3qQyH3Z/A7u+gaylptzB0NmmLpTMxhNCCJ+QYEoIf9Z4ELJXOAOoJVC0\nxeyPSIYRZ8PIs2H0eVIXSgghfEiCKSH8UUUuLH/MLO9iqzU1oQYfB6f9GYbNhuRxEkAJIYSfkGBK\nCH9SVQDfPQ5rXjFVyydeDqPOhbQTIDjC160TQgjRCgmmhPAH1cXww7/hpxfBboPJV8JJ90CMrBQg\nhBD+ToIpIXypthRWPAmrnjfLvUy4zCzvEjfE1y0TQgjhJgmmhPAFhx1WPgvf/gMOVsG4i2DWfZA4\nwtctE0II0UkSTAnhbaV74IObYN+PZs280x6C5DG+bpUQQogukmBKCG/R2iSWf3E/WKxwwXMmwVxm\n5QkhRK8mwZQQ3lCZDx/dBru+gvRZpshmzMCOrxNCCOH3JJgSoqdtegcW/9YU4Dz7H3DM9WCx+LpV\nQgghPESCKSF6gsMOZXthySOw5T0YMA0u/A8kDPN1y4QQQniYBFNCdJXWUJUPJbuhZBeU7nZ+vxvK\n9oC9ASwBcOoDcPydYJV/bkII0RfJ/+5CdFZjA2x8E77/F5RmNe+3Bpv6UAnDYeRZED8MBs2U3igh\nhOjjJJgSwl22elj3Gnz/b6jMhZSJcPajJniKHwpRqZILJYQQRyEJpoToyMFqWPNfWPEUVBfCwBlw\n3hNmwWEpayCEEEc9CaaEaEt9Bax+Hn58FupKTUmDi18yiw5LECWEEMJJgikhWpOzGt66GqoLTJXy\nk+6GgdN93SohhBB+SIIpIQ6X8V/49B6IHgC/XgKpU33dIiGEEH5MgikhXBoPwmf3miVfhs6Gi1+E\nsDhft0oIIYSfk2BKCDDLvSy6BnJXwwl3mdpQFquvWyWEEKIXkGBKiH2rYNHVZtbeJa/C2At83SIh\nhBC9iART4uiW8TJ8ei9Ep8LVH0DyGF+3SAghRC8jwZQ4+mgNeWtg1XOw6W0YdprJjwqN9XXLhBBC\n9EISTImjR2kWbHwbNr5l1tGzBsOJd8Mpf5D8KCGEEF0mwZTo22pLYct7sHER5Kwy+9JOhBPuhDHn\nQ0i0b9snhBCi15NgSvQ9VQWw80vY/hns/AocNkgcBbP/BOMvgZiBvm6hEEKIPkSCKdH7ORyQv94E\nUDs+h/3rzP6oVJhxA0y4DPqNlyVghBBC9AgJpkTv1FADWcucvU9fmgWIUWbJl9kPmiVgksdKACWE\nEKLHSTAleo+qQtjxmQmgspZBYz0ER8Gw2TDiLDMrLzzB160UQghxlJFgSvgvraE4EzIXmwAqL8Ps\njx4EU6+FkWfD4OPBGujTZgohhDi6STAl/NO2j+GrP5kSBgD9p8ApD5gASobvhBBC+BEJpoR/qciD\nT++B7YsheRyc+y8zhBfV39ctE0IIIVolwZTwDw47/PQifPOw+f70h+HYm2UITwghhN+TYEr4XsFm\n+Ph2s8TL0Nlw7j8hNs3XrRJCCCHcYvF1A8RRrKHW5EX95yQoy4aLX4Kr3oXYNGoONnLP2xsorjro\n61YKIYQQ7ZKeKeF9B3bCtoJNgdQAACAASURBVI9gzatQng2TrzbDemFxTaeszCrh7TW5HJMex6XT\npGK5EEII/yXBlOh5WkPBRjNDb9vHptwBQOoxcMGzkHbCEZdkFlQBsK+k1pstFUIIITpNginRM7SG\nfSubA6iKfaAspi7UtF/BqDkQPaDNy7flVwKQXSrBlBBCCP8mwZTwPFsdfHgLbH4XrEEw5BSYdS+M\nPAfC4926RXPPVE1PtlQIIYToNgmmhGdV5sObPzeLDZ9yP8y4EUKiOnWLepudrOJqAPbKMJ8QQgg/\nJ8GU8Jy8tSaQqq+Ey183Q3ldsKuoGoeGyYNiWLevnIpaG9FhUm9KCCGEf5LSCMIzNr8H/z0HLAHw\nqy+7HEhBc77UmWP7AZBdKkN9Qggh/JcEU6J7tIalf4N3roOUiXD9Uug3rlu3zCyoIiTQwknDEwHI\nlqE+IYQQfkyG+UTXNdTChzfDlvdh4s/hvH9DQHC3b5tZUMnI5EjSEsIAyJYkdCGEEH5MginRNVUF\nsPAyyN8Ap/8FZt4GSnX7tlprtuVXcfroZMKCAkiKDJaeKSGEEH5NginReTUlsGAulOfAFW/CyLM8\nduvi6oOU1jQwKiUSgMHxYVJrSgghhF+TnCnROfWV8PrFULYXrlzk0UAKIDPf1Jca1c+UUxgUFy5V\n0IUQQvg1CaaE+2x18MYVULAJLnm11WVguiuzwMzkG9XP9EylxYdRUFlPvc3u8WcJIYQQniDBlHCP\n3QZvXwvZP8AFz3m8R8olM7+KflEhxIYHATAo3iSh75OhPiGEEH5KgikfefzL7azdV+brZrjH4YAP\nboIdn8Ocx2DCJT32qG0FVU35UgCD48MBKY8ghBDCf0kw5QMHG+08tWQXb2fk+LopHdMaPr0bNr0N\nsx+EY37dY4+y2R3sKqpqypcCGBwn5RGEEEL4NwmmfKC81gZAVnEvCBCW/AUyXoLj74AT7urRR2UV\n12Cza0a36JmKCQskKiRAeqaEEEL4LQmmfKC0pgGArAN+Hkz98AR89zhMvRZO+7NH6ki1pzn5vLln\nSinF4PhwKY8ghBDCb0kw5QOuYKq46iBV9TYft6YVB6vg64fgqwdh7EUw5589HkgBbMuvItCqGJIY\nfsj+QfFh7JNhPiGEEH5KgikfcAVTAHv8qXfKboPVL8ATk+D7f8HEK+DC/4DF6pXHZxZUMiwpkkDr\noX8tB8eFkVtWR6Pd4ZV2CCGEEJ0hFdB9oKy2OZjKKq5hQmqMD1uDSTLP/MT0RpXsgsHHw+mLIHWq\nV5uRmV/FzKHxR+xPiw+n0aHZX17fVCpBCCGE8BcSTPlASbUJpiwKsoqrfduYfavgqz9CzipIGGmW\nhxlxlleG9Voqq2mgoLL+kLIILq4AKru0RoIpIYQQfsetYT6l1FlKqe1KqV1KqftaOT5IKbVUKbVO\nKbVRKXWO55vad5TVNhAdGsjAuDB2+2qYr3wfvHU1vHyGWRrm3H/DTStg5NleD6QAMgsOXUampcGu\nYEpm9AkhhPBDHfZMKaWswDPA6UAu8JNS6iOt9dYWpz0ALNJaz1dKjQE+BdJ6oL19QmlNA/HhQQyO\nD2OPL8ojVOTBy2dDXRmc/Hs47lYIjvB+O1pomsnXSs9UcmQIQQEWqYIuhBDCL7kzzDcd2KW1zgJQ\nSr0JzAVaBlMacHUpRAP7PdnIvqa0poHY8CDSEyJYmVWKw6GxWLzUG1RXBv+7GOor4JefQcpE7zy3\nA5n5VcSHB5EYEXzEMYtFMTgujL3+lKwvhBBCOLkzzDcAaFmqO9e5r6WHgKuUUrmYXqnbWruRUmqe\nUipDKZVRXFzcheb2DaU1DcSGBTEkMZw6m52CynrvPNhWBwsvh9LdcPnrfhNIgemZGpUSiWpjiHFw\nfJj0TAkhhPBLniqNcAXwitY6FTgHeE0pdcS9tdbPa62naa2nJSYmeujRvU9ZrRnmc9VT8kp5BHsj\nvPNLk2h+0fMwZFbPP9NNdodme2FVq/lSLoPiwskuqUVr7cWWCSGEEB1zJ5jKAwa2eJ3q3NfSr4BF\nAFrrH4EQIMETDexrtNZNw3xDEkyeUo/P6NMaFt8J2z+Fs/8BYy/s2ed1UnZJDfU2B6P6HZkv5TI4\nPow6m53iqoNebJkQQgjRMXeCqZ+A4UqpdKVUEHA58NFh5+wDZgMopUZjgqmjdxyvHdUHG7HZNXHh\ngSRHBRMeZGV3TyehL/0rrF0AJ90DM+YBUFRZz87Cqp59rptcM/lGp7TdM9U0o0+G+oQQQviZDoMp\nrXUjcCvwBbANM2tvi1LqYaXU+c7Tfgtcr5TaALwBXKtlPKZVZTVm+Zi48GCUUqQnhvfsMN+q52H5\nozDlGjjl/qbdf/10G/NeW9Nzz+2EzPxKLAqGJbU9o3BwvBkSlfIIQggh/I1bRTu11p9iEstb7nuw\nxfdbgeM927S+qaTGDFPFhQcCMCQhgnU5ZT3zsC3vw2f3wshzYM6/DqkftXV/JYXeSnzvwLaCKoYk\nRhAS2PayNQNiQrEoZI0+IYQQfkfW5vMy11IysWFBAKQnhJNbVke9ze7ZB+36Gt6bB4OOhZ+9DNbm\nuLmh0cGeAzXUNtg9/9wuyCyobDdfCiAowEL/mFD2Ss+UEEIIPyPBlJeVOof54sNNPaUhieFo7cHh\nq9pS+PBWU0sqfhhc8QYEhh5yyt6SGhodZhS2vNbmmed2UVW9jZzSunbzpVzS4sMlZ0oIIYTfkWDK\ny0qdw3yxzmG+oYkmT2jPgW7O6HM4YO1r8NRU2PAGzLwdfvUVhMYeceqOFonnLRdd9gVXWzrqmQKz\nRp8M8wkhhPA3stCxl5XW2Ai0KiKCzUeflmASq7s1o69wC3xyF+SshEHHwZx/QvKYNk/fUdgcuPk6\nmNqW7wym3OiZGhwXRlmtjYo6G9GhgT3dNCGEEMItEkx5WVlNA3HhQU2VviOCA0iOCiarK8HUwWpY\n9jdYOR9ComHuMzDx52Bpv8NxZ2EVVovC7tA+H+bLLKgkMiSA/tEhHZ7rKo+wr6SW8anRPd00IYQQ\nwi0yzOdlJc6lZFoakhDRuWE+rWHbx/DMdPjxaZh8Fdy2xnztIJACM7Q2boAJRnzdM5WZX8XoflFt\nLiPTUlN5hFIZ6hNCCOE/JJjysrJa0zPVUnpiOFnu1poqz4E3roC3roLQOJMXdf6TEBbn1uUHG+3s\nLalleprJpfJlz5TWmsyCKkaldJwvBTAozlm4U2b0eUVFrY2fzV9BZkGlr5sihBB+TYIpL3MN87U0\nJCGc8lobpTXt9BLZG+HHZ+CZGbDnWzjjEZi3DAZO79Tz9x6oxe7QjBsQTWiglbL2ntnDcsvqqD7Y\n2O6afC2FBweQEBHMPgmmvGL5zmIyssv4bscBXzdFCCH8muRMeVlJK8FUyxl9ceGt9DDlrYWP74CC\njTD8TJjzGMQM6tLzXbPnhidFEhsWSJkPe6Zcy8i42zMFJm9qr8zo84pVe0oA2COftxBCtEt6pryo\n0e6gos52RM5Uelsz+g5WwWe/gxdnQ3URXLoAfv5WlwMpMMnnFmXqW8WEBfk0Zyoz3wwfjUzuXDC1\nT2pNecXKrFIA9vbkckdCCNEHSDDlReV1zoKdEYcGU6mxoQRaVfOMPq1h64fw9HRY9R+Y9ku4dTWM\nmXvIkjBdsaOwmrT4cEICrcSGB/o2mCqoYnB8GOHB7neQDo4Lp6Cy3i8qt/e0p77ZydlPfIfd4f1l\nLg9UH2RXUTUWRc+uHSmEEH2ABFNe5MqJOrxnKsBqYXB8OFlFVbD9c3h+Fiy6xiSV/+ormPO4KX3g\nATuKqhieHNHUDl8moG9zYxmZww2OD0NryC3r271Tr6/K5vGvdrAtv5JsHwyzrXL2Sp08Mon8inrq\nGvp+8CqEEF0lwZQXuYKpw3Om0JrzwrZwV/ZN8MZlUF8BF8yHed/CwGM89vyDjXayS2oZ4RxWi/Xh\nMF9dg529B2rcTj53GeSsNbX3QN8Npr7eWsgfP9jcNPzpKmzqTav2lBAWZOW8iSmAlKMQQoj2SDDl\nRWWHB1Naw+4l8NIZ3FHweyLsZTjOexJuzYBJPz9kcWJPyCquwe7QDG8KpgKpqLP5ZBhpZ1EVDg2j\nO5F8DmZ9PqDPrtG3PqecW99Yy7gB0bw571isFsW2fO+XJliVVcrUwbEMTzJ/Pnu6U6FfCCH6OAmm\nvKikZTC193v479nw2oVQuZ+McQ9yysF/kpP2M7D2zFIprpl8I5zDfDFhQWgNlXXeH+pzzeQb0Ynk\nczABYGRwQJ9co2/vgRp++cpPJEWG8NIvjiE2PIhhiRFs9XIwVVrTwPbCKo4dEt+03JHM6BNCiLZJ\nMOVFZTUNxFBFwld3wCtzoGwvnPMY3L4Wpl2HjQD3i3d2wa6iaqwW1TR70LXYsi+G+nYUVBEcYGmq\nau4upRSD4sP6XM/UgeqD/OK/q9Fa88p1x5AYGQyYnjtv90ytdpZEOHZIHBHBASRGBsuMPtFlDofG\nZnf4uhlC9CgJprxFa/rnfsI3wfdg3fIOnHg33L4Opl8PAcFNAU6X1uhz045CM3suOMAKmJ4pwCe1\nprYXmkR4q6XzsxMHx4f1qSrotQ2N/OqVnyisrOela49hiLPuGMDolCjyK+q9Wlx1ZVYpIYEWxg+I\nASA9Plxm9Iku+39fZHLmv5ejtffTCYTwFgmmvKF8H7x+CRfveYhCazLcsBxm/xECQ5tOiQsPIjo0\nkKziTqzR10k7C6sZkdQ8rOaaVVjui56pwqpOD/G5DI4PJ7es1ie5Xp7WaHdw28J1bMqr4KkrpjBl\nUOwhx8f0Nwn63uydWplVwrTBcQQFmP8e0hLC2NOHE/5Fz7E7NO+uySWruMbrw9VCeJMEUz3JYYeV\nz8Ezx0L2Cl6LuYkH4v4JyWOPOFUpxZDEnusBqLfZ2VtS05QvBSb/CGh/GZseUF7bQGHlwU6XRXAZ\nHBeGza7ZX17n4ZZ5l9aaP364hW8yi3h47jhOH5N8xDmjU0ww5a0fRGU1DWQWVDEjvbkSf3pCBAeq\nD1JV77syGqJ3WrWnhAPV5v+XZduLfdwaIXqOBFM9pXArvHQGfP47GDwTblnJW9Y5xESEtnlJekJ4\njw3zZRXX4NA0zeSD5mE+b9ea2lFoet+62jPlKo/Q24f6XluZzRur93HzyUO56tjBrZ6TEBFMYmSw\n18ojrN5r6ksdOzS+aV96Qt8vR9FXaa35/XsbeTsjxyfPX7wxn9BAKyOSI1iaWeSTNgjhDRJMeZrW\nsPoF+M9JULYHLnoRrnwbYgZRWt1wRMHOloYmRlBQWU/NwUaPN2tn0ZGz56JCArBalNcT0Lc7ZxWO\n7GrPVFN5hN6bx6O15uXv93BMWiz3nDmy3XPHpER5rWdqZVYJwQEWJqQ2F4mVGX29V2ZBFW+szuG+\n9zaxek+pV5/daHfw+eYCTh2dxFlj+7F2XxkVPiwSLERPkmDKkxpq4L158OndMORkuOUnmHBJ0xIw\npbUNRywl09IQ1w+tHhjq21FYRUCLmXxghhZ9sdjxjoIqIkMC6BcV0qXrU6JCCAqwsK8X90ytyyln\nb0ktl0wbiOpgiaDRKVHsKqqiobHnZ0S56ku5JilAc20vmdHX+yzemI9FwYCYUG5ZuJaiqnqvPXv1\nnlJKahqYMz6FWSOTcGhYvlOG+kTfJMGUpxzYCS/Mhk1vwykPwM8XQXjzUEldg516m6Pdnqn0ROeM\nvh4JpqpJSwhvSip2iQkL8noC+vbCKkYmR3YYRLTFYlEMjA3t1cN8763NJSTQwtnj+nV47uiUSGx2\nze4enJwAUFFrY1tBJTPS4w/ZHxJopX90iMzo62W01ny6KZ/jhsbz/DVTqaq3cevCdV4rU/DJJjPE\nd8rIJCYNjCEmLJCl22WoT/RNEkx5wpYP4PlToKYIrn4PZt0DlkM/2pKagwDEhbddkDMtPhyl6JEZ\nfbuKqg9JPncxPVPeC6a01mYmXxeH+FwGx4ezt5cOOzU0OvhkYz5njOlHZEjHBVrHOmf0bd3fs0N9\nq/eWorWpL3W4tAQpj9DbbMuvIutADXPG92dUvyj+ftEEVu8p5dEvtvf4s11DfLNHJxEaZMVqUcwa\nkci324tx9IFZuEIcToKp7rDb4PM/wNu/gKRRpuTB0FNbPbWsxgylxYUHt3m7kEArA2JCPZ6EXm+z\nk11S07Q0SEsxXl7suLjqIOW1tqZ157pqUFwY+0pre2XtmqXbiyivtXHhlAFunZ8WH05wgKXHyyOs\nyiohKMDCxIExRxxLT+i9wevRavGm/VgtijPHmlmiF0wewNXHDub55Vl8vjm/R5+9MquU0poGzp2Q\n0rTvlJFJlNQ0sCmvokefLfoeh0Pz9JKd7Cz0/jql7pJgqqsq98Mr58LKZ2D6DXDtpxCd2ubppbWu\npWTa74kYkhjh8R6A3cXVzpl8nuuZ+mZbIec+9R0HG+2dum57YdeWkTlcWnwYtQ32pmnXvcl7a3NJ\niAjmxGEJbp0fYLUwsl8k2wp6NphauaeEKYNiCAm0HnEsPSGc8lqbV4uHiq7TWrN4Yz7HDYknPqL5\nF7gHzh3NpIEx3P32xh4dNl68KZ+wICsnj0xq2nfSiESUkhIJRyOtNetzyrtcG/DlH/bw2Jc7eH55\nlodb5jkSTHVF7hozW69gE1z8EpzzDwhoOxcKoNQ5zNdezhSYJPSs4mqP9rjsbKcUQWxYEGW1tk4/\nb/XeUjbnVbK5k79lbi84dH3ArnLN6NvXy2b0ldc2sCSziLmT+hNgdf+f35iUKLbur+yxnriKOhtb\n9x+ZL+XiSkKXGX29w9b8SvaW1DKnRc8QQHCAlWevnEJQgIWb/reG2gbPzxw2Q3z5zB6dfEhgHhce\nxMTUGMmbOso4HJr7P9jMBc/8wN8+3dbp63cWVvGPL7ajlOnV99dhYgmmOmv752ZdvcAwuH4JjP+Z\nW5eVOof54tsZ5gMYkhhOTYOdoqqD3W6qi2smX1or6+DFhAXR0OigtqFzPUxFlaZ9GXvLOnXd9oIq\nEiKCD/ltuSsGO2tNPfDBFp5fvrvXzOz7ZGM+NrvmwsnuDfG5jE6JoqzWRmGl5/5etJSxtxSHhmOH\ntB5MuSZHyIy+3mHxxnznEN+RExz6x4Ty5OWT2VlUze/f29RqgN5od/Dj7hL+9OFmjvvbN8xbkOF2\nIP9jVglltTbmjE854tgpI5PYkFtOSXXP/D0W/sXu0Nz77kYWrtrHyORIXvx+D4s3uj/E3NDo4M5F\n64kMDuD+c0ZzoNp/h4klmOqMjP/Cm1dA4kj49dcmT8pNZTUNWC2KyJCAds8bkmB6bDyZN7WjsJr0\nVmbyQXMV9M4O9bmmWK/J7lwwtaOwipH9utcrBWbY6YE5o7Fa4P8+zeSkR5dyzhPf8dQ3/j2u/v66\nPEYkRzQllburuRJ6z/xHsmpPKUFWC5MHHZkvBTAwNgyL6pmyHcKztNYs3pTPzKHxxIW33hN+wvAE\nfnv6CD5cv5/XVmYD5gfXsu1F3PfuRqb/3zdc8cJK3vwph6TIYL7cWsgnbv4Q/HRTPuFBVk4emXjE\nsVNGJaKlRMJRwWZ3cOdb63lnTS53njaCj287gcmDYrj3nQ3sKnJviPnpJTvZnFfJXy8cz8VTUrEo\n+MZPi79KMOUOrWHJX+GT38DQ2XDtYohI6vi6FkpqGogNC8TSwcK+zeURPJfPsLOo7XXwYsO7VgXd\n1UOyJrvM7d9YHQ7NjsLqbudLgamR9esTh/DJbSfy3b2ncP85owkNsvL4Vzs4/V/Lmf34Mh79IpPq\nHiiA2lV7D9SwJruMi6akdrosxKgU85n1VCX0lVklTBrYer4UQFCAhdTYMAmmeoEt+yvJLqlttWeo\npZtPHsbsUUn85ZOt3LJwLVMf+Ypr//sTH2/Yz/HDEnj2yimse/B03rv5eMYPiObhT7ZSUdf+/xM2\n5yy+08Ykt/p3aVz/aBIigliaKcFUX9bQaNYc/WjDfn531ijuOG04QQEWnr1yCsGBVm7635oOi1Ov\n21fGM8t2c/GUVM4a14/Y8CCmDIr120r6Ekx1xG6DD2+B5f+AyVfBFW9AcOd7VspqGtr8LbGllKgQ\nQgItHuuZqmuws6+0ttXkc2jO4ep0z1RlPZHBAZTUNLDXzSG23LI66mz2bs/kO9zAuDCuP2kI7940\nk1V/mM3Dc8eSHBXCs8t288zSXR59Vne8vy4PpWDupP6dvjYqJJCBcaE9Ugm9qt7G5ryKVksitJQm\nM/p6hcWb2h7ia8liUfzz0kmkxobx/c4DnDm2Hy/9Yhpr/ng6T10xmXPGpxAWZFZJ+L8Lx1NSfZDH\nOiir8OPutof4XM88aUQiy3cW94mFysWR6m12bvzfGj7fUsCD547hppOHNh1LiQ7lqSsms7u4mvva\nGGIG83Prt4s2kBwZzJ/OH9O0/5RRSWzKq6Co0nvFZ90lwVR7DlbDwstg/etw8u/h/KfB2nFdoNaU\n1ra/lIyLxaJIT4jwWK2p3cXVaN327LnmYT73e6bqGuxU1jcye7TpncvY694yFU0z+bpZY6o9yVEh\nXHNcGguvP5apg2JZmVXSY8/qDK0176/LY+bQeFKi216fsT2j+0WxrQdqTWXsLcOhYUYb+VIuQxLC\n2VNc0yvLURwtXLP4jh+W0NTr3J7osEC++M1JrHngNB67ZOIRSeMu41Ojuea4NP63Kpv1OeVt3m/x\nxnwiggM4acSRQ3wup4xMorzW1u59RO9U12Dn+gUZLMks4pELxvHLE9KPOOf4YQn89oyRfLxhP6+u\n2Nvqff7+2TayDtTw2CUTiWpRi8/1M8cfJzFIMNWWqkJ45RzIWgbnPwUn39e0LExXlLrZMwXOH1oe\nGk5pXpOv9Z6p5sWO3e+ZcuVLzRyaQFRIAGv3uZc3tcMZTA1P6n7OlDump8exKbeiR2Ysddaa7DL2\nldZy0eS2y2d0ZEz/KPaU1Hj8/azcU0KgVTFlUGy756XFh1HTYKdYkof91ua8SvaV1nJuB0N8LQUF\nWNyaWfrbM0aQFBnMH97bRGMrVdRtdgdfbC3gtNFJbQ4XA5w0PBGLgmV++ANRdF3NwUau/e9qvt91\ngH/8bEKbi7cD3DRrKKeNTuKRxduOyLv9bmcxr/6YzS+PT2fmYeVjRiZH0j86hG+2+d/fHQmmWqou\ngsxP4ZuH4cXZZomYK96EKdd0+9buDvOBmdGXU1bnkbXYdhRWE2hVTaUEDhfj6pmqcb9nyjXTsF90\nCFMHx7o9o297QRUDYkLdqvrtCdPT42h0aNZm+/434PfW5REaaOUsN5aPacvolCi0bi4v0ZHahkbe\n+mkfVfXt/9muyiplYmoMoUFt/wCE5gWP9x7oHTMnj0aLN+UTYFGc4SzU6UmRIYE8dN5YtuZX8kor\nPQordpdQXmtjzoT2h7GjwwKZOjjWL3sXRNdUH2zkmpdXk5Fdxr8vm8Sl0wa2e77Fonj80kn0jwnl\nltfXcsD5C1pFrY173t7I0MRw7j3ryAXglVKcOjqJ73cd6HSNw57WJ4OpzXkV3PjamvbXoLLVwb6V\nsOJpePta+Nd4eGy4ma33/b8hPBGu/QRGnNHt9jgcmrLazgVTdof2SA2lnYVVpCeEE9jGb56BVguR\nwQGdypkqdI5XJ0UFMy0tjp1F1W71bO0orGJUDw7xHW7q4FgsClbv8e1Q38FGO59s2M+ZY5MJD25/\nNmd7xjTN6HNvqO/l7/fwu3c3cca/lrMks7DVc6oPNrIpr6LNkggtuWaa7vHg5AjhOWYWn0kej3Ej\npaArzhrXj1NGJvLPr3awv7zukGOLN+4nMjiAE4d3XIz25JFJbM6r9OrCy6Jn2B2aO95Yx/qccp6+\nYjJzJ7lX9iU6NJD5V02hrLaB2xauo9Hu4KGPt3Cg+iD/umxSm72bp45KorbBzqos99JLXCrrbdTb\nei4A65PB1Lc7ivl8SwG5ZXVHHnTY4dtH4e+D4OUz4cv7ITcDBkyBMx6B6z6H3+fCvKUwYKpH2lNR\nZ8OhOy7Y6ZLuwfIIOwqrGd5BwndMeGDnhvmcM/mSI03PFNDhUJ/N7mB3cXWP5ksdLjIkkHEDolm1\np3P/6DxtybYiKusbuXBK14f4AFJjQ4kMDnBrWRm7Q/PG6hzGpEQRGRLAL1/J4I431x1R32dNdhl2\nh2ZGB8nnAP1jQgi0KvZIz5Rf2pRXQU5p3RGFOj1JKcXDc8fh0Jo/f7ylab/N7uCLLYWc3sYsvsO5\nyiZ8K9XQe71Hv9jON5lF/Om8MZzdieFlgLH9o3nkgnH8mFXCNS+v5v11edx26nAmpLZeogVMeklI\noIUlnZjV19Do4Nwnv+euRes71b7O6JPBVIlziZHiwwtfVubDgrmw9BEYeTZcvhB+uwPu3AyXvgoz\nb4PBx0FQmEfb41pKJj7C/Z4pgKxu5k3VNdjJKatlRCtr8rUUGxZEaScS0Aur6gmyWogJC2RiagwB\nFtXhUN/eAzXY7NrjM/k6Mj0tjnU55T7tEn5vXR5JkcEcP7Tj3p/2KKUYnRLlVnmE73YWk1dex82n\nDOWT207kN6cN59NN+Zz2z2/5YF1eUxL5yqwSAiyqKShuT4DVwsC4MCnc6UE5pbVc9p8fPTJRYvHG\nfAKtijPHdH0o2R0D48K4Y/YIvthSyNdbTY/nD7sOUFFn4xw3f5iOSYkiKTLYraVl3lubyzUvr+5w\nKn1PceUC9fR6hr3Re2tzee7b3Vw5YxBXt5Mj1Z5Lpg3kiukDWbG7hImp0dx8ytB2zw8JtDJzaALf\nZBa6PRnmg/V57Cut5fPNBeSU9swvg30ymHKNvx4STO38Cp47wfRCnf80XPIqjJoDkZ7PLThcqXM9\nM3d7pqJCAkmOCuanbvao7CpyzeRrP+E7Niyo0z1TiZHBKKUIDbIytn9Uh8U7PbUmX2dNT4+jodHB\nhhzfVM0trWlg2fbOLx/TltEpkWzLr+xwSYWFq/YRHx7EGWP6ERRg4TenjWDx7ScyOD6c37y1nute\n+Ym88jpWZZUwITWa7n1avwAAIABJREFUsCD3hh+HSHkEj/rzx1tZtaeU6xdkkNmNtRddhTpPGJZA\ndFjP5yT++sR0RiRH8KePtlDb0MjijflmiG+Ee+tNKqU4ZWQSy3cWt5uO8fqqbO5atIHlO4o7VTnb\nkxZl5LBsezF3vLmeTbn+WX3bF9buK+O+9zZx7JA4Hjp/bKdr57X0p/PGctfpI3j651PaTElp6dRR\nSeSU1rm1vqTdoXlu2W7SE8JRSvE/Z5FaT+vjwVQ9NDbAlw/A6z+DiGS44VuYcnW3ZuZ1liuYcjdn\nCuCK6YP4JrOIrd2YCt80e66DAKazix0XVdWTHNW8HMzUwXFsyC1v9z/FHQVVWC2qqdfNW45JM8NX\nvsqb+mTjfufyMd0b4nMZ0z+KWmftsLYUVtbzTWYRP5uWekjV+xHJkbx700wePHcMq7JKOeOf37Ih\n1718KZe0eDPT1FPrYxVW1vdoHoM/W7a9iK+3FXLtzDTCgqxc+/JP5Fe0kprgho25FeSW1bndM9Rd\ngVYL/3fhePLK63jsix18saWA08cmExzQ8RCfyymjEqmqb2RtG7+Ivfz9Hu5/fzOnjkpiaGI4b2Xk\neKr5brPZHbz43R7GD4gmISKYea9lHDnicRTKr6hj3oI19IsKYf6VU90KgNoTEmjl9tnDGRjn3qjQ\nKaNMiQR3hvo+31xA1oEa7j5jJGeN7cebP+VQ18nl09zRJ4Mp1zBfw4Es+O9ZsOIpmPYruP4bsxSM\nl5V1IZi67vh0IkMCePKbnV1+7o6iKoKsFtLi2/8LGhMWRHknZvMVVh4kKTKk6fW0tFjqbQ62tBP4\nbS+sIi0+zK18Ck+KDQ/i/7d35/FRV+cexz9nZrLvK4EQSMIWwi5hVQFxw7q16FW0dam7dr2ttdre\nVmtvb6u2ttW6Vq37vu9SK4iirLIHwk4gJGQh+56Zc/+Y+YWQzGR+k0kyk/C8Xy9fkMlM8uuvJHly\nznO+z7ghMQHrm3rzmyJy0mLI9XF8jCfGWJnu+qZeW3cQu0Nz2YwRXd5ntSiuOSWLpf89j5NGJmB3\n6G4zgTrLTI6iuc1BSS+E5tU2tbLobyu45LGvg+5kTl9rbrPzu/fyyUqO4o5v5fCvq2dS19zG1U+t\npcbL6Ut3Ptji3OI7q4+3+DrKy0xkyYwMnlq5j5qmNs7zsVfr5NHJ2CyKZW62+h5Zvoe7389n0YQ0\nHv3edC6dkcH6A5XsLu3fUVEfbimmqKqRn5w+hseumE5lQwu3vLC+V05aD1RGllRTq50nrsozlWfW\n29LjI8hJi/EakaC15qFlu8lOjmLRxDSumptJdWMrb28s6vVrGpTFVHldM+daVnHFpiugfLdzS++8\n+yGkZ2GJ/qroQTEVFxHC90/O4uNtJT1e/t99pI7slCiv20sJkaHUNrd1f/qxg9KazitTzn6b7sI7\ndx6pY1w/Np93NCs7kfUHKt1m4/SlvWV1bDxYxeKTfBtq3J2xQ2KwKM8n+ozG85NHJ7VHGbiTkRjJ\ns9fM5IvbTvNpZSo7ufcGHr+wupDKhlY2H6rmd+/l+/3xBpKnvtzPvvJ67jw/lzCbldxhsTx2xXT2\nlNVx47PrfSoujaDOU8ek9MsWX0e/XJRDYlQoMeE2ThltvigH5wGRvMyE4/KmtNb87dOd3PPxDi6Y\nMox/XD6NUJuFxScNx2ZRvLK2/1antNY89vleRqVEsTAnlYnpcdxz0WTW7q88rvn+RKK15tbXN7Ht\ncA1/XzK139s2Ojp9fCrrDlR2O+Jo+c4y8otruGnBKKwWxYzMBHKHxvL0yv29Hj486IqpNruDBU2f\n8lDoAxTZRsBNX8CEbwf0mirrW4gMtfq8KnPtyVlEh9l48D89G4mys7TW6xYfQEKU8xuwmfl8Rvp5\nauyxlakhseEMT4jweKKvscXO/or6gH3hzcxKpKHFztY+SA/vztsbirAoTB8VNiM8xMqolGiPK1NG\n4/llM7uuSnWmlDK9rG4wCjR/D0c0tdp54ot9nDommZsXjOLF1YW8vv6QXx9zoCipbuLBz3Zxxvgh\nLBh3bMbnyaOTue+/JvP13gp+8dpm01upmw5VU1TV6HUWX19IiArln1dO54El09wOUvfmtHGp7Cip\npbi6Ea01935SwN8+3cXF04fz10untv8imBwdxhnjh/DmN0X9tir05e5y8otruHHeqPaZqhdOTeem\n+aN4YXUhL6zum96bYPbgZ7v5YHMxty/K4fTxfd9v3J2FOanYHZoVOz0fYnh42W6GxYXzbdf3YKUU\nV8/NpOBILat8jFbwZtAVU5W1DfzU+gYbHdn8LOqPkNCzEwa9yewomc7iIkO4em4mH24tbu9/Mquh\npY2DRxtNpY37koJu5MKkxoQd93ieK7zTXbVvNML390k+w8wA9U19ubuck0YkMKRD4dkbujvR99Ka\nY43nfSEtNpwwm8XvlanX1h2kvK6ZWxaM5udnjmVOdhK/fmuLXz2CA8UfP9pOm0Pz2/Nyu7zvO9OG\nc9uicby76TD3fLLD1Mf7YPNhQqyKM3ID88Nt+sjE9h4WXxmvW7ajjN+/v51Hlu/h8lkjuPeiyVg7\nDYW/dEYGFfUtHjPTetvjK/aSGhPGhdOODyH9xdnjWDAuhTvf2caaAMeu9KePthRz/793snhaOjfM\nyw705TA1I4GEyBCPfVNr9h1l7f5KbpiXfVyhf8HUYSREhvD0V/t69XoGXTHVuuFFMixlPG65hJK6\n4OjD8GWUTGfXnpJFZIjV596p3aXOUw7eTvKBb/P5jPTz1E4FwvTMREprm91me/XHTL7upMaGk5Uc\n1a/f+NrsDvKLa7rNS+mp8UNjKapq7FL8Hqlp4tPtXRvPe5NzdqR/J/pa7Q4e/XwvJ42IZ3Z2Ijar\nhQcum0Z8ZAg3v7C+22X7gW7NvqO8s/EwN87LZoSHXsab54/iitkjeezzvR5nl9kdmvzDNTy9ch9v\nbShi3pgU4iL6d4uvN4xJjWZYXDj/9+F2nlq5j++fnMkfvj2xfSWoo3ljU0iLDe+Xrb6tRdV8sauc\n75+c1aWp3mpR/H3JNDISI7nlhfVdwksHk/rmNr7YVcZflhbws1c3MW1EPP+3eJJfJ/d6i9WiWDAu\nleUFpW6HZj+0bDdJUaFc2ql3NDzEypKZI/h3/hEOVfZeTMLgKqbsrSSsf4BNjmwq0uZTXtccFJPJ\nfRkl01lCVChXzc3kgy3F7PJhdWrnEWcxZWqbz7UyZeZEn5F+3rFnCmC6a67bugNdC5adR2oJtVkY\n6eOWUm+amZnImn1He+0Umje7y+poanUwaXjvNJ53ZDSzd16d6q7xvDdlJkX5tc337sbDFFU18oPT\nRrd/U06JCePh755EUWUjP391U6/9/3TXu9s4/8Ev++3/9+7YHZo7393GsLhwblkw2uPzlFLcdcEE\nzswdwl3vbePjrcW02h18U1jJo5/v4Zqn1zL17qV864EvuOu9fMJDrF6zeYKVUorTclKpa27jpvmj\n+O15uR5/UFstiounD+fznWWUVPdtcvo/v9hLVKiVy2e5/1qKiwjhn1dOp6nVwQ3PreuT02GBUN3Q\nyqf5R/i/D7dz4UMrmfy7pVzx5BoeXr6HScPjeOyK6f1+iKg7C3NSqWxoZePB41tMthZV8/nOMq45\nJcvtmCxjbuBzvRiTMLiKqc2vEFF3kL+3LWb8sDgc+lgsQSAd9WGUjDvXnZpNRIiVBz8z3zu164jz\nJJ+ZAubYfD4T23wd0s87GpcWQ0yYzW3eVEFJLaNTonslZ6mnZmUnUtPU1r5K1teMPJpJ6XG9/rHH\nD3UWyB37phwmG897Q2ZyFAePNvSood/h0Dy8fDc5aTEs7LQ1NH1kIr8+dzyfbj/CYyv2+n2dJdVN\nvLD6AFuKqlm+M/Bz4F5cfYDtxTX8+txcr3MQrRbFA0umMTUjnh+/tJHJdy1l8cNf8aePdnCgop7z\nJg/jb5dOZeXtC/nylwuZPtJ7gn2wuvWscfzr6hn8ctE4rysel+Rl4NDw+vq+W506eLSB9zcXc/ms\nEd2u9o1OjeFvl05l2+Eabn9zc683NPenL3eVs+hvK5j6+6Vc9+w6nl65nzCrhZvnj+LZa2ay6c6z\nePXGOced4g4G88amYLWoLlt9Dy/fTUyYjSvmuG/zSY+P4OwJabzSizEJPR8UFmzsbbDiz5TFjOez\nsmnc4/qBU1brDJgMpKN1PeuZMiRGhXLlnEweW7GHH58+htFe+qBKqpv4ZFsJo1PNFTBGoWdmm69j\n+nlHVoti6oh4t0noO4/U+nRirC/MzHL+sFm9t6I9XqAvbS2qJjLU2j4aqDelxoSTHB123Im+Fa7G\n8zu+ldPrn6+z7OQoWu2aw1VNHreqPFmaX8KesnoeuGya2x+cV8/NZP2BSu77ZAdThsd1mRrvi399\ntQ+7Q5MUFcoTX+xjYU7gGmaP1rfw56U7mZOdxLcmmetniwi18uRVM/ift7eQGhPOrKxE8jITA/79\nrLclRIWa7rkakRTJnOwkXll3kFsWjHa7HdhZS5uDpfklnJ4zxGsRC/Dkl/tQOONpvDkjdwg/P3Ms\nf166kx3FzjmoI5MiGZnk/HNEYiTD4iO69H/5amtRNXaHZkpG77cNbD5UxQ3PrSMtNpyfnTGWmVmJ\nTMmID6oVKE/iIkLIG5nAf7aX8ouznd/7dpfW8dHWEm5ZMIrYcM/F8FVzM/loawnvbCxiiYkDO94M\nnpWpLa9C5T6WD/0+oVYr2SnOH2JldYENWGtqtVPfYjc9SsaT60/NItxm5R+fdd87tfNILYsfXkl5\nXQv/c954Ux87IsRKqM1irgG9Q/p5Z3kjEyk4UntcTk51YyvF1U0BPUILMDwhkvT4CNZ0E9/Qm7YU\nVTNxWJzf30Q9MZLQDX3deN7RsRN9vg08dma+7CEzKdLjyTOlFPdcNJnslGh+9NKGHm/n1Da18uKq\nQs6ZNJQb5mXz1Z4Kth3um/TquuY2r6sSf15aQF1zG7+70Lek6MSoUB7+7nTuumAC50waOugKqZ64\ndEYGB482mh7Bc/f72/jhixu4/IlVXncqKutbeGXtQS6YOoxh8eaidH5w2mhuPyeH9IQIdpbW8q+V\n+/nVW1v47hOrOfXeZeT85iMW/nk5jyzf06Pt5nc3HWbxw19xyWNfs/lQlc+v705hRQPXPL2WhMhQ\nXr5hNj86fQyzspMGRCFlWJjjPBFq9K49+vkewmwWr8XwrKxEctJiePor7zEJdofmjx9u7/Y5g6OY\nsrfB5/dC2mRW22aRHB3aftos0Gm1RtyAPytTAEnRYVw5ZyTvbjrMXg8R+qv2VnDxI1/R6tC8cuNs\n5o4yP9rBbAp6aW0TqbHuv6FPH5mA1rCh8NgXvNHnNS6t91dofDUzy9k31dfL8Ubz+cQ+2OIz5A6N\nZdeROlrtDkr7ofG8o8xk52qUryf6vthVzpaiam52Zb54EhVm49HvTaep1d7jgMSX1hRS29zGjfOy\nWTJzBJGhVp78sndP7zgcmrve3cbEOz9h7p8+4ycvb+CF1QfYXVp73L+xrUXVvLSmkCvnjAz4LxWD\nwaKJacSE20wlor/5zSGeX1XIwpxU8g/XcNEjX1FY4bnp+PlVB2hstft0Wk0pxU3zR/HU1TP47OcL\n2P77RXz5y9N48bpZ/HHxJK45JYshseHc8/EObnnhG59mDD7xxV5+/NIGpmS4EtifXU9pLwTmgnO1\n9Op/raHVrnnmmhldDhUNFKePP5aGfqiygbc3FLFkxgiSo7v/xcOISdhRUtvt4aSqBud98tZ6MDiK\nqS2vQeU+mP9LyutbSIoOa/8NzjjKHygV9c5iLjHK/5M218/LJsxm5R/LuvZOvb/5MFc+uYaUmDDe\numUuE4b59oM8ITLU3DZfTXOXfinD1BHxWBTH9U0VtBdTfb+15s2srETK61r8zkjypi+bzw25w2Jp\nsTvYU1bHq/3UeG5IiQ4jOszG/m5+KLnz0LLdDI0LNzVaZ3RqNPdcPJlvCqu492NzEQGGljYHT325\nnznZSUweHk9cRAiX5GXw3qbD7Qco/GV3aH711hae/mo/35mWzvSRCXy1p4Jfv7WVM+5fQd7/fspN\nz63nqS/38T9vbyUxMpSfnjG2Vz73iS48xMp3pqXz0dYSqrv5nrW9uIZfvbWFWVmJPH7FdF64bhZH\n61tY/MhKtzP2mlrtPPP1fhaMSyHHj+9XVotieEIkc0cnc9nMEdxxznhevH4Wv/7WeJbml7D44a84\n4OU0rMOhufu9fP73g+2cO2koz107i39emUdNUyvXP7fe7xFMTa12rntmLYeqGnniqjxGpw7cIn9U\nSjQZiRF8tqOUf7oKHrPF8IVT04mLCOFpD6dmC0pqufChlazaW8GfFk/q9mMN/GLK3gYr7oMhkyDn\nXMrrmkmODiUy1EZ0mC3gK1OVrjEtiVH+L88nR4fxvdkjeGfj4eNWBZ78ch8/emkDk4fH8cbNcxme\n4PupufjIEJPbfE1dTvIZosNsjB8ay/oOJ/p2ltQSHWZjWFzgf+s51jfVt1t9fdl8bjD6vrYV1fRb\n47lBKUVmcqRPRem6/UedA31PzTa9enbe5GF8b/YInly5r9t0/c7e3XSYkpombpx/7Bvq90/OpM2h\nefbr/aY/jidtdge/eG0TL689yI8Xjub+S6bwj8tPYs2vTmf5rQu496LJLBiXyrbiau5+P5+NB6v4\n5aKcARldEKwuycugpc3BO5vcjwWpaWrl5ufXExsewoOXT8NmtZCXmcgbN88hzGbl0se/Pi55HeCN\nbw5RXtfCjfN6/2SkUorr52XzzDUzKalp4oJ/rOSLXe7DJpta7fzopQ08tXIf15ycxYOXTSM8xJmS\nf/8lU9l0sIrb3+h5w7vdofnxSxvYcLCKv186tX1+6UCllOL0nCGs3F3Oy2sPsvikdNNbtBGhVpbM\nzGBp/hGKOkVcfLy1mO88vJKGFjsv3zDHa1/VwC+mtr4BR/fA/NtAKSrqWtqX91JiwgJeTB1tMEbJ\n9M430uvnZWOzKP6xbDcOh+Z/38/n9+/nc3ZuGs9fN6s9gNNXZlammlq7pp93Nn1kAhsKq9pPehUc\nqWXskOigyCXJSo4iOTqsz8M7+7L53JCdHEWozcITX+4znXjemzKTonza5nto2W4So0JZMjPDp89z\n+znjGRYXwW1vbDb127jWmsdX7CEnLYb5HWYOjkyK4qzcIbywutCv0zutdgc/eXkjb24o4tazxvKz\ns46dQHMWmVFcMiODv1wyhS9uW8hXty/kpetn8195vTPoWjhNTI9jwrBYXl7TdatPa82tr27iYGUj\nD333pONOoI1OjeGtW+aSmRTFtc+s41XXVqHdoXnii31MHh7H7Oy+Ky5OHZPCuz88mbTYcK56ag3/\nXLH3uKKouqGVK59awwdbivmfc8fz2/Nzj2uyXzQxjVvPGsvbGw/z6Oe+n3jVWvO797axNP8Ivz0v\nl3MCkJrfF07LSaW5zUGL3cFN830rhq+YPRKtNc+7YhIcDs39Swu46flvGDMkhvd+eEr7yLTuDOxi\nymF3rkqlToCc89BaU1Hn3OYD53ZEwIspVwO8vz1ThtSYcL47ayRvbSjiumfX8cSX+7h6biYPffck\nv5oG4yNDva5MGbEIndPPO5o+MoGGFjs7Spx9IwUltQGbydeZUopZWYms7uO+qb5uPgewWS2MG+Js\nQu+vxvOOspOjOFTZYKqfadvhapYVlHHNyZlEhvp2gDg6zMYfF09ib1m9qeDa5QVl7DxSxw3zsrsU\n8Nedmk1VQytvfNOzsTXNbXZueeGb9h90P1w4xutrhsVHMGdUUlD8MjHYXDojg/ziGrYWHb9l99iK\nvSzNP8Id5+S4XXVJjQ139ZQmcdvrm3ngP7tYuq2EfeX13DhvVJ//fzUyKYo3b5nL2RPS+MOH2/nZ\nq5toarVTVNXIxY9+xcbCKh64bBrXnep+q+oHp43m/CnDuPeTHXya71sa/GMr9vLs1we4YV62qdOK\nA8WsrERiwm2cO2lo++Ezs4YnRHJm7hBeXlNIWW0zNzy3jgc+281/TR/OKzfMJs3krsrALqa2vgkV\nu5yrUhYLNY1ttNgdJLtOzgXHylQrStHjFSN3bprvXJ36bEcpd5yTw53n5/r9gzshMoSqhtZui4wj\nxiiZblam8lzfvNYfqKS8roXKhtagarqdmZVIcXWT26T23tAfzecGI2+qvxrPO8pMjsKhofCo976p\nh5fvITrMxhVzMnv0ueaNTeHi6cN5bMXeLj84O3v08z0MjQvn/CnDurwvb2QCU4bH8dSX+3w+VdXU\naueGZ9fz7/wj3H3hBI8/6ET/uXBKOqE2y3GJ6F/vqeDej3dw7qShXHuK52IhJjyEJ6+aweJp6dz/\n753c+tomRiRGsmhi//xSEhVm4+HvnuRaZSrioke+YvHDKympaeKZa2ZygZt/vwalFPddPJlJ6XH8\n5OUNFJSYy857Z2MRf/poB+dPGcbti/o+QqU/hYdY+eBHp3LPRZN79Pqr5mZS2dDKwr8sZ1lBGb+7\nYAL3XjzZpwWKgVtMOeyw4l5IzYXxFwBQ7mr2NprPg6GYqqxvIT4ipFdXKVJjw3ngsmk8dXUeN87v\nnd+kEiJDaXNoars5aeIp/byj9PgIhsaFs+5AZfs8wUDN5HNnVrYxp69v+qb6o/nccNKIBGwWxZJ+\najzvyOjP8rbVt7esjg+3FHPFnJF+9Qz95txcEqNCue31zbR6CAvdeLCK1fuOcu0pWYS4yVdTSnHt\nqdnsLa9nWYH5EM+GljaueXotK3aVcc9Fk7iyh0Wh6F1xkSGcMzGNtzcW0dRq50hNEz966RuykqO4\n5+LJXr8vhtos/OWSKdyyYBT1LXZunJ/dp6vJnSml+OHCMTxxZR6FFQ0oFK/dNIc5o7xn8oWHWHn8\nijyiwmxc+8xaj5EPRnL+Pz7bxa2vbWJ2diJ//q/JpvK5BpoRSZFEhfUsOnNOdhIThsUSYrXw/LWz\nuGpups8/VwduaOe2t6B8J1z8L7A4v3GWuwqnpKhjxVRtcxuNLXZTYW194Wh9Cwl+pJ97cvaE3v0N\nyrjGyvoWj0FnntLPOztpZALr9x9lmitgLlAz+dwZmxpDXEQIq/dVcNH03u9j6Y/mc8PF04dzypjk\nHh048Fe2UUx5OZX06Od7CLVauMbPLYW4yBB+f+FEbnp+PY99vsftFtvjK/YQE27rtlH0nIlpDIsL\n54kv9pmael/b1Mo1T69l/YFK7r9kiqmTiKL/XJqXwTsbD/PepsO8svYgDS12Xrp+NtEmf6gqpbht\nUQ6XzxpBusmm5d52+vghfHbrAkJtFp9+4UiLC+fxK/O45LGvufn59Tx37SzsDs2Gg5WuIb9H+eZA\nFY2uXsOZmYk8dkVel1mDwvnv4MXrZoOix7/0DcxiyuFw9kql5EDut9sfLq9zVufJMce2+ZyPN5MR\noLlwR+tbSOqDYqq3dRx2PNLDL0ae0s87yxuZwAebi1lWUEpSVKjXvI/+ZLEoZrjm9PWF/mg+N9is\nloAUUuDcto6PDPF4oq+5zc6fPtrBq+sOcfXczF4Jm1w0MY1zJw3lgf/s5uwJacfNndxfXs/HW0u4\ncf6obn+QhlgtXDU3kz9+tIOtRdXdbsfuKavjxufWs7+8ngcvO4lzJw+OZt3BZHZ2EhmJEfz67a20\ntDl44LJppuaRdhaoryNDT78+pmbEc9/Fk/nJyxs54/7PKa5upNWuUQrGp8Vy6YyMQZuc39vivPxc\n82ZgFlM73oOyHXDRk+2rUnAs06njaT6A0trAFVOVDS2MCOCAX7PiTQw7Lusm/byjPNecsC93lzM7\nK7BjZNyZlZXIp9uPcKSmiSG9HFTXH83nwcLTib7dpXX86KUNbC+u4eq5mdx+Tu/1Z9x1wQRW7inn\ntjc28/pNc9vv8xNf7sVmsfD9uZleP8aSmSP4+3928dSX+7j/0qlun/Np/hH++5WNhNgsPHvtTNMB\nuKJ/WSyKS/My+PPSnVw9N7PbXqPB6sKp6RyqbGTZjlLOmZTGrKxEpo9MlCiOfmaqZ0optUgpVaCU\n2q2Uut3N+/+qlNro+m+nUqp3M+872/EBRKXAhO8c93B5bTMWdezkXEq0kYIeuODOinr/hhz3F2Nl\nqrsTfUe6ST/vaPzQGCJCrGhN0Jzk66iv+qb6s/k8GGQnH19Maa15ZW0h5z/4JSXVjTx5VR53XTCh\nV0dTpMSEcef5uWworGoP2quoa+a1dYf4zrR0UynORojnu25CPB0OzV//vZPrnl1HZnIU7/3oFCmk\ngty1p2Tz10un8KtvmRufNRj94LTRvH7zXO44ZzwLc4ZIIRUAXosppZQVeAg4B8gFLlNK5XZ8jtb6\nv7XWU7XWU4EHgTf74mLbFa6CEbPBcvw36bI6Z+Fi/LZq/OAPVBO61prKAVNMGT1TnrOmuks/78hm\ntTDV6JcKouZzQ+7QWKJCrazu5byp/mw+DwaZyVEcrm6iscVOdWMrP3xpA798YwvTRsTz8U/nmepJ\n6olvT03ntHEp/PmTAgorGnjm6wM0tzm43ocRINecnIVdHx/iWdPUyvXPruPv/9nFxdOH89pNcwLW\nRyPMiwi18p1p/X+iVYiOzPzrmwns1lrv1Vq3AC8DF3bz/MuAl3rj4tyqKYaqAzBiTpd3VdQ1H9ef\nkxQVhkUFrpiqbW6jzaEHRDEVGxGCUt2vTJXWmFuZAsjLdIacBcNMvs5sVgvT+6Bvqj+bz4OBcaLv\nrQ1FfOvvX/Dx1hJuWzSO566d1evbpx0ppfjDdyZhtShufX0Tz329nzPGD2F0qvl/ayOSIjk7N40X\nVhfS0NLGriO1XPiPlXy+s4zfXziB+3w8Fi2EOLGZKabSgY4xs4dcj3WhlBoJZAGfeXj/DUqpdUqp\ndWVl7qP0vTq4yvlnxuwu7yqvayYp+ljhYrUoEqPCKKsLTDF1tM5IPw/+YspqUcRFhHhMQTfSz83+\nkFx80nAWT0vmXJS8AAAaZElEQVT3eUZgf5mVlcjOI3Vep8j7oj+bz4OBcaLvV29tQSl47aY53LJg\ndL/0iw2Lj+COb+WwZt9RKhtauWm+77lP152aRVVDK798YwvffmgltU1tvHj9bK6Y4/uxaCHEia23\nG9CXAK9rrd3Oa9BaPw48DpCXl9ezCOrC1WCLgKFdw7nK61qYNiL+uMdSYsLaj/T3N2OUTF9EI/QF\n50gZ98WFmfTzjrKSozw29wYDY07f2v1Hey1mYktRNROGxZ4QzecA2SlRpMWGMzMrkf/9zkSPkRp9\n5bIZI1i2owy7w9EeFuuL6SMTmJIRz3ubDjM1I55HvzfddNqxEEJ0ZKaYKgI6DtQa7nrMnSXAD/y9\nqG4dXAXD88Da9Rt3520+cP7wD9TKVKVr1SOxF9PP+5KRgu6OmfTzgWTy8DjCQyy8vKaQM8cP8TvE\nzmg+v3zmyF66wuAXGWrj6zsWBmwVx2JR/PPK6fR0MpBSij98eyKf7yzjulOzJH9HCNFjZrb51gJj\nlFJZSqlQnAXTu52fpJTKARKAr3v3EjtoroPizZAxq8u7Glvs1LfYj9vmg8CmoFfUD5xtPnCuTHna\n9jKTfj6QhNms/OLsHJYVlPHXT3f6/fH2lNWfUM3nhkBvhyml/CqEJ6bH8YPTRkshJYTwi9diSmvd\nBvwQ+ATYDryqtd6mlLpbKXVBh6cuAV7WfTlBtmg9aLvzJF8n5XXHZ0wZUmLCKK9r9nkWV2+oHGDF\nVHfDjo9t8w2OlSmAa07O5JK84Tz42W7e3XTYr4+1+ZAzDeREaT4XQghxjKmeKa31h8CHnR77bae3\n7+q9y/KgcBWgYPiMLu8yiqmUzsVUdBitdk11Y2u/9y4dbWgh1GYhMkCjbHyVEOm5Af1IbRMhVtWe\nRzUYKKX4/bcnsq+8nl+8tonMpEgmD4/3/kI3TrTmcyGEEMcMrGCOg6ucg40juv7AM0bJuNvmA2cK\nen87WuccJRPorRCzEqJCaWy109Ta9fxAWU0zqTHhA+Z/i1lhNiuPfG86ydFhXP/sui4hjmadaM3n\nQgghjhk4xZTDDgfXut3iA8/bfMbps0D0TVU2tLSHYQ4E8e0p6F1Xp8ymnw9EydFh/PPKPGqb2rjh\n2XVui8nuGM3nk9J7tqolhBBiYBs4xdSRbdBS67GYqnAVU537k4yVqbK6/h8pc3SApJ8bErqZz2c2\n/Xygyh0Wy18vncqmQ9X88o3N+NL6d6I2nwshhHAaOMXUwdXOP92c5APnNl9MuK1LanFKAFemBlox\nZaxMuSumfEk/H6jOnpDGrWeN5Z2Nh3nk8z2mXyfN50IIcWIbOMVU4SqIGQbxI9y+u6yuuUvzOUB0\nmI3wEEuvBnc2tdr544fbOVzV2O3zBloxZaxMdd7m8zX9fCD7wWmjOX/KMO77pICl20pMvUaaz4UQ\n4sQ2sIqpEbPAQwN0RadRMgalFKkx4b0a3Pn+5mIeW7GX37y91eNzWu0OapraBlTPlFH4dV6Z8jX9\nfCBTSnHfxZOZlB7HT1/ZyI6SGq+vkeZzIYQ4sQ2MYqr6ENQccjuPz1Be19Kl+dzQ28GdL64+gM2i\n+M+OUj7bccTtc4yCJNFNgRes2rf5OgV3Drb0c2/CQ6w8fkUe0WE2rvnXWkqqPffbSfO5EEKIgVFM\nFbqGG3toPgfnaT6PxVR07xVTO0pq+Kawip+dNZbslCjufi+f5raup78q651bZQNllAw4YwIiQ61d\nsqYGW/q5GWlx4Tx19QyqG1u5+l9rqG1yn78lzedCCCEGTjEVEgVDJrp9d6vdQVVDq9ttPnCtTPXS\nNt/Law4SarWwZMYI7jp/AvsrGnjii31dnmeMZUmIGlghl+6GHQ/G9HMzJqbH8cj3prO7tI6bnl9P\nS5ujy3Ok+VwIIcTAKKbahxu7D2w3ChdPK1OpMWFUNbS6XUHyRWOLnTe+OcQ5k9JIjApl3tgUzsod\nwj8+201x9fHN6MY1JUUNrNWceDfDjgdj+rlZ88am8KeLJrNyd4XbyARpPhdCCBH8xVRTjTNjasQc\nj08xtvC665mCYynpPfXBlmJqm9q4bOaxE4W/OS8Xh9b834c7jnvu0YbBszI1WNPPzbp4+nB+fuZY\n3tpQxH2fFBz3Pmk+F0IIEfzF1KG1oB3Ok3weVLSvTHne5gP/s6ZeWlNIdkoUs7IS2x/LSIzkxvmj\neG/TYVbtrWh/3GjiHkin+cDzytRgz5jy5ocLR3PZzBE8vHwPz606AEjzuRBCCKfgL6YOrgZlcTvc\n2FBucmXKn2KqoKSW9QcquXzmiC4rNDfPH0V6fAR3vbuNNruzr+ZofQux4TZCrMF/iztytzI12NPP\nzVBK8fsLJ3B6Tip3vrOVpdtKpPlcCCEEMBCKqcKvnY3nYTEen9I+l89DDtKxYcc9Hynz0ppCQq0W\nFp80vMv7IkKt/Oa88ewoqeWF1YXAwAvsNCREhlDd2Irdcaw36ERIPzfDZrXw4OXTmDQ8nh+/vIHn\nVu0HpPlcCCFOdMFdTNnb4ND6biMRwLnNF2azEBVqdft+Y8WqpytTjS123uzQeO7O2RPSOGV0Mn9Z\nWkBFXbNzyPFALKaiQtEaahqdW30nUvq5GZGhNp68Ko8hseE8v6pQms+FEEIEeTF1ZAu01nstpspr\nnRlTnhqkQ6wWEqNCe1xMfbClmJpOjeedKaW464JcGlrs3PdJARV1LSQNxGLK1eNlNNAbsQgpJ0D6\nuVnJ0WE88/2ZJEaFMmV4vDSfCyHECc591kCwMMI6u0k+B+dcPk9bfAZ/gjvdNZ67Mzo1hqvnZvLk\nyn2E2SxMGDbwemmMFPQqVzFlpJ/LytTxMpOj+ODHp2A9QU84CiGEOCa4V6YKV0FcBsSld/u0iroW\nkr2sAvU0uLO7xnN3fnLGGJKiwmhqdQyoUTIGY2XKSHA/EdPPzRoaF3HCjNgRQgjhWfAWU1q7hht3\nvyoF3Y+SMaTGhLVvWfmiu8Zzd2LCQ7j9nBxgYI2SMbQXU522+U609HMhhBDCrODd5qs6AHUlkOE5\nXwrA4dBU1LeQHGNuZUprbTp80mg8XzTRc+O5O4unpdPQ0sZZuWmmXxMs4qOMbT7XytQJnH4uhBBC\nmBG8xVThauefXlamjGP83sa2pMSE0dLmoKapjbgIc4WB0Xh++SzPjefuWCyKK+dk+vSaYBETZsNm\nUe0rUyd6+rkQQgjhTfBu8xV+DWGxkJrb7dO8ZUwZehLcabbxfDBRShEfGUJlh5UpyZgSQgghPAve\nYurgamfqucV9dpTBaCr3NErGkBLtW3Cnr43ng0l8ZOix03ySfi6EEEJ0KziLqcZKKN3e7XBjQ0Wd\nMZfPSwN6rG8rU742ng8miR1Gykj6uRBCCNG94CymDq4FdLfDjQ3t23xeiqmUaOfqipliqqeN54NF\nfGQIlfWtkn4uhBBCmBCkxdQqUFZIn+71qeV1zVgtingvTeWxETZCrRZTWVOf7yylpqmNJTMyTF/y\nYGIMO5b0cyGEEMK74CymDq2FtIkQGuX1qeW1zoHCFi8jPZRSzngEEytTy3aUERNuY+YJ1HjeUXxU\nCFUNrZTUSPq5EEII4U3wFVMOOxRtgPQ8U0+vqPce2GkwU0xprVlWUMq8MSnYrMF3e/pDQmQoLXYH\n+yvqAUk/F0IIIboTfNVC+S5oqYXh5oqpsroWryf5DGaKqfziGkprm1kwLsXUxxyMjIDOgpJaQNLP\nhRBCiO4EXzFVtM75p4l+KYDy2t5dmVpeUAbA/BO4mIp3jZTZeaRW0s+FEEIIL4KvmDq0DsLiIGmM\n16dqrV3bfCZXpqLDONrQQqvd4fE5ywtKmZQed0Kvxhjz+XaU1Er6uRBCCOFF8BVTReshfRpYvF9a\nfYudplaHTytTWh/LpuqsuqGV9QcqOe0EXpUCSHTN5yurbZaMKSGEEMKL4CqmWhrgyDaftvgAkkwW\nU6leRsqs2FWGQ8P8cammPt5gZWzzwbF7JoQQQgj3gquYKt4E2u7TST7wPkrG0D6fr879SJllBaXE\nR4YwNSPe1McbrDpmdkksghBCCNG94CqmitY7/zS5MlVWa26UjKG7YccOh2bFzjLmj03B6iWzarCz\nWS3EhNsAKaaEEEIIb4KsmFoHcRkQM8TU082OkjEYz3NXTG09XE15XQunneBbfAajCV3Sz4UQQoju\nBVkxtd70qhQcayRPMrnNFx5iJS4ihFI3xdSyHWUoBfPGntjN5wYjDkFWpoQQQojuBU8xVVcGVYWm\nwzrBuTIVHxlCiA9J5Z6yppYVlDJlePwJOdjYHaMJXRrQhRBCiO4FTzHlY1gnOIupJB+Ln5TorsVU\nRV0zmw5VyRZfB7IyJYQQQpgTRMXUelBWGDrV9Esq6lpM90sZUmLCKKs7vphasasMreG0HNniM6TE\nhBEeYpH0cyGEEMILW6AvoN2hdTAkF0IjTb+kvK6Z8cNiffo0qTFhlNY0o7VuT/ZeXlBGcnQoE4fF\n+fSxBrPr52Vz1oQ0ST8XQgghvAiOlSmHA4q+8WmLD6CsrplkX7f5YsJobLVT32IHwO7QfL6zjHlj\nU7Cc4JEIHaXGhDMjMzHQlyGEEEIEveAopo7ugeZq02GdAM1tdmqb2nq0zQfH4hE2HqyiqqFV+qWE\nEEII0SPBUUwdcjWf+3CSz4hFSPbxtFnnYmp5QSkWBfPGSL+UEEIIIXwXHMVU0ToIjYbksaZfYgR2\n+nyar1MxtayglOkjE4iTRmshhBBC9EDAiqnaprZjbxSth2HTwGI1/fqerkylxjiP+pfWNlFa28TW\nohoWyBafEEIIIXooYMVUcXWj8y+tTVCy1actPqA93iDFx56p+IgQbBZFWW0znxeUAbBgnGzxCSGE\nEKJnAhaN0NLmwO7QWEs2g6PV55N87dt8JkfJGCwWRbIruPNARQOpMWHkDvUtXkEIIYQQwhCwlSkN\nHK5qdG7xgU8n+cC5zRcZaiUy1Pd6MCUmjOLqJlbsKuO0camSpSSEEEKIHgtoA/r+inrnSb7YdIgd\n6tNry+uafY5FMKTGhLFm31Fqm9pki08IIYQQfglsMVVe7zzJl36Sz68tr2v2eYvPkBITRovdgc2i\nOHlMco8+hhBCCCEEBLCYsihFSclhqNzv8xYf9Gwun8GIR8jLTCA2XCIRhBBCCNFzASumQq0WQoq/\ncb7h40k+8G+bzyimJPVcCCGEEP4KXDFls5BQtRmUBYZO9em1dofmaH0LyT3c5hs7JIZQq4Uzc4f0\n6PVCCCGEEIaARSOE2SxkNu1Ap+WgwqJ9em1lQwsOTY9XpmZnJ7HxzjN7dBJQCCGEEKKjgK5MTVZ7\nqE/xbVUKjmVM9bSYAqSQEkIIIUSvCFgxFa7aSFB1HI7K9fm15bXOUTI9Pc0nhBBCCNFbAlZMhekm\nAAps43x+bUW9/ytTQgghhBC9wVQxpZRapJQqUErtVkrd7uE5lyil8pVS25RSL3r7mNa2Bup1GBub\nfAvrBCirNYopWZkSQgghRGB5bRxSSlmBh4AzgUPAWqXUu1rr/A7PGQPcAZysta5USnnPHGhtYI9t\nIvuONvl80UVVjYSHWIiLkIwoIYQQQgSWmZWpmcBurfVerXUL8DJwYafnXA88pLWuBNBal3r9qK2N\nlMRMdI6U8dH24hpy0mJlpp4QQgghAs5MMZUOHOzw9iHXYx2NBcYqpVYqpVYppRa5+0BKqRuUUuuU\nUuvQDupTpnLwaANtdofpC9Zak3+4hvFDY02/RgghhBCir/RWA7oNGAMsAC4D/qmUiu/8JK3141rr\nPK11HoA1I49Wu6a42vxW3+HqJmqa2sgdGtM7Vy6EEEII4QczxVQRkNHh7eGuxzo6BLyrtW7VWu8D\nduIsrjyzhpCang3AvnLzW33bD9cAkDtMVqaEEEIIEXhmiqm1wBilVJZSKhRYArzb6Tlv41yVQimV\njHPbb2+3HzV6CFkpzuRzX/qm8oudxdS4NCmmhBBCCBF4XosprXUb8EPgE2A78KrWeptS6m6l1AWu\np30CVCil8oFlwC+01hXdfuCoFFJjwogIsbK/vMH0BW8vrmFkUiTRYZJgLoQQQojAM1WRaK0/BD7s\n9NhvO/xdAz9z/WeaUoqRSZE+rUxtL64hV5rPhRBCCBEkApaAbshKjmK/yZ6puuY29lc0yEk+IYQQ\nQgSNgBdTI5OiOFhpLh6hoMTVfC7FlBBCCCGCRMCLqazkSFrtmsNV3uMR8l0n+cbLST4hhBBCBImA\nF1OZSVGAuRN9+cW1xIbbGBYX3teXJYQQQghhSuCLqWTzxdT24hpyh8kYGSGEEEIEj4AXU0Y8grfg\nTrtDs6NExsgIIYQQIrgEvJgy4hEOVHSfNbW/op6mVocUU0IIIYQIKgEvpsBcPML2YjnJJ4QQQojg\nExTFVGay93iE/MM12CyKMUOi+/HKhBBCCCG6FxzFVJL3eITtxTWMTo0mzGbtxysTQgghhOhekBRT\nzhN9+7o50be9uFb6pYQQQggRdIKjmHLFIxzwUEwdrW+hpKaJ8UNj+vOyhBBCCCG8CopiKjUmjMhQ\nz/EIx5rP4/rzsoQQQgghvAqKYsoZj+D5RJ9RTMnKlBBCCCGCTVAUU+BsQveUNZV/uIbUmDCSosP6\n+aqEEEIIIboXPMVUchSFR93HI+S7xsgIIYQQQgSb4CmmkiJpc3SNR2hpc7CnrE5O8gkhhBAiKAVR\nMeU+HmFXaS2tdi3J50IIIYQISkFTTGW54hE6N6FvL64FkJUpIYQQQgSloCmmUlzxCPsrOhdTNYSH\nWNqLLSGEEEKIYBI0xZSneIT8wzWMS4vFalEBujIhhBBCCM+CppiCrvEIWmu2l9SQK/lSQgghhAhS\nwVVMdYpHKKlpoqqhVfqlhBBCCBG0gqqYykqKos2hKapqBJxbfICc5BNCCCFE0AqqYmpkUiQA+11b\nfcYYmRwppoQQQggRpIKqmOocj7C9uJaRSZFEh9kCeVlCCCGEEB4FVTFlxCPscxVT+cU1jE+TVSkh\nhBBCBK+gKqaMeIQDFfU0tLSxv6Jems+FEEIIEdSCqpgCyEqOZH9FAztKatEaGXAshBBCiKAWdMXU\nyKQoDh5tYMuhagDGS8aUEEIIIYJY0BVTRjzCp9uPEBtuIz0+ItCXJIQQQgjhUdAVU0Y8wld7Khg/\nNBalZIyMEEIIIYJX0BVTRjyC3aGl+VwIIYQQQS/oiikjHgGk+VwIIYQQwS/oiikjHgFkjIwQQggh\ngl/QFVPgjEewWhSjU6MDfSlCCCGEEN0Kyjktl88cyYRhcYSHWAN9KUIIIYQQ3QrKYuqUMcmcMiY5\n0JchhBBCCOFVUG7zCSGEEEIMFFJMCSGEEEL4QYopIYQQQgg/SDElhBBCCOEHKaaEEEIIIfwgxZQQ\nQgghhB+kmBJCCCGE8IMUU0IIIYQQfpBiSgghhBDCD1JMCSGEEEL4QYopIYQQQgg/SDElhBBCCOEH\nKaaEEEIIIfygtNaB+cRK1QIFAfnkg0cyUB7oixjg5B76T+6h/+Qe+kfun//kHno3Umud4u4dtv6+\nkg4KtNZ5Afz8A55Sap3cQ//IPfSf3EP/yT30j9w//8k99I9s8wkhhBBC+EGKKSGEEEIIPwSymHo8\ngJ97sJB76D+5h/6Te+g/uYf+kfvnP7mHfghYA7oQQgghxGAg23xCCCGEEH4ISDGllFqklCpQSu1W\nSt0eiGsYaJRSTymlSpVSWzs8lqiU+rdSapfrz4RAXmMwU0plKKWWKaXylVLblFI/cT0u99AkpVS4\nUmqNUmqT6x7+zvV4llJqtevr+RWlVGigrzXYKaWsSqkNSqn3XW/LPfSBUmq/UmqLUmqjUmqd6zH5\nWvaBUipeKfW6UmqHUmq7UmqO3MOe6/diSillBR4CzgFygcuUUrn9fR0D0NPAok6P3Q78R2s9BviP\n623hXhvwc611LjAb+IHr353cQ/OagYVa6ynAVGCRUmo2cA/wV631aKASuDaA1zhQ/ATY3uFtuYe+\nO01rPbXDcX75WvbN34GPtdY5wBSc/x7lHvZQIFamZgK7tdZ7tdYtwMvAhQG4jgFFa70CONrp4QuB\nZ1x/fwb4dr9e1ACitS7WWn/j+nstzm8c6cg9NE071bneDHH9p4GFwOuux+UeeqGUGg6cCzzhelsh\n97A3yNeySUqpOGAe8CSA1rpFa12F3MMeC0QxlQ4c7PD2IddjwndDtNbFrr+XAEMCeTEDhVIqE5gG\nrEbuoU9c21MbgVLg38AeoEpr3eZ6inw9e/c34DbA4Xo7CbmHvtLAUqXUeqXUDa7H5GvZvCygDPiX\na7v5CaVUFHIPe0wa0AcJ7TyWKUczvVBKRQNvAD/VWtd0fJ/cQ++01nat9VRgOM5V5pwAX9KAopQ6\nDyjVWq8P9LUMcKdorU/C2S7yA6XUvI7vlK9lr2zAScAjWutpQD2dtvTkHvomEMVUEZDR4e3hrseE\n744opYYCuP4sDfD1BDWlVAjOQuoFrfWbroflHvaAa0tgGTAHiFdKGaOp5Ou5eycDFyil9uNscViI\ns3dF7qEPtNZFrj9LgbdwFvbytWzeIeCQ1nq16+3XcRZXcg97KBDF1FpgjOv0SiiwBHg3ANcxGLwL\nXOX6+1XAOwG8lqDm6kt5Etiutb6/w7vkHpqklEpRSsW7/h4BnImz92wZcLHraXIPu6G1vkNrPVxr\nnYnze99nWuvvIvfQNKVUlFIqxvg7cBawFflaNk1rXQIcVEqNcz10OpCP3MMeC0hop1LqWzj7BqzA\nU1rrP/T7RQwwSqmXgAU4J3sfAe4E3gZeBUYAB4BLtNadm9QFoJQ6BfgC2MKxXpVf4eybkntoglJq\nMs6mVCvOX8Re1VrfrZTKxrnKkghsAL6ntW4O3JUODEqpBcCtWuvz5B6a57pXb7netAEvaq3/oJRK\nQr6WTVNKTcV5CCIU2At8H9fXNXIPfSYJ6EIIIYQQfpAGdCGEEEIIP0gxJYQQQgjhBymmhBBCCCH8\nIMWUEEIIIYQfpJgSQgghhPCDFFNCCCGEEH6QYkoIIYQQwg9STAkhhBBC+OH/AemYhexFTq3uAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_df[['val_acc','acc']]\n",
    "acc.columns = ['val_acc', 'train_acc']\n",
    "acc.plot(figsize=(10, 6), title='Val acc & Train acc vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8RiTO3yLDXy"
   },
   "source": [
    "#### **Let's plot learning rate vs epochs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "o2ggKlccOAHA",
    "outputId": "ea40c994-b4b7-46ee-a2dc-6d3834d3a0d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5b60d9f278>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAF1CAYAAABChiYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = history_df[['lr']]\n",
    "lr.plot(figsize=(10, 6), title='Learning rate vs epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEjAnQK9Mhfy"
   },
   "source": [
    "#### **Let's evaluate the best model, on the validation set and compute relevant metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKttpsSSFyfD"
   },
   "outputs": [],
   "source": [
    "#uploaded = files.upload()\n",
    "res_cnn.load_weights('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "hkPgAlWuF0t4",
    "outputId": "60c629ab-a730-47d6-fd54-67d6619c62aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc:\n",
      " 0.8287545787545788\n",
      "\n",
      "Confusion Matrix:\n",
      " [[229 130   5]\n",
      " [ 29 333   2]\n",
      " [ 11  10 343]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     C4-7_pos       0.85      0.63      0.72       364\n",
      "       C5_pos       0.70      0.91      0.80       364\n",
      "all_other_pos       0.98      0.94      0.96       364\n",
      "\n",
      "     accuracy                           0.83      1092\n",
      "    macro avg       0.85      0.83      0.83      1092\n",
      " weighted avg       0.85      0.83      0.83      1092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0.83755\n",
    "X, y_true = next(val_generator)\n",
    "y_pred = res_cnn.predict(X)\n",
    "for i in range(1, len(val_generator)):\n",
    "  X, y = next(val_generator)\n",
    "  y_true = np.vstack((y_true, y))\n",
    "  y_pred = np.vstack((y_pred, res_cnn.predict(X)))\n",
    "\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "#roc_auc = roc_auc_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = [k for k in val_generator.class_indices]\n",
    "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "print('\\nval_acc:\\n', val_acc)\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', c_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCyuxkmCWFmc"
   },
   "source": [
    "## **Let's evaluate the best model when loaded from GoogleDrive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "qUocxlDZwrmQ",
    "outputId": "73a923f0-136b-410f-be5c-425853149af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded content: \"base_model_C4-7_C5_083.h5\"\n",
      "Root dir content: ['.config', 'Patches', 'gdrive', 'base_model_C4-7_C5_08223.h5', 'base_model_C4-7_C5_083.h5', 'adc.json', 'base_model.h5', 'base_model_C4-7_C5_082875.h5', 'history_dict.json', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "file_id = '1-4e6W-yR13q3ckpgo8O9QVMTncWITHwg' # final model_C4-7_C5_2_0.8223\n",
    "\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile(downloaded['title'])\n",
    "print('Downloaded content: \"{}\"'.format(downloaded['title']))\n",
    "print('Root dir content: {}'.format(os.listdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tEWiFP8Wit9"
   },
   "source": [
    "#### **Results when creating a fresh network and only weights are loaded:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxt1DQx0WhqH"
   },
   "outputs": [],
   "source": [
    "classes = list(iter(train_generator.class_indices))\n",
    "n_classes = len(classes)\n",
    "layers_per_block = [4, 4, 4, 4] #18 layers total with first conv and last FC\n",
    "n_filters = [64, 128, 256, 512]\n",
    "kernel_sizes = [(3,3), (3,3), (3,3), (3,3)]\n",
    "l2_reg = 0.1\n",
    "optimizer = RMSprop # Adamax, RMSprop, Adam (No: Nadam, SGD)\n",
    "lr = 1e-3\n",
    "decay = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "res_cnn = make_resnet(img_size, n_classes, layers_per_block, n_filters,\n",
    "                       kernel_sizes, l2_reg, optimizer, lr, decay, momentum)\n",
    "#load weights:\n",
    "res_cnn.load_weights(downloaded['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "7o2tsHVcRFge",
    "outputId": "c26f816c-6cab-4917-836d-7a345c0b3a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc:\n",
      " 0.8315018315018315\n",
      "\n",
      "Confusion Matrix:\n",
      " [[229 130   5]\n",
      " [ 29 333   2]\n",
      " [ 11   7 346]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     C4-7_pos       0.85      0.63      0.72       364\n",
      "       C5_pos       0.71      0.91      0.80       364\n",
      "all_other_pos       0.98      0.95      0.97       364\n",
      "\n",
      "     accuracy                           0.83      1092\n",
      "    macro avg       0.85      0.83      0.83      1092\n",
      " weighted avg       0.85      0.83      0.83      1092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y_true = next(val_generator)\n",
    "y_pred = res_cnn.predict(X)\n",
    "for i in range(1, len(val_generator)):\n",
    "  X, y = next(val_generator)\n",
    "  y_true = np.vstack((y_true, y))\n",
    "  y_pred = np.vstack((y_pred, res_cnn.predict(X)))\n",
    "\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "#roc_auc = roc_auc_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = [k for k in val_generator.class_indices]\n",
    "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "print('\\nval_acc:\\n', val_acc)\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', c_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-yH-sS3XikP"
   },
   "source": [
    "#### **Results when loading the entire model (not just weights):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYFZl3FRxqAi"
   },
   "outputs": [],
   "source": [
    "#uploaded = files.upload()\n",
    "final_model = load_model(downloaded['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "hkeC7XBBZVvj",
    "outputId": "38c96492-075d-4778-ae49-47b9544b0382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc:\n",
      " 0.8315018315018315\n",
      "\n",
      "Confusion Matrix:\n",
      " [[229 130   5]\n",
      " [ 29 333   2]\n",
      " [ 11   7 346]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     C4-7_pos       0.85      0.63      0.72       364\n",
      "       C5_pos       0.71      0.91      0.80       364\n",
      "all_other_pos       0.98      0.95      0.97       364\n",
      "\n",
      "     accuracy                           0.83      1092\n",
      "    macro avg       0.85      0.83      0.83      1092\n",
      " weighted avg       0.85      0.83      0.83      1092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y_true = next(val_generator)\n",
    "y_pred = final_model.predict(X)\n",
    "for i in range(1, len(val_generator)):\n",
    "  X, y = next(val_generator)\n",
    "  y_true = np.vstack((y_true, y))\n",
    "  y_pred = np.vstack((y_pred, final_model.predict(X)))\n",
    "\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "#roc_auc = roc_auc_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = [k for k in val_generator.class_indices]\n",
    "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "print('\\nval_acc:\\n', val_acc)\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nClassification Report:\\n', c_report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "'C4-7' vs 'C5' vs all_other (downsample).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
