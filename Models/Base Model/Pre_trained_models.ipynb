{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initial Base_Model with pre-trained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOP-GdfHXmLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization,\\\n",
        "                          Conv2D, MaxPooling2D, Flatten, AveragePooling2D,\\\n",
        "                          GlobalAveragePooling2D, ZeroPadding2D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import RMSprop, Adam, Adamax, Nadam, SGD\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, \\\n",
        "                            classification_report\n",
        "\n",
        "# Import PyDrive and associated libraries (to connect with GoogleDrive)\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DItexGaqdfEA",
        "colab_type": "text"
      },
      "source": [
        "### **Check if we are using GPU:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn7AYx74dNq6",
        "colab_type": "code",
        "outputId": "b1a9b036-626b-40cb-f267-273ce5df4deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras import backend as K\n",
        "if K.backend() == \"tensorflow\":\n",
        "    import tensorflow as tf\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name == '':\n",
        "        device_name = \"None\"\n",
        "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)\n",
        "    print('keras version:', keras.__version__)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow version: 1.15.0 , GPU: /device:GPU:0\n",
            "keras version: 2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQXfhMrHlqrz",
        "colab_type": "text"
      },
      "source": [
        "### **Download Patches from GoogleDrive:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACvUlEucnnY0",
        "colab_type": "code",
        "outputId": "41524dd3-237a-45bb-9569-3a6e00fc080a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1M_CrRxfsb5y2STHQGGA5IvcUTtA6HidU' #128x128_s60_no border_minpospix_1250 minposval_1024 Downsampled Control\n",
        "#file_id = '1Dwc0vZ-Atmq1-y3bQoMS_M0ReBB5-ewS' #128x128_s56_no border_minpospix_1250 minposval_1024 Downsampled Control\n",
        "#file_id = '1kttFmwfFRrIVTq_ERVWV83wAi4arr1Q0' #128x128_s60_no border_minpospix_1024 minposval_1024 Downsampled Control\n",
        "\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile(downloaded['title'])\n",
        "print('Downloaded content: \"{}\"'.format(downloaded['title']))\n",
        "print('Root dir content: {}'.format(os.listdir()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content: \"Patches_128_s60_min1250_minval_1024_no_border_nonNeg_noStreak_downsampledControl.zip\"\n",
            "Root dir content: ['.config', 'adc.json', 'Patches_128_s60_min1250_minval_1024_no_border_nonNeg_noStreak_downsampledControl.zip', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSdGQav-qEJM",
        "colab_type": "text"
      },
      "source": [
        "### **Unzip the Patches:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP1-2THkn47w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3cb567b-2b15-4b35-b411-88b795358e95"
      },
      "source": [
        "# Remove 'Patches' dir if it already exists\n",
        "if 'Patches' in os.listdir():\n",
        "  shutil.rmtree('./Patches')\n",
        "with zipfile.ZipFile(downloaded['title'],\"r\") as zip:\n",
        "    zip.extractall()\n",
        "os.remove(downloaded['title'])\n",
        "print('Root dir content: {}'.format(os.listdir()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root dir content: ['.config', 'adc.json', 'Patches', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiJP7bNcrqI1",
        "colab_type": "text"
      },
      "source": [
        "### **Let's count patches by type and location:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHNY_50qpMOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "20fa8b69-0380-4edb-cfec-94588a4a9350"
      },
      "source": [
        "class_weights = {} # empty dictionary to store class weights\n",
        "classes = ['C1','C2-3','C4-7','C5','C6','C8','C9','C10']\n",
        "\n",
        "grand_total, pos_total, neg_total = 0, 0, 0\n",
        "for type in ['Serial', 'Control', 'Streak']:\n",
        "    print(\"\\nTotal '{}' Patches per location:\".format(type))\n",
        "    n_type, type_pos, type_neg = 0, 0, 0\n",
        "    class_weights[type] = {} # nested empty dictionary to store class weights\n",
        "    class_weights[type]['pos'] = {} # nested dictionary to store class weights\n",
        "    class_weights[type]['neg'] = {} # nested dictionary to store class weights\n",
        "    for cls in classes:\n",
        "        pos_folder = './Patches/Positive/{}/{}_pos'.format(type,cls)\n",
        "        neg_folder = './Patches/Negative/{}/{}_neg'.format(type,cls)\n",
        "        n_pos = len(os.listdir(pos_folder))\n",
        "        n_neg = len(os.listdir(neg_folder))\n",
        "        total = n_pos + n_neg\n",
        "        n_type += total\n",
        "        type_pos += n_pos\n",
        "        type_neg += n_neg\n",
        "        print('total_{}: {} = {} positive + {} negative'.format(cls,total,n_pos,n_neg))\n",
        "        class_weights[type]['pos']['{}'.format(cls)] = 1/n_pos if n_pos else 0\n",
        "        class_weights[type]['neg']['{}'.format(cls)] = 1/n_neg if n_neg else 0\n",
        "    print('Total {}: {} = {} positive + {} negative'.format(type,n_type,type_pos,type_neg))\n",
        "    for loc in class_weights[type]['pos'].keys():\n",
        "        class_weights[type]['pos'][loc] *= type_pos\n",
        "    for loc in class_weights[type]['neg'].keys():\n",
        "        class_weights[type]['neg'][loc] *= type_neg\n",
        "    grand_total += n_type\n",
        "    pos_total += type_pos\n",
        "    neg_total += type_neg\n",
        "print('\\nGRAND TOTAL: {} = {} positive + {} negative'.format(grand_total,pos_total,neg_total))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total 'Serial' Patches per location:\n",
            "total_C1: 743 = 743 positive + 0 negative\n",
            "total_C2-3: 1410 = 1410 positive + 0 negative\n",
            "total_C4-7: 3057 = 3057 positive + 0 negative\n",
            "total_C5: 1518 = 1518 positive + 0 negative\n",
            "total_C6: 848 = 848 positive + 0 negative\n",
            "total_C8: 1105 = 1105 positive + 0 negative\n",
            "total_C9: 508 = 508 positive + 0 negative\n",
            "total_C10: 1957 = 1957 positive + 0 negative\n",
            "Total Serial: 11146 = 11146 positive + 0 negative\n",
            "\n",
            "Total 'Control' Patches per location:\n",
            "total_C1: 373 = 373 positive + 0 negative\n",
            "total_C2-3: 373 = 373 positive + 0 negative\n",
            "total_C4-7: 373 = 373 positive + 0 negative\n",
            "total_C5: 373 = 373 positive + 0 negative\n",
            "total_C6: 373 = 373 positive + 0 negative\n",
            "total_C8: 373 = 373 positive + 0 negative\n",
            "total_C9: 373 = 373 positive + 0 negative\n",
            "total_C10: 373 = 373 positive + 0 negative\n",
            "Total Control: 2984 = 2984 positive + 0 negative\n",
            "\n",
            "Total 'Streak' Patches per location:\n",
            "total_C1: 0 = 0 positive + 0 negative\n",
            "total_C2-3: 0 = 0 positive + 0 negative\n",
            "total_C4-7: 0 = 0 positive + 0 negative\n",
            "total_C5: 0 = 0 positive + 0 negative\n",
            "total_C6: 0 = 0 positive + 0 negative\n",
            "total_C8: 0 = 0 positive + 0 negative\n",
            "total_C9: 0 = 0 positive + 0 negative\n",
            "total_C10: 0 = 0 positive + 0 negative\n",
            "Total Streak: 0 = 0 positive + 0 negative\n",
            "\n",
            "GRAND TOTAL: 14130 = 14130 positive + 0 negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYIdPd1HYCA",
        "colab_type": "text"
      },
      "source": [
        "#### **Since we have imbalanced training data, we have set different class weights to give more importance to the minority classes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sl8nkEeroKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4cdf6270-9281-44f8-e8ff-c158295fd881"
      },
      "source": [
        "print('Class Weights:', str(json.dumps(class_weights['Serial'], indent=2, default=str)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Weights: {\n",
            "  \"pos\": {\n",
            "    \"C1\": 15.001345895020188,\n",
            "    \"C2-3\": 7.904964539007093,\n",
            "    \"C4-7\": 3.6460582270199544,\n",
            "    \"C5\": 7.342555994729908,\n",
            "    \"C6\": 13.143867924528301,\n",
            "    \"C8\": 10.086877828054298,\n",
            "    \"C9\": 21.940944881889763,\n",
            "    \"C10\": 5.695452222789985\n",
            "  },\n",
            "  \"neg\": {\n",
            "    \"C1\": 0,\n",
            "    \"C2-3\": 0,\n",
            "    \"C4-7\": 0,\n",
            "    \"C5\": 0,\n",
            "    \"C6\": 0,\n",
            "    \"C8\": 0,\n",
            "    \"C9\": 0,\n",
            "    \"C10\": 0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNJ7lSKQpdOT",
        "colab_type": "text"
      },
      "source": [
        "#### **Let's build image generators, using keras.preprocessing.image.ImageDataGenerator, rescaling image pixel values from [0,  255] to [0, 1]:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UANfdA6IUFKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "421983c7-055c-455c-9cd1-e48c1d30cea4"
      },
      "source": [
        "#warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "c1_pos_folder = './Patches/Positive/Serial/C1_pos'\n",
        "img = plt.imread(c1_pos_folder + '/' + os.listdir(c1_pos_folder)[:5][0])\n",
        "img_size = img.shape\n",
        "train_batch_size = 32\n",
        "val_batch_size = 64\n",
        "\n",
        "# datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True,\n",
        "#                              vertical_flip=True)\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(\"For training:\")\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        './Patches/Positive/Serial',\n",
        "        target_size=(img_size[0],img_size[1]),\n",
        "        batch_size=train_batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        "\n",
        "print(\"\\nFor validation:\")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        './Patches/Positive/Control',\n",
        "        target_size=(img_size[0],img_size[1]),\n",
        "        batch_size=val_batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "#warnings.filterwarnings(\"once\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For training:\n",
            "Found 11146 images belonging to 8 classes.\n",
            "\n",
            "For validation:\n",
            "Found 2984 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR5UXKYgHsvx",
        "colab_type": "text"
      },
      "source": [
        "#### **Let's check what is the training generator's index for each class, so we can correclty set up the class weights:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv9rJZlFHtYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "94af0199-2495-49b2-f7a5-da436b1159f7"
      },
      "source": [
        "print('train_generator.class_indices:', str(json.dumps(train_generator.class_indices, indent=2, default=str)))\n",
        "#print('validation_generator.class_indices:', str(json.dumps(val_generator.class_indices, indent=2, default="
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_generator.class_indices: {\n",
            "  \"C10_pos\": 0,\n",
            "  \"C1_pos\": 1,\n",
            "  \"C2-3_pos\": 2,\n",
            "  \"C4-7_pos\": 3,\n",
            "  \"C5_pos\": 4,\n",
            "  \"C6_pos\": 5,\n",
            "  \"C8_pos\": 6,\n",
            "  \"C9_pos\": 7\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a1IrvgIH1Pp",
        "colab_type": "text"
      },
      "source": [
        "#### **Let's set up the class weights in correct order:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4c9uWrH1os",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "58652c67-767c-4ac4-8619-f7d0447358a4"
      },
      "source": [
        "serial_pos_weights = [class_weights['Serial']['pos']['C10']] # C10 has index 0\n",
        "for cls in classes:\n",
        "    if cls == 'C10': continue\n",
        "    serial_pos_weights.append(class_weights['Serial']['pos']['{}'.format(cls)])\n",
        "print('original class weights dictionary:')\n",
        "print(str(json.dumps(class_weights['Serial']['pos'], indent=2, default=str)))\n",
        "print('class weights for generator, re-arranging indexes:')\n",
        "print(str(json.dumps(serial_pos_weights, indent=2, default=str)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original class weights dictionary:\n",
            "{\n",
            "  \"C1\": 15.001345895020188,\n",
            "  \"C2-3\": 7.904964539007093,\n",
            "  \"C4-7\": 3.6460582270199544,\n",
            "  \"C5\": 7.342555994729908,\n",
            "  \"C6\": 13.143867924528301,\n",
            "  \"C8\": 10.086877828054298,\n",
            "  \"C9\": 21.940944881889763,\n",
            "  \"C10\": 5.695452222789985\n",
            "}\n",
            "class weights for generator, re-arranging indexes:\n",
            "[\n",
            "  5.695452222789985,\n",
            "  15.001345895020188,\n",
            "  7.904964539007093,\n",
            "  3.6460582270199544,\n",
            "  7.342555994729908,\n",
            "  13.143867924528301,\n",
            "  10.086877828054298,\n",
            "  21.940944881889763\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLzEQJeEOobF",
        "colab_type": "text"
      },
      "source": [
        "### **pre-trained VGG16:**\n",
        "\n",
        "#### **Let's build and compile our baseline model, using VGG16 pre-trained model from keras and adding trainable layers:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoEPWdJYOqcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "d0e07fc7-26a3-4295-b9f7-389c6d762a62"
      },
      "source": [
        "pre_trained = VGG16(weights='imagenet', include_top=False,\n",
        "                    input_shape=(128, 128, 3))\n",
        "\n",
        "for layer in pre_trained.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "#x = Flatten()(pre_trained.output)\n",
        "\n",
        "x = pre_trained.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "base_model = Model(input=pre_trained.input, output=predictions)\n",
        "base_model.classes = classes\n",
        "\n",
        "lr = 1e-3\n",
        "decay = 0.05 # 0.05\n",
        "optimizer = RMSprop # (RMSprop, Adam, Adamax, Nadam)\n",
        "\n",
        "if optimizer == keras.optimizers.Nadam:\n",
        "    base_model.compile(optimizer(lr=lr, schedule_decay=decay),\n",
        "                loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "else:\n",
        "    base_model.compile(optimizer(lr=lr, decay=decay), \n",
        "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 14,718,792\n",
            "Trainable params: 4,104\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twS5-nrvO6wX",
        "colab_type": "text"
      },
      "source": [
        "### **Let's train and validate our baseline model (pre-trained VGG16):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjCPC3Aywp7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "116e2fbb-9065-4d6e-9b33-6cbeab6b4b4c"
      },
      "source": [
        "## VGG16\n",
        "\n",
        "epochs = 50 #100\n",
        "\n",
        "train_steps = train_generator.n//train_generator.batch_size\n",
        "val_steps = val_generator.n//val_generator.batch_size\n",
        "\n",
        "# Callbacks:\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=3, \n",
        "                                   verbose=1, mode='min', min_lr=1e-9)\n",
        "EarlyStop = EarlyStopping(monitor='val_acc', patience=30, verbose=1,\n",
        "                          min_delta=0, mode='max')\n",
        "checkpoint = ModelCheckpoint('base_model.h5', monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [reduce_lr, checkpoint, EarlyStop] #order matters!\n",
        "\n",
        "#base_model.load_weights('base_model.h5')\n",
        "\n",
        "history = base_model.fit_generator(train_generator, steps_per_epoch=train_steps,\n",
        "                            validation_data=val_generator,\n",
        "                            validation_steps=val_steps, epochs=epochs,\n",
        "                            verbose=1, callbacks=callbacks_list, shuffle=False,\n",
        "                            class_weight=serial_pos_weights)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "348/348 [==============================] - 14s 40ms/step - loss: 1.7695 - acc: 0.4003 - val_loss: 2.0347 - val_acc: 0.2276\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22758, saving model to base_model.h5\n",
            "Epoch 2/50\n",
            "348/348 [==============================] - 12s 35ms/step - loss: 1.6968 - acc: 0.4247 - val_loss: 1.9980 - val_acc: 0.2387\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.22758 to 0.23870, saving model to base_model.h5\n",
            "Epoch 3/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6715 - acc: 0.4300 - val_loss: 1.9846 - val_acc: 0.2432\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.23870 to 0.24315, saving model to base_model.h5\n",
            "Epoch 4/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6570 - acc: 0.4365 - val_loss: 1.9757 - val_acc: 0.2455\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.24315 to 0.24555, saving model to base_model.h5\n",
            "Epoch 5/50\n",
            "348/348 [==============================] - 12s 35ms/step - loss: 1.6437 - acc: 0.4392 - val_loss: 1.9679 - val_acc: 0.2469\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.24555 to 0.24692, saving model to base_model.h5\n",
            "Epoch 6/50\n",
            "348/348 [==============================] - 12s 35ms/step - loss: 1.6354 - acc: 0.4405 - val_loss: 1.9602 - val_acc: 0.2473\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.24692 to 0.24726, saving model to base_model.h5\n",
            "Epoch 7/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6305 - acc: 0.4396 - val_loss: 1.9681 - val_acc: 0.2507\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.24726 to 0.25068, saving model to base_model.h5\n",
            "Epoch 8/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6220 - acc: 0.4441 - val_loss: 1.9674 - val_acc: 0.2507\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.25068\n",
            "Epoch 9/50\n",
            "348/348 [==============================] - 12s 35ms/step - loss: 1.6184 - acc: 0.4446 - val_loss: 1.9587 - val_acc: 0.2514\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.25068 to 0.25137, saving model to base_model.h5\n",
            "Epoch 10/50\n",
            "348/348 [==============================] - 12s 35ms/step - loss: 1.6124 - acc: 0.4451 - val_loss: 1.9587 - val_acc: 0.2521\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.25137 to 0.25205, saving model to base_model.h5\n",
            "Epoch 11/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6100 - acc: 0.4451 - val_loss: 1.9534 - val_acc: 0.2521\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.25205\n",
            "Epoch 12/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6072 - acc: 0.4466 - val_loss: 1.9508 - val_acc: 0.2521\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.25205\n",
            "Epoch 13/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.6049 - acc: 0.4453 - val_loss: 1.9430 - val_acc: 0.2527\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.25205 to 0.25274, saving model to base_model.h5\n",
            "Epoch 14/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5978 - acc: 0.4480 - val_loss: 1.9446 - val_acc: 0.2534\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.25274 to 0.25342, saving model to base_model.h5\n",
            "Epoch 15/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5991 - acc: 0.4469 - val_loss: 1.9367 - val_acc: 0.2541\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.25342 to 0.25411, saving model to base_model.h5\n",
            "Epoch 16/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5941 - acc: 0.4495 - val_loss: 1.9407 - val_acc: 0.2548\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.25411 to 0.25479, saving model to base_model.h5\n",
            "Epoch 17/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5915 - acc: 0.4482 - val_loss: 1.9341 - val_acc: 0.2555\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.25479 to 0.25548, saving model to base_model.h5\n",
            "Epoch 18/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5873 - acc: 0.4529 - val_loss: 1.9336 - val_acc: 0.2565\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.25548 to 0.25651, saving model to base_model.h5\n",
            "Epoch 19/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5882 - acc: 0.4477 - val_loss: 1.9476 - val_acc: 0.2572\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.25651 to 0.25719, saving model to base_model.h5\n",
            "Epoch 20/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5895 - acc: 0.4504 - val_loss: 1.9459 - val_acc: 0.2582\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.25719 to 0.25822, saving model to base_model.h5\n",
            "Epoch 21/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5816 - acc: 0.4510 - val_loss: 1.9440 - val_acc: 0.2582\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.25822\n",
            "Epoch 22/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5837 - acc: 0.4517 - val_loss: 1.9433 - val_acc: 0.2586\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.25822 to 0.25856, saving model to base_model.h5\n",
            "Epoch 23/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5819 - acc: 0.4509 - val_loss: 1.9421 - val_acc: 0.2586\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.25856\n",
            "Epoch 24/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5789 - acc: 0.4510 - val_loss: 1.9461 - val_acc: 0.2524\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0007225000590551645.\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.25856\n",
            "Epoch 25/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5784 - acc: 0.4528 - val_loss: 1.9565 - val_acc: 0.2373\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.25856\n",
            "Epoch 26/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5816 - acc: 0.4493 - val_loss: 1.9553 - val_acc: 0.2380\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.25856\n",
            "Epoch 27/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5736 - acc: 0.4553 - val_loss: 1.9554 - val_acc: 0.2377\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0006141250254586339.\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.25856\n",
            "Epoch 28/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5744 - acc: 0.4536 - val_loss: 1.9543 - val_acc: 0.2380\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.25856\n",
            "Epoch 29/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5753 - acc: 0.4540 - val_loss: 1.9532 - val_acc: 0.2380\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.25856\n",
            "Epoch 30/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5773 - acc: 0.4501 - val_loss: 1.9474 - val_acc: 0.2428\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005220062914304435.\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.25856\n",
            "Epoch 31/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5738 - acc: 0.4526 - val_loss: 1.9320 - val_acc: 0.2555\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.25856\n",
            "Epoch 32/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5708 - acc: 0.4547 - val_loss: 1.9277 - val_acc: 0.2586\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.25856\n",
            "Epoch 33/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5691 - acc: 0.4557 - val_loss: 1.9278 - val_acc: 0.2582\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.25856\n",
            "Epoch 34/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5724 - acc: 0.4537 - val_loss: 1.9265 - val_acc: 0.2592\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.25856 to 0.25925, saving model to base_model.h5\n",
            "Epoch 35/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5730 - acc: 0.4518 - val_loss: 1.9308 - val_acc: 0.2545\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.25925\n",
            "Epoch 36/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5715 - acc: 0.4523 - val_loss: 1.9176 - val_acc: 0.2603\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.25925 to 0.26027, saving model to base_model.h5\n",
            "Epoch 37/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5719 - acc: 0.4512 - val_loss: 1.9166 - val_acc: 0.2606\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.26027 to 0.26062, saving model to base_model.h5\n",
            "Epoch 38/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5682 - acc: 0.4570 - val_loss: 1.9120 - val_acc: 0.2606\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.26062\n",
            "Epoch 39/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5673 - acc: 0.4540 - val_loss: 1.9163 - val_acc: 0.2606\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.26062\n",
            "Epoch 40/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5717 - acc: 0.4527 - val_loss: 1.9137 - val_acc: 0.2606\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.26062\n",
            "Epoch 41/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5690 - acc: 0.4522 - val_loss: 1.9150 - val_acc: 0.2606\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00044370535761117935.\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.26062\n",
            "Epoch 42/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5681 - acc: 0.4540 - val_loss: 1.9451 - val_acc: 0.2442\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.26062\n",
            "Epoch 43/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5655 - acc: 0.4554 - val_loss: 1.9551 - val_acc: 0.2404\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.26062\n",
            "Epoch 44/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5715 - acc: 0.4509 - val_loss: 1.9471 - val_acc: 0.2438\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00037714955396950245.\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.26062\n",
            "Epoch 45/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5637 - acc: 0.4564 - val_loss: 1.9511 - val_acc: 0.2418\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.26062\n",
            "Epoch 46/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5700 - acc: 0.4505 - val_loss: 1.9513 - val_acc: 0.2411\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.26062\n",
            "Epoch 47/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5636 - acc: 0.4561 - val_loss: 1.9519 - val_acc: 0.2397\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003205771208740771.\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.26062\n",
            "Epoch 48/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5717 - acc: 0.4509 - val_loss: 1.9090 - val_acc: 0.2588\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.26062\n",
            "Epoch 49/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5611 - acc: 0.4569 - val_loss: 1.9024 - val_acc: 0.2613\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.26062 to 0.26130, saving model to base_model.h5\n",
            "Epoch 50/50\n",
            "348/348 [==============================] - 12s 34ms/step - loss: 1.5687 - acc: 0.4519 - val_loss: 1.9062 - val_acc: 0.2610\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.26130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coNt7qVfQorX",
        "colab_type": "text"
      },
      "source": [
        "### **pre-trained VGG16 didn't work...**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szmg5n7WQGOb",
        "colab_type": "text"
      },
      "source": [
        "### **pre-trained ResNet50:**\n",
        "\n",
        "#### **Let's build and compile our baseline model, using Resnet50 pre-trained model from keras and adding trainable layers:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YIn2laORMvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3872e9f-8829-48be-bb27-326a4a318f5b"
      },
      "source": [
        "classes = list(iter(train_generator.class_indices))\n",
        "n_classes = len(classes)\n",
        "\n",
        "pre_trained = ResNet50(weights='imagenet', include_top=False,\n",
        "                       input_shape=(128, 128, 3))\n",
        "for layer in pre_trained.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "#x = GlobalAveragePooling2D()(last)\n",
        "x = Flatten()(pre_trained.output)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "base_model = Model(input=pre_trained.input, output=predictions)\n",
        "base_model.classes = classes\n",
        "\n",
        "lr = 1e-3\n",
        "decay = 0.05 # 0.05\n",
        "optimizer = RMSprop # (RMSprop, Adam, Adamax, Nadam)\n",
        "\n",
        "if optimizer == keras.optimizers.Nadam:\n",
        "    base_model.compile(optimizer(lr=lr, schedule_decay=decay),\n",
        "                loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "else:\n",
        "    base_model.compile(optimizer(lr=lr, decay=decay), \n",
        "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 64, 64, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 64, 64, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 32, 32, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 32, 32, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 32, 32, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 32, 32, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 16, 16, 128)  32896       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 16, 16, 512)  131584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 16, 16, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 16, 16, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 16, 16, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 8, 8, 256)    131328      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 8, 8, 1024)   525312      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 8, 8, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 8, 8, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 8, 8, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 8, 8, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 4, 4, 512)    524800      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 4, 4, 2048)   2099200     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 4, 4, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 4, 4, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 4, 4, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 4, 4, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 4, 4, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 4, 4, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 4, 4, 2048)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 32768)        0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 8)            262152      flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,849,864\n",
            "Trainable params: 262,152\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjit-S6SE_Q",
        "colab_type": "text"
      },
      "source": [
        "### **Let's train and validate our baseline model (pre-trained ResNet50):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1d7iToOKmVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48b18cf0-013c-4646-8796-94fad0327183"
      },
      "source": [
        "epochs = 50 #100\n",
        "\n",
        "train_steps = train_generator.n//train_generator.batch_size\n",
        "val_steps = val_generator.n//val_generator.batch_size\n",
        "\n",
        "# Callbacks:\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=5, \n",
        "                                   verbose=1, mode='min', min_lr=1e-9)\n",
        "EarlyStop = EarlyStopping(monitor='val_acc', patience=30, verbose=1,\n",
        "                          min_delta=0, mode='max')\n",
        "checkpoint = ModelCheckpoint('base_model.h5', monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [reduce_lr, checkpoint, EarlyStop] #order matters!\n",
        "\n",
        "#base_model.load_weights('base_model.h5')\n",
        "\n",
        "history = base_model.fit_generator(train_generator, steps_per_epoch=train_steps,\n",
        "                            validation_data=val_generator,\n",
        "                            validation_steps=val_steps, epochs=epochs,\n",
        "                            verbose=1, callbacks=callbacks_list, shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0606 - acc: 0.9779 - val_loss: 3.7564 - val_acc: 0.1267\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.12670, saving model to base_model.h5\n",
            "Epoch 2/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0560 - acc: 0.9803 - val_loss: 3.7308 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.12670 to 0.12774, saving model to base_model.h5\n",
            "Epoch 3/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0499 - acc: 0.9816 - val_loss: 3.7307 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.12774\n",
            "Epoch 4/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0512 - acc: 0.9812 - val_loss: 3.7351 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.12774\n",
            "Epoch 5/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0523 - acc: 0.9809 - val_loss: 3.7206 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.12774\n",
            "Epoch 6/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0456 - acc: 0.9849 - val_loss: 3.7202 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.12774\n",
            "Epoch 7/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0475 - acc: 0.9808 - val_loss: 3.7846 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.12774\n",
            "Epoch 8/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0468 - acc: 0.9833 - val_loss: 3.8029 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.12774\n",
            "Epoch 9/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0487 - acc: 0.9822 - val_loss: 3.8130 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.12774\n",
            "Epoch 10/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0412 - acc: 0.9858 - val_loss: 3.8037 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.12774\n",
            "Epoch 11/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0422 - acc: 0.9843 - val_loss: 3.8052 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.12774\n",
            "Epoch 12/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0453 - acc: 0.9857 - val_loss: 3.8018 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.12774\n",
            "Epoch 13/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0456 - acc: 0.9827 - val_loss: 3.8060 - val_acc: 0.1065\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.12774\n",
            "Epoch 14/50\n",
            "348/348 [==============================] - 12s 36ms/step - loss: 0.0412 - acc: 0.9856 - val_loss: 3.8178 - val_acc: 0.1058\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.12774\n",
            "Epoch 15/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0454 - acc: 0.9838 - val_loss: 3.8117 - val_acc: 0.1058\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.12774\n",
            "Epoch 16/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0428 - acc: 0.9853 - val_loss: 3.8152 - val_acc: 0.1058\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0007225000590551645.\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.12774\n",
            "Epoch 17/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0496 - acc: 0.9816 - val_loss: 3.8109 - val_acc: 0.1058\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.12774\n",
            "Epoch 18/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0403 - acc: 0.9849 - val_loss: 3.8028 - val_acc: 0.1089\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.12774\n",
            "Epoch 19/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0437 - acc: 0.9844 - val_loss: 3.7290 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.12774\n",
            "Epoch 20/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0450 - acc: 0.9847 - val_loss: 3.7380 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.12774\n",
            "Epoch 21/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0447 - acc: 0.9834 - val_loss: 3.7357 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006141250254586339.\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.12774\n",
            "Epoch 22/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0367 - acc: 0.9868 - val_loss: 3.7359 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.12774\n",
            "Epoch 23/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0456 - acc: 0.9841 - val_loss: 3.7435 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.12774\n",
            "Epoch 24/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0422 - acc: 0.9845 - val_loss: 3.7656 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.12774\n",
            "Epoch 25/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0399 - acc: 0.9870 - val_loss: 3.8070 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.12774\n",
            "Epoch 26/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0397 - acc: 0.9869 - val_loss: 3.8125 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005220062914304435.\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.12774\n",
            "Epoch 27/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0393 - acc: 0.9864 - val_loss: 3.8115 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.12774\n",
            "Epoch 28/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0424 - acc: 0.9851 - val_loss: 3.8121 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.12774\n",
            "Epoch 29/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0404 - acc: 0.9861 - val_loss: 3.8125 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.12774\n",
            "Epoch 30/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0442 - acc: 0.9843 - val_loss: 3.8132 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.12774\n",
            "Epoch 31/50\n",
            "348/348 [==============================] - 13s 37ms/step - loss: 0.0442 - acc: 0.9837 - val_loss: 3.8090 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00044370535761117935.\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.12774\n",
            "Epoch 32/50\n",
            "348/348 [==============================] - 13s 36ms/step - loss: 0.0369 - acc: 0.9859 - val_loss: 3.8111 - val_acc: 0.1277\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.12774\n",
            "Epoch 00032: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRz_1oJzJRFH",
        "colab_type": "text"
      },
      "source": [
        "## **pre-trained ResNet50 didn't work either....**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9hqpxkxMahE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "9ba3e50a-ca6c-4e66-b961-693db037e8ec"
      },
      "source": [
        "X, y_true = next(val_generator)\n",
        "y_pred = base_model.predict(X)\n",
        "for i in range(1, len(val_generator)):\n",
        "  X, y = next(val_generator)\n",
        "  y_true = np.vstack((y_true, y))\n",
        "  y_pred = np.vstack((y_pred, base_model.predict(X)))\n",
        "\n",
        "y_true = np.argmax(y_true, axis=1)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "val_acc = accuracy_score(y_true, y_pred)\n",
        "#roc_auc = roc_auc_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = [k for k in val_generator.class_indices]\n",
        "c_report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "print('\\nval_acc:\\n', val_acc)\n",
        "print('\\nConfusion Matrix:\\n', cm)\n",
        "print('\\nClassification Report:\\n', c_report)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "val_acc:\n",
            " 0.12935656836461126\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 13   0   0 360   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]\n",
            " [  0   0   0 373   0   0   0   0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     C10_pos       1.00      0.03      0.07       373\n",
            "      C1_pos       0.00      0.00      0.00       373\n",
            "    C2-3_pos       0.00      0.00      0.00       373\n",
            "    C4-7_pos       0.13      1.00      0.22       373\n",
            "      C5_pos       0.00      0.00      0.00       373\n",
            "      C6_pos       0.00      0.00      0.00       373\n",
            "      C8_pos       0.00      0.00      0.00       373\n",
            "      C9_pos       0.00      0.00      0.00       373\n",
            "\n",
            "    accuracy                           0.13      2984\n",
            "   macro avg       0.14      0.13      0.04      2984\n",
            "weighted avg       0.14      0.13      0.04      2984\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}